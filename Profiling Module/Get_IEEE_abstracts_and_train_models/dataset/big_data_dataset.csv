BD_1,researcher investigating internet thing iot obtain information environment control act analysis collected big data important topic iot manage vast number device demo demonstrate management model order detect fault analyze network improve performance connectivity low powered mesh network model take action necessary visualize action state different managed object building proposed model modified wellknown network management protocol management data access performed fault performance analysis term value counter collected interface demonstration indicate usage proposed method perform well limited bandwidth network time security device firmware related feature also added management system ,2
BD_2,one recent application vehicular networking domain distributed data processing car sensor information recent concept vehicular cloud computing explored provide necessary scalability improve communication cluster car called vehicular micro cloud participant car bicyclist pedestrian order provide bigger picture also interconnect micro cloud data center cloud server considered bridging gap uplink capability connected car data center option include direct lte uplink car selected roadside unit rsus backend connectivity lte uplink vehicular micro cloud finally hybrid solution taking network quality available channel resource account finding clearly show advantage hybrid solution term throughput well optimizing operational cost ,2
BD_3,big data technology efficient case however disadvantage applied modern university current quality education high enough thus university satisfy several condition example providing broad set different type task including group discussion oral speech essay one possible correct opinion developing complex skill student collecting information course student activity progress alumnus skill undoubtedly big data opportunity develop quality education many small university provide private educational program small group moreover offer student direct conversation lecturer word mouth format educational strategy definitely advantage usage big data russia possible however claim increasing higher education quality ,2
BD_4,wireless sensor network wsn set thousand micro sensor node one important constraint limited energy since node small dimension needed energy provided small limited energy battery therefore problem energy reduction one biggest challenge network propose clusterbased method reduce average energy consumption round method data packet transmission b method normal node cluster head chs tree structure transmit data packet toward cluster head b respectively fact energy consumption reduced contrast leach following modification minimization hop length necessary transmission data packet inside cluster via continuously data aggregation cluster selection nearest cluster head b transmission final data packet toward b round simulation result show algorithm decrease average energy consumption sensor network contrast leach ,2
BD_5,automotive suspension system big potential mechanical failure due fatigue system subjected variable amplitude loading condition specifically focus coil spring one suspension system part vehicle driven road surface hit pothole bump coil spring affected significant load significant load cause damage component objective predict coil spring fatigue damage relate ikaz coefficient result statisticalbased method ikaz method signal captured repeated loading known fatigue signal car driven three different road highway country road damagesurface road strain gauge mounted outer surface coil spring capture fatigue load variable amplitude data road recorded strain analysed fatigue damage ikaz coefficient purpose analysis found damage road give highest fatigue damage rather road also fatigue damage proportionally related ikaz coefficient ,2
BD_6,recent technological trend cloud big data platform requires data gathered multiple erse network especially visual analytics aspect node network collect process transfer essential data scenario power efficiency bandwidth network become crucial factor play important role maintaining life longevity network specifically wireless network device dont constant power source mostly battery driven commonly iot device mobile phone sensor node smartwatches etc design development power efficient data routing protocol demand research perpetual industry well academic aspect research also contributes towards green computing short various protocol specialized carried also teen protocol investigated experimentally ,2
BD_7,describes methodology aiming introducing validation action step measurement process big data scenario typical industry application validation involves step measurement one data retrieving data storage organization data processing finally data presentation way variability result consequently uncertainty reduced usefulness taking mind metrological concept like measurement uncertainty level confidence also discussed case presented better demonstrate methodology reference condition monitoring application automatic system ,2
BD_8,internet thing iot paradigm extends connectivity capability everyday life object internet availability billion connected device spread able acquire elaborate data scenario development data acquisition system design method automatic management big data allowing digital service last year field application iot structural health monitoring shm system developed framework experimented good result system mainly devoted monitoring example multiple part civilindustrial structure reducing risk people due sudden collapse aim give overview different type structural health monitoring shm used identify detect characterize degradation damage type engineering structure highlighting benefit improvement obtained thanks application iot paradigm ,2
BD_9,recently trend big data cloud computing internet thing iot visualization network demand terabyte bandwidth computer performance graphic card order meet performance terabyte bandwidth graphic module dic high bandwidth memory hbm technology emerged due difference scale interconnect pitch gpu hbm package substrate hbm interposer certainly required terabyte bandwidth graphic module electrical performance hbm interposer channel consideration manufacturing capability analyzed simulation frequency timedomain furthermore although silicon substrate widely employed hbm interposer fabrication organic glass substrate also proposed replace high cost high loss silicon substrate therefore comparison analysis electrical performance hbm interposer channel silicon organic glass substrate conducted ,2
BD_10,fast robust threedimensional reconstruction facial geometric structure single image challenging numerous application introduce learningbased approach reconstructing threedimensional face single image recent face recovery method rely accurate localization key characteristic point contrast proposed approach based convolutionalneuralnetwork cnn extract face geometry directly image although deep architecture outperform model complex computer vision problem training properly requires large dataset annotated example case threedimensional face currently large volume data set acquiring bigdata tedious alternative propose generate random yet nearly photorealistic facial image geometric form known suggested model successfully recovers facial shape real image even face extreme expression various lighting condition ,2
BD_11,increase number forest fire last year dispatch government take precaution besides prevention early intervention also important fire fighting firefighter know fire time would easier stop fire therefore big need simulating fire behavior exists proposing system simulate propagation fire time also system visualize propagation fire dgis environment accepts kmz file format besides demanded data visualized map system give chance fire planning firefighter system visualize result screen therefore better understanding terrain obtained ,2
BD_12,g network expected able satisfy variety vertical service mobile user business demand automotive industry network slicing promising technology g provide network naas wide range service run different virtual network deployed shared network infrastructure moreover son selforganizing network g expected significant evolution guarantee full intelligence automatic faster management optimization deal requirement recently softwaredefined networking sdn network function virtualization nfv big data machine learning proposed emerging technology necessary tool g especially network slicing aim integrate various machine learning ml algorithm big data sdn nfv build comprehensive architecture experimental framework future son network slicing finally based framework successfully implemented early state traffic classification network slicing mobile broadband traffic application implemented broadband mobile lab bml national chiao tung university nctu ,2
BD_13,technology developed internet thing embedded device built every fabric urban environment connected data continuously produced device processed integrated different level made available standard format service data obviously f form ` big data seen valuable asset developing intelligent application size iot data continue grow becomes inefficient transfer raw data centralised cloudbased data centre perform efficient analytics even stateoftheart big data processing technology address problem article demonstrates idea distributed intelligence sensor data computing disperses intelligent computation much smaller autonomous unit eg sensor network gateway smart phone edge cloud order reduce data size provide high quality data data centre autonomous unit usually close proximity data consumer also provide potential reduced latency improved quality service research designing method apparatus distributed computing sensor data eg acquisition discovery estimation provide case urban air pollution monitoring visualisation ,2
BD_14,project named cityeyes based hbase big data analyzing platform realtimedisplay technology hcss could analyze data result dynamically project devoted designing online citydataanalyzing platform interacting real time filtering analyzing displaying data view filtering sample wuxi collect much information including phone signaling railway airport weibo population mobility etc moreover write enough data mining script variety data extract value view analyzing build efficient analyzing model ides two part includes front end back end back end focusing compressing data extracting valid information clustering data stream time frontend applies realtimedisplay technology provide interactive nicelooking data visualizing solution user view displaying come various solution two angle every variety data distribution network svgcanvas animation tech data mixed map display dynamically ,2
BD_15,intelligent transportation system it supposed constantly provide driver useful navigation information eg shortest driving path realtime traffic condition road condition data collecting raw data physical sensor various medium previous mainly considers develop framework extract useful information physical sensor meanwhile relatively rich usercontributed posting contain valuable information traffic road condition leveraged enhance effectiveness it address research gap present relatively approach extracting analyzing useful driving navigation information big data archived online social medium socalled social sensor particular advocate topic modelbased computational method extract relevant semantics eg traffic condition road condition driver condition etc relatively noisy usercontributed posting online social medium classification ensemble method proposed automatically identify specific traffic related event transmit useful navigation hint back dissemination driver evaluation based realworld posting twitter sina weibo demonstrates proposed social sensor analytics method effective identifying traffic event compared baseline method open door development next generation it leverage big data archived online social medium enhance richness quality traffic navigation aid provided it ,2
BD_16,kiichannel hvdc link one world biggest hvdc link utilizes submarine cable commercial operation since june link bulk power transmission coalfired thermal power plant load center also contributes stabilize reinforce power system western part japan many technology dc gas insulated switchgear large diameter lighttriggered thyristors applied project several coordination control also applied hvdc operation data since commissioning hvdc prof high reliability showing high energy utilization % ,2
BD_17,proposed related experimental application multilayer perceptron mlp artificial neural network ann oriented predictive diagnostic automated patient monitoring homecare assistance mean control room possible check periodically heart rate patient sending data home annmlp model designed developed knime workflow providing heart rate prediction good data processing performance describes step data processing highlighting procedure read workflow output according optimal heart rate value annmlp predictive diagnostic model suitable dehospitalization process enabling telemedicine smart sensor able measure patient physiological data finally provides solution big data system integration ,2
BD_18,aim highlight categorical method potential application could useful drawing company marketing strategy multivariate statistical technique used quantitative analysis marketing decision support system md nevertheless big data provide numerous qualitative variable whose processing requires categorical statistical method dealing big data marketing research carried multiple correspondence analysis show investigate intricate relation among categorical variable observed category specific regard consumer purchasing behavior data analysis allow detect essential aspect rational basis adopting effective marketing strategy ,2
BD_19,growing rhythm modern economy force company constantly introduce solution resulting innovating market nowadays vast majority business determined implement product technical technological organizational innovation enterprise focused creating value customer becoming aware demanding term increased customer requirement relating lead time delivery service product availability reliability newest solution internet thing big data industry create opportunity meet need contribute development logistics supply chain management analyse possibility utilizing business process management technique standard methodology artificial intelligence technique ai decision support system ds management business process supporting business process optimization centred approach supply chain usage business process lifecycle ,2
BD_20,cancer one twentyfirst century disease affecting thousand people around globe every biggest problem currently noninvasive method detection early detected cured avoiding death person selditofms used resulting data noisy therefore method data preprocessing classification reviewed effectiveness measured finally requirement diagnosis software discussed ,2
BD_21,supervisory control data acquisition scada system control monitor majority utility network today increased number attack computer system computer network resulted increased concern security issue internetworked industrial automation system internal external saboteur pose big threat could disrupt power delivery give u better understanding nature vulnerability supervisory control data acquisition system scada system highlight need defend protect scada system ongoing cyber threat investigate vulnerability way protect unique scada system achieve studying scada communication system well taking survey common scada vendor focus attention scada electric power grid find scada vendor implement adequate security measure product recommend security policy put place ensure security vital infrastructure ,2
BD_22,electronic device convey information displaying liquid crystal display lcd visually impaired people benefit electronic device lcd technology adapted product exist market product established relatively small number imported therefore useful product available affordable cost design construction talking call line identification tcli unit integrated sound output used telkom line unit incorporates audio visual inputoutput onboard function visually impaired user navigate unit setting assisted prerecorded voice prompt big input button graphical lcd unit completes unit used nonimpaired reproduction human voice accomplished prerecording solidstate information storage device isd capable recording eight minute voice data enables unit announce incoming caller number associated recording caller name come great benefit visually impaired seeing user telephone well ,2
BD_23,inefficiency road freight transport one primary factor hamper economy subsaharan africa long delay experienced border post single biggest contributor towards slow average movement freight crossborder operation complicated conflicting security objective custom authority versus efficiency objective transport operator furthermore suffers illegal practice involving truck driver custom official theory efficiency crossborder operation improved based availability accurate complete information latter possible different stakeholder exchange data currently isolated system firstly quantifies size problem estimate potential economic benefit created improved crossborder operation proposes combined gpsrfid system provide required level visibility support improved operational management resulting simultaneous increase security efficiency crossborder freight operation brief costbenefits analysis performed show expected benefit system far exceed cost implementation ,2
BD_24,data high volume velocity variety veracity brings experience curve analytics big data higher education come different source include blog social network student information system learning management system research machinegenerated data data analysed promise better student placement process accurate enrolment forecast early warning system identify assist student atrisk failing dropping big data becoming key creating competitive advantage higher education like organization traditional data processing analysis structured unstructured data rdbms data warehousing longer satisfy big data challenge lack adequate conceptual architecture big data tailored institution higher education led many failure produce meaningful accessible timely information decision making therefore call development conceptual architecture big data higher education present architecture big data analytics higher education ,2
BD_25,complexity big data structure network demand research term analysing representing data better comprehension usage regard several type model represent structure aim article social network topology analyse road network following state united state u california pennsylvania texas approach mainly focus clustering road network data order create community ,2
BD_26,sg smart grid emerging promising technology building one critical component sg meant leverage energyefficiency promote green usage via efficient renewable energy integration sg pose inherent challenge stemming mainly interdisciplinary nature besides ict information communication technology sg involves two broad discipline power system control system still ict major component manifest sg smartness architecture realworld smart microgrid testbed deployed university campus highlight component emphasis ict component advocating sg utilize internet thing iot source type data thus making whole system fall realm big data handle huge amount data collected advise deployment private local cloud source platform hpc highperformancecomputing hadoopmapreduce underlying data storage processing model deem project ideal blueprint easily adopted similar realworld smart microgrid testbeds africa around world ,2
BD_27,every project matter small big encounter conflict life cycle case conflict avoided managed timely identified important continuously monitor signal point existence action taken swiftly situation may lead deeper conflict might jeopardize lot project activity project manager organization stakeholder want article studied management conflict project also identifies discus analysis cause well various way conflict manifest project effect conflict project equally examined quantitative qualitative data generated different software mechanical design construction building structural water road project article concludes issue conflict management project reached point effective relevant strategy longer ignored conclusion article suggests direction future research make recommendation strategic conflict management project ,2
BD_28,text classification important field text mining due everincreasing volume text data internet text classification needed ever last decade researcher trying offer accurate model distinguish data class class many research aimed find set feature would increase accuracy classification recently deep learning considered ideal approach big data issue proved impact convolutional network improving result model mainly represent text based word due complexity natural language importance extra knowledge researcher still trying achieve efficient method research used deep convolutional neural network applied persian corpus remarkable feature model characterbased convolutional layer extract feature text higher accuracy characterbased representation ,2
BD_29,presented development hybrid intelligent system conditionbased maintenance cbm peircesmith converter psc considered integral part plantwide operational system psc considered nonlinear stochastic timevarying big uncertainty thus neural network nn modeling degradation tuyer accepted data reconciliation performed order reduce gross error method candidatetuyer possible blocking proposed quantity blocked tuyers blocking time determined higher hierarchical level tradeoff learning procedure casebased reasoning model predictive control thresholdbased maintenance estimate minimal residual size psc refractory lining final series process cycle nnbased approach proposed signal hottest spot image processing pattern recognition representative experimental stimulation result presented ,2
BD_30,recent year seen increasing number scientist employ data parallel computing framework mapreduce hadoop run data intensive application conduct analysis colocated compute storage framework wise data placement scheme significantly improve performance existing data parallel framework eg hadoop hadoopbased cloud distribute data random placement method simplicity load balance however observe many data intensive application exhibit interest locality sweep part big data set data often accessed together result grouping semantics without taking data grouping consideration random placement perform well way efficiency optimal data distribution develop datagroupingaware draw data placement scheme address abovementioned problem draw dynamically scrutinizes data access system log file extract optimal data grouping reorganizes data layout achieve maximum parallelism per group subjective load balance experimenting two realworld mapreduce application different data placement scheme node test bed conclude draw increase total number local map task executed % reduces completion latency map phase % improves overall performance % comparison hadoops default random placement ,2
BD_31,performance gap cpu storage subsystem becoming bigger bigger fill gap common method caching prefetching prefetching read data cachebuffer accessed depends predicting data block accessed accurately however difficult predict next io request storage subsystem system serve lot application simultaneously io request come multiapplication mixed together original sequent io look like random io make difficult figure io mode predict data block accessed designed implemented prefetching scheme storage system adapt multiapplication named psam level hash table used help detecting sequential io mixed io stream sequential io substream detected adaptive sequential prefetching algorithm applied differing common prefetching scheme psam maintains prefetchingdata hotdata two different cache designed independently flexible application need inform anything psam keep application interface compatible evaluation result show psam improve performance storage system percent time multiapplication environment ,2
BD_32,summary form given asip application specific instructionset processor dedicated designed application domain asip instruction set specifically designed accelerate heavy used function asip architecture designed implement assembly instruction set minimum hardware cost asip dsp application specific digital signal processor iterative data manipulation transformation extensive application generalpurpose processor designer think maximum performance maximum flexibility instruction set must general enough support general application compiler offer compilation program adapt programmer coding behavior asip designer think application cost first usually biggest challenge asip designer silicon cost power consumption based carefully specified function coverage goal asip design reach highest performance silicon power consumption well design cost requirement flexibility sufficient instead ultimate performance application specific instead highest one tutorial asip application specific instruction set processor introduced discussed audience want know asip yet want design introduction includes asip design flow source code profiling architecture exploration assembly instruction set design design assembly language programming toolchain firmware design benchmarking micro architecture design two example design instruction set level acceleration radio baseband design instruction set level acceleration image video signal processing introduced professional asip designer please read dake liu embedded dsp processor design application specific instruction set processor elsevier isbn detail ,2
BD_33,department defense dod downsizes great need reduce maintenance burden currently system dod inventory utilize numerous hardware interconnecting device data protocol communicate diagnostics maintenance information external system maintainer communication device end big burden system maintainer term weight volume moreover interconnecting device require portable maintenance aide tethered weapon system greatly confines maintainer mobility hence waste maintenance manpower advanced technology office ato u army test measurement diagnostic equipment activity usata sep initiated proofofconcept wireless remotecontrollable communication device could developed untether maintainer maintenance aide system weapon system provides development design wireless remotecontrollable communication device ,2
BD_34,estimated midsize company usa generate equivalent data u library congress company walmart creates equivalent million filing cabinet worth data every hour number seem incredible trend company increasing volume data generation storage test data generated automatic test equipment ate r & ampampd manufacturing repair environment exception increased volume data challenge enormous amount test data provide people effective way make decision data visualization chart graph report historically one effective way provide actionable intelligence human readily make decision based pattern comparison data volume go even method reaching limit one start combine large datasets like manufacturing test data repair data together data visualization becomes problematic sophisticated algorithmic machine learning predictive approach become critical explore experience predictive algorithm big data manufacturing test repair test environment complex mission critical aerospace industry effectively datasets different functional area looking applying spc technique answer question correlation repair test data manufacturing data end goal predict number return future minimize product escape ,2
BD_35,axie commonly referred big brother pxi share many feature pxi modular structure pci express fabric similar software deploying large board size power cooling matching found high performance instrument however also add one unique aspect axie local bus author describe local bus compare common bus topology author describe local bus capability real world implementation application demonstrate breakthrough system performance utilizing local bus capability include real time streaming processing excess gb per link link per chassis real time highspeed streaming enables number application previously unrealized radar system evaluation simulation example data streamed indefinitely highspeed digitizer data processing module raid array highenergy physic another example data recorded long period triggered event detected digital processor unit indeed broad range data acquisition application long data stream need recorded processed searching intermittent event axie local bus enables capability previously unattainable speed ,2
BD_36,hpc big data community continue converge heterogeneous distributed system becoming commonplace order take advantage immense computing power system distributing data efficiently leveraging specialized hardware eg accelerator critical mapreduce popular paradigm provides automatic data distribution programmer cuda opencl popular framework leveraging accelerator specifically gpus heterogeneous systemsin develop portable highlevel framework popular mapreduce framework apache spark conjunction cuda opencl order simultaneously take advantage automatic data distribution specialized hardware node hpc system framework accelerate two realworld compute data intensive graph analytics application function call graph similarity application triangle enumeration subroutine demonstrate linear scalability call graph similarity application well exploration triangle enumeration parameter space show method yield portable solution used leverage almost legacy current nextgeneration hpc cloudbased system ,2
BD_37,recent technological advancement led deluge data distinctive domain eg health care scientific sensor usergenerated data internet financial company supply chain system past two decade term big data coined capture meaning emerging trend addition sheer volume big data also exhibit unique characteristic compared traditional data instance big data commonly unstructured require realtime analysis development call system architecture data acquisition transmission storage largescale data processing mechanism literature survey system tutorial big data analytics platform aiming provide overall picture nonexpert reader instill doityourself spirit advanced audience customize bigdata solution first definition big data discus big data challenge next systematic framework decompose big data system four sequential module namely data generation data acquisition data storage data analytics four module form big data value chain following detailed survey numerous approach mechanism research industry community addition prevalent hadoop framework addressing big data challenge finally outline several evaluation benchmark potential research direction big data system ,2
BD_38,intelligent transportation system concept introduced increase road safety manage traffic efficiently preserve green environment nowadays application becoming dataintensive data described v big data thus fully utilize data big data analytics need applied internet vehicle iov connects device cloud computing centre data processing performed however transferring huge amount data geographically distributed device creates network overhead bottleneck consumes network resource addition following centralized approach process big data result high latency tolerated delaysensitive application fog computing considered promising technology realtime big data analytics basically fog technology complement role cloud computing distributes data processing edge network provides faster response application query save network resource however implementing fog computing lambda architecture realtime big data processing challenging iov dynamic environment regard novel architecture realtime big data analytics iov environment proposed proposed architecture merges three dimension including intelligent computing ie cloud fog computing dimension realtime big data analytics dimension iov dimension moreover give comprehensive description iov environment big data characteristic lambda architecture realtime big data analytics several intelligent computing technology importantly discus opportunity challenge face implementation fog computing realtime big data analytics iov environment finally critical issue future research direction section discus issue considered order efficiently implement proposed architecture ,2
BD_39,big data explosively generated various area considered growth engine erse industry recent year analysis big data attracted attention exhibit potential generate high value addition advent iot era wherein object connected others system importance big data likely continue emphasized due availability data generated erse device increasing importance indoor space city dweller spend % daily life big data containing user indoor positioning information critical asset understanding indoor behavior pattern user shopping behavior pattern customer large department store however also risk leakage personal information feasible infer user sensitive information tracking analyzing user indoor position local differential privacy ldp stateoftheart approach used protect inidual privacy process data collection ldp ensures privacy data contributor protected perturbing herhis original data data contributor side thus data collector access original data still able obtain population statistic focus application ldp collection indoor positioning data particular experimentally evaluated utilization indoor positioning big data collected leveraging ldp estimating density specified indoor area experimental result synthetic actual data set demonstrate ldp well applicable collection indoor positioning data inferring population statistic ,2
BD_40,expand trend cloud data mobility led malicious data threat necessitate data protection technique cloud system application contain valuable confidential data personal trade health information threat data may put cloud system hold data high risk however traditional security solution capable handling security big data mobility current security mechanism insufficient big data due shortage determining data protected due intractable time complexity therefore demand securing mobile big data increasing rapidly avoid potential risk proposes integrated methodology classify secure big data executing data mobility duplication analysis necessity securing big data mobility determined classifying data according risk impact level content two category confidential based classification category impact data security studied substantiated confidential data scope hadoop distributed file system revealed proposed approach significantly improve cloud system data mobility ,2
BD_41,mobile cellular network become generator carrier massive data big data analytics improve performance mobile cellular network maximize revenue operator introduce unified data model based random matrix theory machine learning architectural framework applying big data analytics mobile cellular network moreover describe several illustrative example including big signaling data big traffic data big location data big radio waveform data big heterogeneous data mobile cellular network finally discus number research challenge big data analytics mobile cellular network ,2
BD_42,recent year big data become hot research topic increasing amount big data also increase chance breaching privacy iniduals since big data require high computational power large storage distributed system used multiple party involved system risk privacy violation increased number privacypreserving mechanism developed privacy protection different stage eg data generation data storage data processing big data life cycle goal provide comprehensive overview privacy preservation mechanism big data challenge existing mechanism particular illustrate infrastructure big data stateoftheart privacypreserving mechanism stage big data life cycle furthermore discus challenge future research direction related privacy preservation big data ,2
BD_43,approximately quintillion byte data emitted daily basis brought world era big data ann known effectiveness efficiency small datasets era big data posed challenge big data analytics ann recently much research effort devoted application ann big data analytics still ongoing although early stage summarise recent progress challenge opportunity future research present concise view stateoftheart challenge future research opportunity regarding application ann big data analytics reveals progress made area point limitation previous approach challenge ann approach term application big data analytics several ann architecture yet explored big data analytics opportunity future research believe serve yardstick future progress application ann big data analytics well starting point researcher interest exploration ann big data analytics ,2
BD_44,voluminous amount data produced since past decade miniaturization internet thing iot device increase however data useful without analytic power numerous big data iot analytics solution enabled people obtain valuable insight large data generated iot device however solution still infancy domain lack comprehensive survey investigates stateoftheart research effort directed toward big iot data analytics relationship big data analytics iot explained moreover add value proposing architecture big iot data analytics furthermore big iot data analytic type method technology big data mining discussed numerous notable case also presented several opportunity brought data analytics iot paradigm discussed finally research challenge privacy big data mining visualization integration presented future research direction ,2
BD_45,traditionally data generated manufacturing process full management decision difficult achieve decision optimization manufacturing system level analysis big data uncertain information influence assembly objective helpful improve capacity resisting disturbance scheduling system realize optimal production focus analysis utilization assembly big data manufacturing process study key technology big data analysis assembly scheduling optimization complex equipment big data analysis scheduling optimization system proposed solve assembly execution decision complex equipment proposes analyze assembly big data make decision uncertain information locally linear embedding adaptive boosting support vector machine d evidence theory order explore influence pattern assembly environment assembly efficiency neural industrial engineering proposed introduced human error prediction based physiological big data finally variable metric clustering assembly task provided ensure maximization assembly efficiency production balance proposed system effectively handle dynamic uncertain information assembly get better overall scheduling optimization assembly system support technology presented provide good theoretical ,2
BD_46,cyberphysical system produce large amount data stored domainrelated data lake variety format big data technology enable efficient data processing value data increase technology turn data actionable information influence important decisionmaking process however broader view operational environment investigated phenomenon challenge related frequently obtained combining data many data set located various big data lake requires contact point data lake must flexibly joined many case data set correspond one another directly show fuzzy join operation flexible combining big data lake fuzzy join transforms numerical value common attribute joined data set fuzzy set us representation join operation propose two variant join operation transforms crisp numerical value joining attribute fuzzy number linguistic term fuzzy join operation implemented tested declarative usql language used scalable parallel querying big data lake idea presented exemplified distributed analysis cardiac disease data microsoft azure cloud result conducted experiment confirm fuzzy join enrich data set used making critical decision highly scalable cloudbased solution successfully used processing large volume data delivered cyberphysical system ,2
BD_47,order enable big data analysis data volume go beyond available computing resource propose method big data analysis method us random sample data block big data set obtain approximate result entire data set random sample partition rsp distributed data model used represent big data set set nonoverlapping random sample data block block saved rsp data block file used directly estimate statistical property entire data set subset rsp data block randomly selected analyzed existing sequential algorithm parallel result block combined obtain ensemble estimate model improved gradually appending result newly analyzed rsp data block end propose distributed dataparallel framework alpha framework develop prototype framework microsoft r server package hadoop distributed file system experimental result three real data set show subset rsp data block data set sufficient obtain estimate model equivalent computed entire data set ,2
BD_48,past five year research big data analysis actively conducted many service developed find valuable data however low quality raw data data loss problem data analysis make difficult perform accurate data analysis enormous generation unstructured structured data refinement data becoming increasingly difficult result data refinement play important role data analysis addition part effort ensure research reproducibility importance reuse researcher data research method increasing however research system supporting role conducted sufficiently therefore propose big data analysis system named unified data analytics suite uda focus data refinement uda performs data refinement based big data platform ensures reusability reproducibility refinement analysis visual programming language interface also recommends source visualization library user statistical analysis qualitative evaluation uda functional evaluation factor big data analysis platform demonstrated average satisfaction user significantly high ,2
BD_49,fault diagnosis important topic practice research intense pressure industrial system continue reducing unscheduled downtime performance degradation safety hazard requires detecting recovering potential fault early possible historical perspective ides fault diagnosis previous research industrial big data era according primary driver classifies fault diagnosis knowledgedriven datadriven valuedriven method among former two approach belong previous research fault diagnosis mainly depend expert experience shallow model detect extract failure relatively small size data continuous exponential growth data insufficient mine valuable fault information massive multisource heterogeneous data huge diagnostic value embodied industrial big data driven emergence third category belongs fault diagnosis based big data consists big data processing analysis corresponding high efficiency cost effectiveness generality deal well problem previous method faced introduce concept device electrocardiogram perspective applicability outline status fault diagnosis big data compare traditional diagnostic system also discus issue challenge need considered would great valuable integrate explore advanced diagnostic method handle collected industrial big data put practice mine huge hidden diagnostic value ,2
BD_50,geological big data becoming focus geoscience research vast amount textual geoscience data provides opportunity challenge data analysis data mining fact seem possible meet demand big data age traditional manual reading information extraction gaining knowledge workflow proposed extract prospecting information text mining based convolutional neural network cnns aim classify text data extract prospecting information automatically procedure involves three part text data acquisition text classification based cnn statistic visualization first large amount available text data acquired based geoscience big data acquisition methodology text preprocessing cnn used classify geoscience text data four category geology geophysics geochemistry remote sensing category consisting three level text scale word sentence paragraph second word frequency statistic cooccurrence matrix statistic term frequencyinverse document frequency tfidf statistic word sentence paragraph respectively aimed obtain key node link derived contentwords finally deep semantic information big data mining relevant geoscience text visualized word cloud knowledge graph eg chord bigram graph tfidf statistical graph lala copper deposit sichuan province taken test case prospecting information extracted successfully developed text mining methodology provides strong basis research establishing mineral deposit prospecting model based logical knowledge tree addition show great potential method intelligent information extraction geoscience big data ,2
BD_51,contextawareness big data application different traditional application getting challenging obtain context big data due complexity velocity variety aspect big data especially big video data awareness context big data difficult indepth classical application therefore propose indepth contextawareness framework pervasive video cloud order obtain underlying context big video data framework propose approach combine historical view current view obtain meaningful indepth context deep learning technique used obtain raw context data conducted initial evaluation show effectiveness proposed approach term performance also accuracy obtaining context evaluation result show proposed approach effective realtime contextawareness pervasive video cloud ,2
BD_52,emergence data handling technology analytics enabled organization big data process innovative aspect wireless sensor network wsns big data paradigm combined wsn technology involves challenge necessary resolve parallel data aggregation rapidly emerging research area represents one processing challenge big sensor network introduces big data paradigm dimension represent one challenging concept principle analytic tool introduced wsns technology also present big data challenge must overcome efficiently manipulate voluminous data proposes classification challenge based necessity challenge wsns big data aggregation challenge represents center interest survey proposed strategy wsns ,2
BD_53,idea big data gained extensive attention government academia world especially relevant establishment smart city environment combining complex heterogeneous data data analytics artificial intelligence ai technology big data generated many facility sensor network smart city often streamed stored cloud storage platform ensuring integrity subsequent auditability big data essential performance aidriven data analysis recent year witnessed emergence many big data auditing scheme often characterized third party auditor tpas however tpa centralized entity vulnerable many security threat inside outside cloud avoid centralized dependency propose decentralized big data auditing scheme smart city environment featuring blockchain capability supporting improved reliability stability without need centralized tpa auditing scheme support designed optimized blockchain instantiation conducted comprehensive comparison existing scheme proposed scheme theoretical analysis experimental evaluation comparison show lower communication computation cost incurred scheme existing scheme ,2
BD_54,big medical data pose great challenge life scientist clinician computer scientist engineer group life scientist clinician computer scientist engineer sit together discus several fundamental issue first unique characteristic big medical data different domain ? second prioritized task clinician research practice utilizing big medical data ? enough publicly available data set performing task ? third stateofthepractice stateoftheart algorithm perform good job ? fourth benchmark measuring algorithm system big medical data ? fifth performance gap stateofthepractice stateoftheart system handling big medical data currently future ? finally least life scientist clinician computer scientist engineer ready working together ? believe answering issue help define shape landscape big medical data ,2
BD_55,advance newgeneration information technology especially big data digital twin smart manufacturing becoming focus global manufacturing transformation upgrading intelligence come data integrated analysis manufacturing big data beneficial aspect manufacturing besides digital twin pave way cyberphysical integration manufacturing important bottleneck achieve smart manufacturing big data digital twin manufacturing reviewed including concept well application product design production planning manufacturing predictive maintenance basis similarity difference big data digital twin compared general data perspective since big data digital twin complementary integrated promote smart manufacturing discussed ,2
BD_56,sp theory intelligence realization sp machine may advantage applied management analysis big data sp systemintroduced fully described elsewheremay help overcome problem variety big data potential universal framework representation processing erse kind knowledge helping reduce ersity formalism format knowledge different way processed strength unsupervised learning discovery structure data pattern recognition parsing production natural language several kind reasoning lends analysis streaming data helping overcome problem velocity big data central working system lossless compression information making big data smaller reducing problem storage management potential substantial economy transmission data big cut energy computing faster processing smaller lighter computer system provides handle problem veracity big data potential assist management error uncertainty data lends visualization knowledge structure inferential process highparallel opensource version sp machine would provide mean researcher everywhere explore done system create version ,2
BD_57,advance smart grid enabling huge amount data aggregated analyzed various smart grid application however traditional smart grid data management system scale provide sufficient storage processing capability address challenge present smart grid big data ecosystem based stateoftheart lambda architecture capable performing parallel batch realtime operation distributed data furthermore presented ecosystem utilizes hadoop big data lake store various type smart grid data including smart meter image video data implementation smart grid big data ecosystem cloud computing platform presented test capability presented ecosystem realtime visualization data mining application performed real smart grid data result application top ecosystem suggest capable performing numerous smart grid big data analytics ,2
BD_58,big data revolution promise transform think enabling process optimization empowering insight discovery improving decision making realization grand potential relies ability extract value massive data data analytics machine learning core ability learn data provide data driven insight decision prediction however traditional machine learning approach developed different era thus based upon multiple assumption data set fitting entirely memory unfortunately longer hold true context broken assumption together big data characteristic creating obstacle traditional technique consequently compiles summarizes organizes machine learning challenge big data contrast research discus challenge highlight causeeffect relationship organizing challenge according big data v dimension instigated issue volume velocity variety veracity moreover emerging machine learning approach technique discussed term capable handling various challenge ultimate objective helping practitioner select appropriate solution case finally matrix relating challenge approach presented process provides perspective domain identifies research gap opportunity provides strong foundation encouragement research field machine learning big data ,2
BD_59,special type big data big graph wide application remote data integrity checking rdic scheme enables cloud efficiently convince client graph data stored properly without need retrieving actual data content existing scheme support verifiable update often adopting authentication data structure ad eg merkel hash tree mht obstacle applying existing rdic scheme big graph due lack support verifiable subgraph operation high efficiency propose rdic scheme big graph called gvdrdic support auditing verifiable dynamic graph update high efficiency designed novel ad based graph voronoi diagram gvd enhanced mht address integrity graph structure verifiable subgraph update addition ad applied type graph moreover gvdrdic scheme adopts construction homomorphic authenticator enable index verification auditor server response constructed unchallenged block rejected proposed scheme proven secure random oracle model theoretical analysis simulation result show scheme practicable realworld big graph ,2
BD_60,mobile device increasingly becoming indispensable part people daily life facilitating perform variety useful task mobile cloud computing integrates mobile cloud computing expand capability benefit overcomes limitation limited memory cpu power battery life big data analytics technology enable extracting value data four v volume variety velocity veracity discus networked healthcare role mobile cloud computing big data analytics enablement motivation development networked healthcare application system presented adoption cloud computing healthcare cloudletbased mobile cloudcomputing infrastructure used healthcare big data application described technique tool application big data analytics reviewed conclusion drawn concerning design networked healthcare system big data mobile cloudcomputing technology outlook networked healthcare given ,2
BD_61,big data promoting development supply chain design management problem trustworthy scheduling big data challenging significantly influence performance agricultural product supply chain apsc management currently various approach optimize scheduling apsc tackle problem primary objective time cost limited smallscale supply chain efficient approach provided scheduling apsc big data environment aim proposing novel trustworthy scheduling optimization approach apsc big data first management architecture provided revealing underexploited value big data support scheduling apsc second novel scheduling model presented guarantee trustworthiness agricultural product supply chain last evolutionary algorithm developed optimize scheduling largescale supply chain complex structure experiment performed various scale test instance apsc customer review search space result compiled demonstrate effectiveness proposed approach ,2
BD_62,today one challenge big data research processing big timeseries data moreover time data analysis considerable importance previous trend useful predicting future due considerable delay volume data increase presence redundancy innate lack timeseries structure traditional relational data model seem adequately able analyze time data moreover many traditional data structure support time operator result inefficient access time data therefore relational database management system difficulty dealing big datait may require massively parallel software run many server led u implement chronos software inmemory backgroundbased time database keyvalue pair software implemented c++ language independent design suggested appropriately temporal algorithm parallelism algorithm method data storage ram result indicate employment ram storing data timeline index algorithm getting access time background key chronos translate increase % % efficiency compared database mysql mongodb ,2
BD_63,rapid growth data past decade information communication technology made significant impact global environment positive negative aspect recent year international effort made advance green technology initiative support sustainable system technical economic societal development & ltxref reftypebibr ridref & gt & ltxref & gt & ltxref reftypebibr ridref & gt & ltxref & gt generation huge amount data called big data across different sector banking healthcare retail education among others creating need efficient tool manage data & ltxref reftypebibr ridref & gt & ltxref & gt conventional database management tool capability manage surging volume unstructured data example % data unstructured form video tweet gps global positioning system coordinate email mean decision need made high velocity amount data expected exponentially grow data collection via pervasive sensor andor internet also lead emerging challenge potential create accurate solution science technology believe big data significant impact green communication computing aim provide energysustainable resourcesaving environmentfriendly solution recently panoramic investigation direction two relevant work recently published provide indepth understanding area & ltxref reftypebibr ridref & gt & ltxref & gt & ltxref reftypebibr ridref & gt & ltxref & gt goal special section therefore provide insight view development area big data green communication computing well provide direction research field ,2
BD_64,modern day big data curation data become important especially handling high volume complex data system data volume growing exponentially increasing variety heterogeneity data source acquiring data may need analysis become costly timeconsuming process multiple data set various source must first processed connected used big data analytics tool publication presentation data analytics also important however traditional data curation system designed consideration chronological value another limitation usually designed programmer ordinary user propose chronological big data curation system proposed system acquisition care data processed basis relation specific topic chronological order ensure data maintains value time system implemented experimental result show goodness proposed system ,2
BD_65,core part generation information technology internet thing accumulated large number realtime data stream various type structure data stream generated extremely fast speed content distribution characteristic highspeed dynamic change must processed real time therefore feature learning algorithm required support incremental update learn characteristic highspeed dynamic change data real time current machine learning model processing big data belong static learning model batch learning method make impossible analyze data stream real time learning ability dynamic data stream poor therefore proposes incremental highorder deep learning model extend data vector space tensor space update parameter structure network model highorder tensor space process parameter updating firstorder approximation concept introduced avoid incrementing parameter iterative method improve parameter update efficiency updated model quickly learn characteristic dynamically changing big data satisfy realtime requirement big data feature learning maintaining original knowledge neural network model much possible evaluate performance proposed model experiment performed real image data setsmnist model evaluated stability plasticity run time experimental result show model ability incrementally learn characteristic data online also retains ability learn original data feature improve model update efficiency maximize online analysis realtime processing dynamic data stream ,2
BD_66,current analytical approach computational social science characterized four dominant paradigm text analysis information extraction classification social network analysis graph theory social complexity analysis complex system science social simulation cellular automaton agentbased modeling however come organizational societal unit analysis exists approach conceptualize model analyze explain predict social medium interaction iniduals association idea value identity address limitation based sociology association mathematics set theory present approach big data analytics called social set analysis social set analysis consists generative framework philosophy computational social science theory social data conceptual formal model social data analytical framework combining big social data set organizational societal data set three empirical study big social data presented illustrate demonstrate social set analysis term fuzzy settheoretical sentiment analysis crisp settheoretical interaction analysis eventstudiesoriented settheoretical visualization implication big data analytics current limitation settheoretical approach future direction outlined ,2
BD_67,many community researched application novel network architecture contentcentric networking ccn softwaredefined networking sdn build future internet another emerging technology big data analysis also lot attention academia industry many splendid research done ccn sdn big data addressed separately traditional literature propose novel network paradigm jointly consider ccn sdn big data provide architecture internal data flow big data processing case indicate benefit applicability simulation result exhibited show potential benefit relating proposed network paradigm refer novel paradigm datadriven networking ,2
BD_68,traditional internet brain thing big data information filtering method ignores extraction big data feature filtering effect effect denoising processing simulation result resulting low filtering accuracy poor performance effective information filtering mining algorithm internet brain thing based support vector machine svm proposed first model construction feature extraction internet brain thing big data system carried correlation feature extraction performed effective information feature correlation factor effective information data sorted feature quantity relevance degree extracted filter nonassociation designed information reasonably filtered data processed converted interval processing data protocol implemented data effective information feature mining implemented based svm algorithm simulation result show algorithm effective filtering big data high precision superior performance show good application value ,2
BD_69,explosion big data technology healthcare data continuously rapidly growing abundant various value wide variety data heterogeneous healthcare data image text video raw sensor data etc generated required effectively stored processed queried indexed analyzed datasets differ widely volume variety velocity value including patientoriented data electronic medical record emr publicoriented data health data knowledgeoriented data drugtodrug drugtodisease diseasetodisease interaction registry big data healthcare brings great challenge play important role healthcare transformation traditional technique compromise endusers quality qos term data availability data response delay etc urgent develop software tool technique support rapid query processing speedup data analytics provide awareness knowledge realtime ,2
BD_70,big data considered key unlocking next great wave growth productivity amount collected data world exploding due number application technology permeate daily life including mobile social networking application internet thingbased smartworld system smart grid smart transportation smart city exponential growth data efficiently utilize data becomes critical issue call development big data market enables efficient data trading via pushing data kind commodity digital market data owner consumer able connect sharing increasing utility data nonetheless enable effective market data trading several challenge need addressed determining proper pricing data sold purchased designing trading platform scheme enable maximization social welfare trading participant efficiency privacy preservation protecting traded data resold maintain value data conduct comprehensive survey lifecycle data data trading specific first variety data pricing model categorize different group conduct comprehensive comparison pro con model focus design data trading platform scheme supporting efficient secure privacypreserving data trading finally digital copyright protection mechanism including digital copyright identifier digital right management digital encryption watermarking others outline challenge data protection data trading lifecycle ,2
BD_71,dissemination patient medical record result erse risk patient privacy malicious activity record cause severe damage reputation finance party related directly indirectly data current method effectively manage protect medical record proved insufficient propose medshare system address issue medical data sharing among medical big data custodian trustless environment system blockchainbased provides data provenance auditing control shared medical data cloud repository among big data entity medshare monitor entity access data malicious data custodian system medshare data transition sharing one entity action performed medshare system recorded tamperproof manner design employ smart contract access control mechanism effectively track behavior data revoke access offending entity detection violation permission data performance medshare comparable current cutting edge solution data sharing among cloud provider implementing medshare cloud provider data guardian able achieve data provenance auditing sharing medical data entity research medical institution minimal risk data privacy ,2
BD_72,intrusion detection system id provides important basis network defense due development cloud computing social network massive amount data generated inevitably brings much pressure id therefore becomes crucial efficiently ide data different class big data according data feature moreover determine whether one normal behavior based class information although clustering approach based kmeans id well studied unfortunately directly big data environment may suffer inappropriateness one hand efficiency data clustering need improved hand differ classification unified evaluation indicator clustering issue thus necessary indicator suitable evaluating clustering result id propose clustering method id based mini batch kmeans combined principal component analysis first preprocessing method proposed digitize string data set normalized improve clustering efficiency second principal component analysis method used reduce dimension processed data set aiming improve clustering efficiency mini batch kmeans method used data clustering specifically kmeans++ initialize center cluster order avoid algorithm getting local optimum addition choose calsski harabasz indicator clustering result easily determined compared method experimental result time complexity analysis show proposed method effective efficient proposed clustering method used id big data environment ,2
BD_73,freely available online data rapidly increasing company detected possibility value data business particular data social medium seen interesting properly treated assist achieving customer insight business decision making however unstructured uncertain nature kind big data present kind challenge evaluate quality data manage value data big data architecture ? contributes addressing challenge introducing architectural solution evaluate manage quality social medium data processing phase big data pipeline proposed solution improves business decision making providing realtime validated data solution validated industrial case example customer insight extracted social medium data order determine customer satisfaction regarding quality product ,2
BD_74,business process represent cornerstone operation enterprise operational mean organization fulfill goal nowadays enterprise able gather massive amount event data generated business process executed stored transaction log database email correspondence free form text enterprise social medium taping data enterprise would like weave data analytic technique decision making capability recent year industry witnessed significant advancement domain big data analytics unfortunately business process management bpm community kept speed development often rely merely traditional modelingbased approach way effectively exploiting data sufficiently used advocate good understanding business process big data world play effective role improving efficiency quality various dataintensive business operation wide spectrum emerging big data system moreover coin termitalicprocess footprintitalicas wider notion process data currently perceived bpm community roadmap towards taking business process data intensive operation next level shaped ,2
BD_75,educational datamining evolving discipline focus improvement selflearning adaptive method used finding hidden pattern intrinsic structure educational data arena education heterogeneous data involving continuously growing paradigm bigdata extract meaningful information adaptively big educational data specific data mining technique needed present clustering approach partition student different group cluster based learning behavior furthermore personalized elearning system architecture presented detects responds teaching content according student learning capability primary objective includes discovery optimal setting learner improve learning capability moreover administration find essential hidden pattern bring effective reform existing system clustering method kmeans kmedoids densitybased spatial clustering application noise agglomerative hierarchical cluster tree clustering fast search finding density peak via heat diffusion cfsfdphd analyzed educational data mining observed robust result achieved replacement existing method cfsfdphd data mining technique equally effective analyzing big data make education system vigorous ,2
BD_76,traditional bigdata analytical approach data clustering small bucket providing distributed computation among different child node approach bring issue especially concerning network capacity specialized tool application capable trained short period furthermore raw data generated iot forming big data come capability producing highly unstructured heterogeneous form data form data grows challenging realtime analytics highly valuable computational value available locally instead distributed resource reduce realtime analytical challenge proposes fusion three different data model like relational semantical big data based data metadata involving issue enhanced capability case used represent data fusion action rdb resource description framework whereas issue feasible solution also discussed ,2
BD_77,feature selection important research area data mining chooses subset relevant feature model building aim provide overview feature selection method big data mining first discus current challenge difficulty faced mining valuable information big data comprehensive existing feature selection method big data presented herein approach two aspect method specific particular kind big data certain characteristic application method classification analysis significantly different existing also highlight current issue feature selection big data suggests future research direction ,2
BD_78,online fraud transaction big concern ebusiness platform development big data technology ecommerce user evaluate seller according reputation score supplied platform reason seller prefer chasing high reputation score high reputation bring high profit seller collusion fraudsters acquire high reputation score attract potential buyer crucial ecommerce website recognizing fake reputation information ecommerce platform try solve continued growing problem adopting data mining technique high development internet thing iot big data play crucial role economic society big data brings economic growth different domain supply support management decisionmaking ability ebusiness analyzing operational data online commerce big data technology also help providing user fair healthy reputation system improves shopping experience aim put forward conceptual framework extract characteristic fraud transaction including inidual transaction related indicator also contains two product feature product type product nature two feature obviously enhance accuracy fraud detection realworld dataset used verify effectiveness indicator detection model put forward recognize fraud transaction legitimate one ,2
BD_79,deep learning currently extremely active research area machine learning pattern recognition society gained huge success broad area application speech recognition computer vision natural language processing sheer size data available today big data brings big opportunity transformative potential various sector hand also present unprecedented challenge harnessing data information data keep getting bigger deep learning coming play key role providing big data predictive analytics solution provide brief overview deep learning highlight current research effort challenge big data well future trend ,2
BD_80,big data analytics applied signaling traffic wireless environment data mobile communication network help realize autonomous network optimization build big databased network operation signalingbased intelligent network optimization scheme introduced applied current mobile communication network g long term evolution g era big data analytics help mine requirement radio access network level thus allowing efficient g design operation illustrates would significantly facilitate local content provision dynamical network functionality deployment behavior awareness finetuned network operation globally optimized energy saving solution anticipated big databased g network design operation greener softer better meet ever increasing usercentric requirement mobile communication ,2
BD_81,big data one hottest research topic science technology community posse great application potential every sector society climate economy health social science big data usually includes data set size beyond ability commonly used software tool capture curate manage conclude big data still infancy stage face many unprecedented problem challenge way unfolding chapter human history ,2
BD_82,big data strongly demand network infrastructure capability efficiently collect process cache share deliver data instead simple transmission network design show requirement energy efficiency availability high performance dataaware intelligence meet requirement adopt informationcentric networking icn approach data retrieved name innetwork caching utilized however typical existing icn architecture content centric network ccn efficiently utilize cache data sharing onpath caching strategy network information netinf demonstrates resolution latency data retrieval design efficient effective icn architecture big data sharing combine strong point ccn netinf information island iois management plane utilized direct data retrieval global data discovery respectively provide reference architecture propose aggregatable namebased routing anbr naturally enable consumer retrieve closest copy information network piece data cached one ioi greatly improves efficiency cache usage consumer first try retrieve data local ioi try globally retrieve closest ioi holding copy data necessary investigate impact key factor ioi size energy consumption anbr show energy consumption first decrease increase ioi size increase optimized ioi size found deployment furthermore relation optimized ioi size average retrieval time data result show optimized ioi size increase average retrieval time increase ,2
BD_83,intelligence transportation system vehicular network attracted research community recent year generate big data traffic however collection application big traffic data limited privacy people generate data besides datadrivenbased need information could reflect one type vehicle specific intersection section road network rather inidual vehicle overall intelligent analysis data fusion multisource traffic data play important role reduce phenomenon privacy disclosure ensure quality data result complete method multisource traffic data analyzing processing proposed including data analysis method based spatiotemporal regression model data fusion method evidence theory based confidence tensor finally practical data used conform way proposed result show implicit privacy information removed also higher accuracy proceed data ,2
BD_84,dramatic growth cloud offering heterogeneous data information discover potentially valuable information big history behavior data design intelligent recommendation technique become important due dynamic cloud environment behavior qos quality performance cloud service sensitive contextual information time location however consideration time location information brings increase order rating matrix data sparsity problem view challenge propose spatialtemporal aware intelligent recommendation method based distributed tensor factorization address problem first time location information introduced recommendation model distinguishing timesensitive qos metric regionsensitive qos metric stable qos metric deal sparse rating data time slot region clustered respectively highorder tensor factorization technique applied mine latent factor among user service time information location information moreover improve scalability recommendation model big data environment fast distributed asynchronous sgd stochastic gradient descent mechanism employed get good balance convergence speed prediction accuracy finally experiment based realworld data set big synthetic data set conducted validate effectiveness scalability proposal experimental result show proposal achieves good balance recommendation accuracy scalability ,2
BD_85,world witnessing unprecedented growth cyberphysical system cps foreseen revolutionize world via creating service application variety sector environmental monitoring mobilehealth system intelligent transportation system information communication technology sector experiencing significant growth data traffic driven widespread usage smartphones tablet video streaming significant growth sensor deployment anticipated near future expected outstandingly increase growth rate raw sensed data cps taxonomy via providing broad overview data collection storage access processing analysis compared survey paper first panoramic survey big data cps objective provide panoramic summary different cps aspect furthermore cps requires cybersecurity protect malicious attack unauthorized intrusion become challenge enormous amount data continuously generated network thus also provide overview different security solution proposed cps big data storage access analytics also discus big data meeting green challenge context cps ,2
BD_86,big data characteristic volume variety cause huge storage communication overhead traditional encryption system high computational complexity effectively implement secure storage big data order solve problem big data secure storage scheme based compressed sensing csbdcss proposed first primary encryption plaintext data realized data combined crossover random permutation method securityenhanced c used compress reencrypt data reduce space overhead achieve secure storage aiming problem key matrix traditional c algorithm vulnerable attack hierarchical security key matrix generation scheme proposed expanding secret key space hierarchical security protection sensitive data different level realized concept pseudohomomorphism encryption proposed computation based ciphertext realized pseudohomomorphism encryption improve efficiency data analysis basis security adaptive secret keyupdating mechanism designed automatically update key csbdcss system avoid security risk caused repeated key experimental result show proposed scheme achieve efficient data compression secure encryption storage ,2
BD_87,research interest spanning numerous domain increasingly rely upon computational system store process largeitalicvolumeitalicofitalicvariableitalicdata stored highitalicvelocityitalic–representing big data problem particularly notable domain ubiquitous pervasive computing domain increasingly relies storage retrieval sensor data enable outcome predictive analytics activity recognition several current big data platform exist however range deficiency including lack generic interoperability agnostic sensor absence feature supporting academic research due deficiency custom research oriented high performance big data platform devised implemented platform calleditalicsensorcentralitalicand presented sensorcentral provides framework enables interoperability large range agnostic sensor device whilst simultaneously providing feature support research research supporting feature include facility define experiment ability annotate experimental instance via purposebuilt mobile application integrated machine learning functionality facility export data set rulebased classification extensible platform flagship implementation platform operation month university research group successfully integrated range sensor variety manufacturer implementation currently store million record central several research industrial project future integrate platform data initiative enabling collaboration international community researcher ,2
BD_88,era big data demand secure data storage rapidly increasing accelerate complex encryption computation specific instruction hardware accelerator adopted large number scenario however hardware accelerator effective especially small volume data due induced invocation cost aesni intel®advanced encryption standard instruction energy efficiency big data satisfy ersity performanceenergy requirement intensive data encryption collaborative solution proposed proposed feasible hardwaresoftware codesign methodology based stack file system ecryptfs quick assist technology named adaptive crypto acceleration secure data storage acasds acasds able choose optimal encryption solution dynamically according file operation mode request character adjustable parameter asinlineformulatexmath notationlatex $ \alpha $ texmathinlineformulainlineformulatexmath notationlatex $ \beta $ texmathinlineformula provided scheme provide better adaptability tradeoff choice encryption computation evaluation show acasds get % – % performance improvement bigdata block compared software hardware acceleration furthermore methodology provides wide range practical design concept research field ,2
BD_89,big data becoming major focus industry academia requiring drastic change aspect computer system order store process transfer big data network fundamental problem efficiently transfer big data since performance affected several factor path bandwidth scheduled start time besteffort algorithm longer applicable may satisfy deadline requirement request consider problem scheduling flexible bandwidth allocation bigdata transfer deadline constraint flexible bandwidth allocation bandwidth allocated request dynamically adjusted time transfer develop optimization programming formulation provides admission scheduling decision bandwidth allocation path selection accepted request formulation aim maximizing acceptance guaranteeing deadline constraint transfer request due complex nature optimization problem develop twophase heuristic algorithm namelyitalicdeadlineaware flexible bandwidth allocation bigdata transfersitalicdafba develop two scheduling approach dafba batch scheduling used every time interval dynamic scheduling used upon every request arrival evaluate performance proposed algorithm comprehensive simulation two routing scenario precomputed path scenario loadbased routing scenario result show proposed algorithm performs close optimal solution outperforms baseline algorithm term rejection ratio amount data transferred ,2
BD_90,nowadays big data analytics widely applied addressing growing cybercrime threat however energy consumption explosive increasing fast growth big data processing anticybercrime energyefficient framework big data application proposed reduce energy consumption satisfying deadline constrains first problem energyefficient task scheduling single spark modeled integer program design energyefficient task scheduling algorithm minimize energy consumption big data application spark avoid servicelevel agreement violation execution time propose optimal scheduling algorithm deadline constrains tradingoff execution time energy consumption experiment spark cluster performed determine energy consumption execution time several workload hibench benchmark suite algorithm consume le energy average fifo fair deadline optimal algorithm able find near optimal task schedule trade energy consumed response time benefit small shuffle partition ,2
BD_91,one biggest concern big data privacy however big data privacy still early stage believe forthcoming solution theory big data privacy root place research output privacy discipline motivated factor extensively survey existing research output achievement privacy field application theoretical angle aiming pave solid starting ground interested reader address challenge big data case first overview battle ground defining role operation privacy system second milestone current two major research category privacy data clustering privacy framework third discus effort privacy perspective different discipline respectively fourth mathematical description measurement modeling privacy presented summarize challenge opportunity promising topic end hoping shed light exciting almost uncharted land ,2
BD_92,apache spark hadoop source framework big data processing adopted many company order implement reliable big data system satisfy processing target completion time accurate resource provisioning execution time estimation needed time estimation resource minimization scheme spark hadoop system presented proposed model probability failure estimation accurately formulate characteristic real big data operation experimental result show proposed spark adaptive failurecompensation hadoop adaptive failurecompensation scheme improve accuracy resource provision considering failure event improves scheduling success rate big data processing task ,2
BD_93,era big data traditional industrial mobile wireless network effectively handle requirement mobile wireless big data network arising spatiotemporal change node traffic load perspective load balancing energy efficiency industrial big data ibd brings transmission challenge industrial wireless mobile network iwmns previous research work considered dynamic change related traffic mobility iwmns ibd technique propose novel seconddeployment sleepscheduling strategy sd balancing load increasing energy efficiency taking dynamic nature network consideration sd ided two stage first stage change traffic every network grid maximum traffic load different time calculated big data analysis technique second stage seconddeployment method cluster head node chns based grid maximum traffic load adopted save energy based position traffic state sleepwake scheduling presented chns simulation result verify effectiveness methodology save energy obtain traffic balance efficient obtained traditional method ,2
BD_94,rapid development information & ampamp communication technology led wide popularity mobile device helped improve business efficiency enabled simple mobility small light device convenience available anytime anywhere cyberphysicalsocial big data many ongoing study mobile cloud computing mcc overcome limited computing capability storage capacity internal battery limitation taking advantage popularity mobile device processing cyberphysicalsocial big data mcc consists serviceoriented architecture agentclient architecture collaborative architecture splitting allocation critical factor allocation technique considering performance resource mobile device studied note however problem reallocation due continuous battery consumption since study consider performance resource mobile device time allocation take account performance resource remaining battery power proposes allocation mechanism jam battery consumption minimization cyberphysicalsocial big data processing mcc continuously reflects battery consumption rate process job mobile device without external cloud server collaborative architecturebased mcc environment jam allocates job considering periodic measurement battery consumption surplus resource minimize problem reallocation due battery rundown mobile device design implement system verifying jam demonstrated processing speed increased mcc environment cyberphysicalsocial big data ,2
BD_95,today awash flood data coming different data generating source wireless sensor network wsns one big data contributor data collected unprecedented scale unfortunately much data interest meaningless redundant hence data reduction becoming fundamental operation order decrease communication cost enhance data mining wsns propose twolevel data reduction approach sensor network first level operated sensor node consists compressing collected data pearson coefficient second level executed intermediate node eg aggregator cluster head objective second level eliminate redundant data generated neighboring node two adapted clustering method ekmeans topk simulation real experiment real telosb sensor show relevance approach term minimizing big data collected wsns enhancing network lifetime compared existing technique ,2
BD_96,advanced unsupervised learning technique emerging challenge big data era due increasing requirement extracting knowledge large amount unlabeled heterogeneous data recently many effort unsupervised learning done effectively capture information heterogeneous data however huge time consumption obstructs application big data analytics scenario enormous amount heterogeneous data provided realtime learning strongly demanded address problem proposing fast unsupervised heterogeneous data learning algorithm namely twostage unsupervised multiple kernel extreme learning machine tumkelm tumkelm alternatively extract information multiple source learns heterogeneous data representation closedform solution enables extremely fast speed justified theoretical evidence tumkelm low computational complexity stage iteration two stage converged finite step experimentally demonstrated reallife data set tumkelm gain large efficiency improvement compared three stateoftheart unsupervised heterogeneous data learning method time achieves comparable performance term effectiveness ,2
BD_97,nextgeneration wireless network evolving complex system ersified requirement heterogeneity application device network network operator need make best available resource example power spectrum well infrastructure traditional networking approach ie reactive centrallymanaged onesizefitsall approach conventional data analysis tool limited capability space time competent anymore satisfy serve future complex network regarding operation optimization cost effectively novel paradigm proactive selfaware selfadaptive predictive networking much needed network operator access large amount data especially network subscriber systematic exploitation big data dramatically help making system smart intelligent facilitates efficient well costeffective operation optimization envision datadriven nextgeneration wireless network network operator employ advanced data analytics machine learning ml artificial intelligence discus data source strong driver adoption data analytics role ml artificial intelligence making system intelligent regarding selfaware selfadaptive proactive prescriptive set network design optimization scheme presented concerning data analytics concludes discussion challenge benefit adopting big data analytics ml artificial intelligence nextgeneration communication system ,2
BD_98,large amount sensor data frequently generated streamed sensor deployed various building forest application area many area one difficulty managing velocity volume big sensor data still providing low time latency support data analysis data aggregation reduce volume big sensor data however data aggregation fundamental yet timeconsuming operation wireless sensor network wsns particularly highdensity wsns therefore researcher started focusing minimizing latency data aggregation proven nphard problem proposes clusterbased distributed data aggregation scheduling algorithm distributed multipower multichannel dmpmc minimize data aggregation latency multichannel multipower wsns save energy low transmission power used packet transmission inside cluster high power used packet transmission among cluster simulation conducted compare dmpmc best centralized algorithm single channel named epa best distributed algorithm single channel named cluddas best algorithm multichannels named multichannel result show dmpmc algorithm proposed achieves lowest average latency ,2
BD_99,big data growth biomedical healthcare community accurate analysis medical data benefit early disease detection patient care community service however analysis accuracy reduced quality medical data incomplete moreover different region exhibit unique characteristic certain regional disease may weaken prediction disease outbreak streamline machine learning algorithm effective prediction chronic disease outbreak diseasefrequent community experiment modified prediction model reallife hospital data collected central china overcome difficulty incomplete data latent factor model reconstruct missing data experiment regional chronic disease cerebral infarction propose convolutional neural network cnnbased multimodal disease risk prediction algorithm structured unstructured data hospital best knowledge none existing focused data type area medical big data analytics compared several typical prediction algorithm prediction accuracy proposed algorithm reach % convergence speed faster cnnbased unimodal disease risk prediction algorithm ,2
BD_100,internet thing technology widely used water traffic research many critical waterway world becoming crowded due many factor waterway environment invisibility variability uncertainty accurate water depth information necessary improve navigation safety water depth information electronic chart updated timely way actual water depth unpredictable factor threatens safety vessel waterway environment based shorebased network ship navigation data big data integrated vessel navigation environment real time scheme quickly accurately construct vessel safety navigation depth reference map contains appropriate channel water depth information effective scheme based automated identification system ai data increase travel safety crowded waterway ai data include rich maritime traffic information static dynamic information vessel waterway extracted processed big realtime ai data based extensive actual experiment apply data mining technique extract waterway depth information draftdepth vessel trajectory based ai data data collected vessel location nantong port jiangsu province china meizhou bay waterway fujian province china hermite interpolation scheme used patch trajectory vessel bp neural network model introduced predict maximum vessel draft clustering data fusion method employed construct vessel safety navigation depth reference map according cluster area vessel trajectory draft information experimental result demonstrate vessel safety navigation depth reference map accurately reflects current water depth profile channel provide accurate timely channel waterdepth information vessel navigation maritime supervision proposed scheme also provide reference trajectory data processing mining ,2
BD_101,pervasive nature big data technology witnessed industry service everyday life given rise emergent datafocused economy stemming many aspect industrial application richness vastness service creating unprecedented research opportunity number industrial field including health urban study economics finance social science geography moving towards era & ltitalic & gtbig data service & ltitalic & gt deployed multiscale complex distributed architecture service formed highlevel computational intelligence based emerging analytical technique big data analytics web analytics context computational intelligence employ software tool advanced analytics discipline data mining predictive analytics machine learning time becomes increasingly important anticipate technical practical challenge identify best practice learned experience special session included nine paper brief summary presented follows ,2
BD_102,internet thing iot widely used various application domain including smart city environment monitoring intelligent transportation system thousand interconnected iot device produce enormous volume data termed big data however privacy protection become one biggest problem progress big data personal privacy usually challenged development technology focus privacy protection location trajectory data collected intelligent transportation system first demonstrate moving preference iniduals exploited perform reidentification attack may cause serious damage identity privacy user address reidentification problem trajectory anonymity model degree correlation parking location iniduals precisely characterized concept location frequencyinverse frequency lfiuf short propose anonymizing method replace parking location kcorrelation region method provides novel anonymity solution publishing trajectory data achieves better trade privacy utility finally run set experiment realworld data set demonstrate effectiveness method ,2
BD_103,gurantee security privacy patient physiological data wirelss body area network wbans important secure communication personal digital assistance held wbans client application provider medical institution physician hospital physiological data large traditional method process efficiently securely thus big data service needed existing anonymous authentication scheme wbans consider malicious wbans client sends false message cheat application provider cause medical accident trace real identity client punish order overcome issue efficient certificateless conditional privacypreserving authentication scheme wbans big data service proposed due proposed scheme based big data capability proposed wbans system better traditional wbans improve performance proposed scheme support batch authentication multiple client significantly reduces computational overhead application provider moreover proposed scheme provides anonymity unlinkability mutual authentication traceability session key establishment forward secrecy attack resistance simulation experiment demonstrates proposed scheme wbans need le computational time recent scheme ,2
BD_104,fastgrowing healthcare big data play important role healthcare providing healthcare big data comprise data different structured semistructured unstructured source data source vary term heterogeneity volume variety velocity value traditional framework algorithm tool technique fully capable handling therefore framework required facilitates collection extraction storage classification processing modeling vast heterogeneous volume data proposes healthcare big data framework voice pathology assessment vpa case proposed vpa system two robust feature mpeg lowlevel audio interlaced derivative pattern used processing voice speech signal machine learning algorithm form support vector machine extreme learning machine gaussian mixture model used classifier experiment proposed vpa system show efficiency term accuracy time requirement ,2
BD_105,introduces novel big feature data analytics scheme integration toward data analytics decision making scheme split combine approach linear discriminant analysis lda algorithm termed sclda proposed sclda replaces full eigenvector decomposition lda much cheaper eigenvector decomposition smaller submatrices recombines intermediate result obtain exact reconstruction original algorithm splitting decomposition applied recursively obtain multistage sclda algorithm smaller submatrices computed parallel reduce time complexity big data application approach discussed lda algorithm variation ldaqr suitable analytics big feature data set projected data vector lda subspace integrated toward decisionmaking process involving classification experiment conducted realworld data set confirm approach allows lda problem ided sizereduced subproblems solved parallel giving exact reconstruction original ldaqr ,2
BD_106,webdelivered clinical trial generate big complex data help untangle heterogeneity treatment effect unsupervised learning method widely applied however identifying valid pattern priority challenging issue method built upon previous research multiple imputation mibased fuzzy clustering validation proposes mibased visualizationaided validation index mivoos determine optimal number cluster big incomplete longitudinal webtrial data inflated zero different recently developed fuzzy clustering validation index mivoos us suitable overlap separation measure webtrial data depend choice fuzzifiers widely used xie beni xb index optimizing view angle projection sammon mapping optimal projectionguided mivoos obtained better visualize verify pattern conjunction trajectory pattern compared xb vos newly proposed mivoos show robustness validating big webtrial data different missing data mechanism real simulated webtrial data ,2
BD_107,protect cyber security privacy critical design security practical key encryption scheme today big data cloud computing bring unprecedented opportunity also fundamental security challenge big data face many security risk collection storage data brings serious problem regarding disclosure private data challenging achieve security privacy protection big data environment thus meet growing demand key encryption environment proposed singlebit key encryption scheme based variant learning parity noise lpn extended multibit key encryption scheme proved correctness chosen plaintext attack security proposed method scheme solved encoding error rate problem existing key scheme based lpn encoding error rate scheme negligible ,2
BD_108,industry make factory smart applying intelligent information processing approach communication system futureoriented technique however high complexity automation flexibility intelligent factory bring challenge reliability safety industrial big data generated multisource sensor intercommunication system externalrelated information might provide solution predictive maintenance improve system reliability put forth attribute industrial big data processing actively explores industrial big data processingbased predictive maintenance novel framework proposed structuring multisource heterogeneous information characterizing structured data consideration spatiotemporal property modeling invisible factor would make production process transparent eventually implement predictive maintenance facility energy saving industry era effectiveness proposed scheme verified analyzing multisource heterogeneous industrial data remaining life prediction key component machining equipment ,2
BD_109,explosive increasing social medium data web created promoted development social medium big data mining area welcomed researcher academia industry sentiment computing news event significant component social medium big data also attracted lot research could support many realworld application opinion monitoring government news recommendation website however existing sentiment computing method mainly based standard emotion thesaurus supervised method scalable social medium big data therefore propose innovative method sentiment computing news event specially based social medium data ie word emoticon news event word emotion association network wean built jointly express semantic emotion lay foundation news event sentiment computation based wean word emotion computation algorithm proposed obtain initial word emotion refined standard emotion thesaurus word emotion hand compute every sentence sentiment experimental result realworld data set demonstrate excellent performance proposed method emotion computing news event ,2
BD_110,smart society increasing demand qualityoriented service infrastructure industrial internet thing iiot paradigm smart urbanization face numerous challenge among secured energy demandside management dsm particular concern iiot render industrial system malware cyberattacks security risk iiot amalgamation big data analytics provide efficient solution challenge proposes secured trusted multilayered dsm engine smart social society iiotbased big data analytics major objective provide generic secured solution smart society iiot environment proposed engine us centralized approach achieve optimum dsm home area network enhance security engine payloadbased authentication scheme utilized relies lightweight handshake mechanism proposed method utilizes lightweight feature constrained application protocol facilitate client monitoring various resource residing server energyefficient manner addition data stream processed big data analytics mapreduce parallel processing proposed authentication approach evaluated netduino plus board yield lower connection overhead memory consumption response time robust defense various malicious attack hand data processing approach tested reliable datasets apache hadoop apache spark verify proposed dm engine test result reveal proposed architecture offer valuable insight smart social society context iiot ,2
BD_111,view influence information incompleteness asymmetry supply chain operation efficiency make big production enterprise object apply blockchain supply chain endogenous risk management research specific operation mechanism application value operation process big production enterprise supply chain information asymmetry fraud problem produce among business subject blockchain decentralized distributed accounting data storage technology blockchain technology resolve business subject fraud problem provide accurate decision information basis business section realize group decision descripted system structure intelligent contract operation mechanism consensus authentication blockchain applying big production enterprise supply chain analyzed case view limitation classical blockchain technology applying big production enterprise supply chain constructed corresponding blockchain data storage mechanism data access mechanism analyzed economics value researching aspect response speed supply accuracy cooperation integrity business interaction economic cost supply quality supply price etc research provide idea model structure developing supply chain area blockchain system promote application research development blockchain specific area ,2
BD_112,current trend medicine regarding issue accessibility quantity quality information quality different compared former decade current state requires method addressing challenge dealing enormous amount data growing web heterogeneous data source sensor social network unstructured data normally referred big data traditional approach enough least although frequently used hybrid architecture past propose architecture process big data including heterogeneous source information defined ontologyoriented architecture core ontology used knowledge base allows data integration different heterogeneous source used natural language processing artificial intelligence method process mine data health sector uncover knowledge hidden erse data source approach applied field personalized medicine diagnosis treatment disease customized patient used telemedicine system case focused diabetes presented prove validity proposed model ,2
BD_113,traditional distance densitybased anomaly detection technique unable detect periodic seasonality related point anomaly occur commonly streaming data leaving big gap time series anomaly detection current era iot address problem novel deep learningbased anomaly detection approach deepant time series data equally applicable nonstreaming case deepant capable detecting wide range anomaly ie point anomaly contextual anomaly discord time series data contrast anomaly detection method anomaly learned deepant us unlabeled data capture learn data distribution used forecast normal behavior time series deepant consists two module time series predictor anomaly detector italictime series predictoritalic module us deep convolutional neural network cnn predict next time stamp defined horizon module take window time series used context attempt predict next time stamp predicted value passed italicanomaly detectoritalic module responsible tagging corresponding time stamp normal abnormal deepant trained even without removing anomaly given data set generally deep learningbased approach lot data required train model whereas deepant model trained relatively small data set achieving good generalization capability due effective parameter sharing cnn anomaly detection deepant unsupervised rely anomaly label time model generation therefore approach directly applied reallife scenario practically impossible label big stream data coming heterogeneous sensor comprising normal well anomalous point performed detailed evaluation algorithm anomaly detection benchmark contain total real synthetic time series experiment show deepant outperforms stateoftheart anomaly detection method case performing par others ,2
BD_114,development brain imaging technology increasing amount magnetic resonance imaging data acquired traditional computational analysis method based single site small sample facing substantial challenge deep learning technology born via artificial intelligence shown powerful ability solve classification problem based big data many study widely used brain imaging classification herein utilized proposed novel deep adding neural network classify sample largest data set brain imaging field collected center proposed method utilizes multiple convolutional layer extract gradient information different orientation combine spatial information two scale via adding operation high accuracy % obtained standard fivefold crossvalidation strategy demonstrating proposed method effectively handle big data classification multiple center compared traditional classification method deep learning architecture proposed method accurate demonstrating stronger power classify data multiple center crosssite classification result prove proposed method robust training data set testing another data set best knowledge first classify neuroimaging data large scale multiple center high accuracy improved performance classification transferable program code proposed method potentially used intelligent medical treatment strategy clinical practice based mobile terminal ,2
BD_115,mobile network posse information user well network information useful making network endtoend visible intelligent big data analytics efficiently analyze network information unearth meaningful insight help machine learning tool utilizing big data analytics machine learning contributes three way first utilize call detail record data detect anomaly network authentication verification anomaly kmeans clustering unsupervised machine learning algorithm effective detection anomaly proceed suitable design resource distribution well fault detection avoidance second prepare anomaly free data removing anomalous activity train neural network model passing anomaly anomaly free data model observe effect anomalous activity training model also observe mean square error anomaly anomaly free data last autoregressive integrated moving average model predict future traffic simple visualization show anomaly free data better generalizes learning model performs better prediction ,2
BD_116,internet thing iots emerged motivate various intelligent application based data collected various thing cloud computing play important role big data processing providing data computing processing service however cloud provider may invade data privacy provide inaccurate data processing result user thus fully trusted hand limited computation resource capability cloud user mostly independently process big data perform verification correctness data processing raise special challenge cloud computing verification especially data stored cloud encrypted form processed satisfying request raised different context current literature still lack serious study research issue propose contextaware verifiable computing scheme based full homomorphic encryption deploying auditing protocol verify correctness encrypted data processing result design four optional auditing protocol satisfy different security requirement performance evaluated compared performance analysis algorithm implementation system simulation result show effectiveness efficiency design pro con protocol also analyzed discussed based rigorous comparison ,2
BD_117,analysing data center energy consumption step toward building reliable infrastructure evidently data center consume large number billion gigabyte information point putting tremendous pressure energy supplier every internet activity involves huge amount data need stored cloud data center somewhere forgetting internet thing application social medium service produce extraordinarily large scale big data require high processing analysis moreover current data center consume % global electricity supply twh power world data center consumed developed intelligent power reduction decision routing protocol iprdr medium scale hybridsoftwaredefined network data center environment proposed iprdr protocol approach dynamically segregate big traffic route high index processing device poweroptimal selected path protocol approach decrease overall power consumption whole network well reduce failure rate device may occur due high level link congestion elevated temperature experimental result show uplink utilization reduced % power consumption level reduced kwday equivalent % operational power addition highraised temperature dropped high range + c° high critical mid + c° high warning effectiveness proposed approach verified experimentally virtualized testbed platform ,2
BD_118,recently big data analytics received important attention variety application domain including business finance space science healthcare telecommunication internet thing iot among area iot considered important platform bringing people process data thingsobjects together order enhance quality everyday life however key challenge effectively extract useful feature massive amount heterogeneous data generated resourceconstrained iot device order provide realtime information feedback endusers utilize dataaware intelligence enhancing performance wireless iot network although parallel advance cloud computing edge computing addressing issue data analytics benefit limitation convergence two computing paradigm ie massive virtually shared pool computing storage resource cloud realtime data processing edge computing could effectively enable data analytics wireless iot network regard propose novel framework coordinated processing edge cloud computingprocessing integrating advantage platform proposed framework exploit networkwide knowledge historical information available cloud center guide edge computing unit towards satisfying various performance requirement heterogeneous wireless iot network starting feature key enablers challenge big data analytics provide various synergy distinction cloud edge processing importantly identify describe potential key enablers proposed edgecloud collaborative framework associated key challenge interesting future research direction ,2
BD_119,internet thing iot set become one key technological development time provided able realize full potential number object connected iot expected reach billion due massive influx erse object emerging progressively iot hence expected major producer big data sharing collaboration data resource would key enabling sustainable ubiquitous environment smart city society timely fusion analysis big data acquired iot source enable highly efficient reliable accurate decision making management ubiquitous environment would grand future challenge computational intelligence would play key role challenge number survey exist data fusion however mainly focused specific application area classification aim literature data fusion iot particular focus mathematical method including probabilistic method artificial intelligence theory belief specific iot environment distributed heterogeneous nonlinear object tracking environment opportunity challenge mathematical method environment given future development including emerging area would intrinsically benefit data fusion iot autonomous vehicle deep learning data fusion smart city discussed ,2
BD_120,smart city advancement driving massive transformation healthcare largest global industry driver include increasing demand ubiquitous preventive personalized healthcare provided reduced risk cost mobile cloud computing could potentially meet future healthcare demand enabling anytime anywhere capture analysis patient data however network latency bandwidth reliability among many challenge hindering realization nextgeneration healthcare proposes ubiquitous healthcare framework ubehealth leverage edge computing deep learning big data highperformance computing hpc internet thing iot address aforementioned challenge framework enables enhanced network quality three component four layer deep learning big data hpc used predict network traffic turn used cloudlet network layer optimize data rate data caching routing decision application protocol traffic flow classified enabling network layer meet application communication requirement better detect malicious traffic anomalous data clustering used identify different kind data originating application protocol proof concept ubehealth system developed based framework detailed literature used capture design requirement proposed system system described detail including algorithmic implementation three component four layer three widely used data set used evaluate ubehealth system ,2
BD_121,cloud fog computing established convenient widely adopted approach computation offloading raw data generated edge device internet thing iot context collected processed remotely vertical offloading pattern however typically take account increasingly pressing time constraint emerging iot scenario numerous data source including human agent ie social iot continuously generate large amount data processed timely manner big data solution could applied respect provided networking issue limitation related connectivity edge device properly addressed although edge device traditionally considered resourceconstrained limitation refer energy networking memory capacity whereas evergrowing processing capability already sufficient effectively involved actual big data processing context role human agent longer limited passive data generation also include voluntary involvement relatively complex computation way user share personal computational resource ie mobile phone support collaborative data processing thereby turning existing iot global cyberphysicalsocial system cps extent proposes novel iotcpss data processing pattern based stream processing technology aiming distribute workload among cluster edge device involving mobile node shared contributor voluntary basis paving way cluster computing edge experiment intelligent surveillance system deployed edge device cluster demonstrate feasibility proposed approach illustrating distributed inmemory data processing architecture effective ,2
BD_122,development latest technology change market demand wireless multisensor system widely used multisensors integrated way produce overwhelming amount data termed big data multisensor system creates several challenge include getting actual information big data high accuracy increasing processing efficiency reducing power consumption providing reliable route toward destination minimum bandwidth shortcoming overcome exploiting novel technique clustering data fusion coding scheme moreover data fusion clustering technique proven architecture used efficient data processing resultant data le uncertainty providing energyaware routing protocol limited resource multisensor system challenging reduce energy consumption survive network longer period keeping challenge view present novel technique hybrid algorithm clustering cluster member selection wireless multisensor system selection cluster head member node proposed data fusion technique used partitioning processing data proposed scheme efficiently reduces blind broadcast message also decrease signal overhead result cluster formation afterward routing technique provided based layered architecture proposed layered architecture efficiently minimizes routing path toward base station comprehensive analysis performed proposed scheme stateoftheart centralized clustering distributed clustering technique result shown proposed scheme outperforms competitive algorithm term energy consumption packet loss cluster formation ,2
BD_123,softwaredefined network sdn offer advantageous feature programming network run time decoupling control plane data plane centralized better forwarding decision attain maximum throughput relatively le latency large network captured realtime big data produced network big data revolutionizing modern computer science world analyze extremely large datasets predict future requirement therefore would useful embed intelligence system power sdn programmed network run time ryu controller dump network traffic engineer accordingly proposed methodology taking intelligent decision traffic engineering sdn result shown sdn leverage big data decrease latency time adding program controller sdn algorithm presented maximize bandwidth utilization posse higher throughput shaping traffic found result proposed methodology applying intelligence traffic management sdn outperforms without intelligence decision making ,2
BD_124,hadoop framework evolved manage big data cloud hadoop distributed file system mapreduce vital component framework provide scalable faulttolerant big data storage processing service lower cost however hadoop provide robust authentication mechanism principal authentication fact existing stateoftheart authentication protocol vulnerable various security threat maninthemiddle replay password guessing stolenverifier privilegedinsider identity compromization impersonation denialofservice onlineoffline dictionary chosen plaintext workstation compromization serverside compromisation attack beside threat stateoftheart mechanism lack address serverside data integrity confidentiality issue addition existing authentication protocol follow singleserverbased authentication strategy fact originates single point failure single point vulnerability issue address limitation propose faulttolerant authentication protocol suitable hadoop framework called efficient authentication protocol hadoop heap heap alleviates major issue existing stateoftheart authentication mechanism namely operatingsystembased authentication passwordbased approach delegated tokenbased scheme respectively presently deployed hadoop heap follows twoserverbased authentication mechanism heap authenticates principal based digital signature generation verification strategy utilizing advanced encryption standard elliptic curve cryptography security analysis formal security broadly accepted realorrandom ror model informal nonmathematical security show heap protects several wellknown attack addition formal security verification widely used automated validation internet security protocol application ensures heap resilient replay maninthemiddle attack finally performance contemplates overhead incurred heap reasonable also comparable existing stateoftheart authentication protocol high security comparable overhead make heap robust practical secure access big data storage processing service ,2
BD_125,significant application energy smart grid complicated interconnected power grid involves sensor deployment strategy smart meter realtime data processing continuously generates data large volume high velocity erse variety first give brief introduction big data smart grid big data application smart grid scenario recent study development summarized context integrated architecture key enabling technology meanwhile security issue specifically addressed finally introduce several typical big data application point future challenge energy domain ,2
BD_126,recently big data bd seen tremendous growth volume magnitude complexity example data include navigation map mobile phone trajectory social medium poststweets normally humongous data known spatial bd sbd handling routing sbd datasets become challenging movement object human vehicle highly dynamic random focus different aspect related generation routing handling bd sbd multifold first viewpoint various researcher bd part also includes differentiation bd sbd based several example second focus social medium eapplications considered biggest contributor generating large volume spatial data third highlight routing perspective bd sbd including various interesting strategy route large traffic volume generated moving object fourth discus different technique big data analysis context moving object finally highlight important issue challenge domain bd sbd ,2
BD_127,address bigdata analysis method estimating driving range electric vehicle ev allowing driver overcome range anxiety first estimating approach project life battery pack cycle ie year km based data collected cyclelife test approach merit simplicity addition considers several critical issue occur inside battery pack dependence internal resistance stateofhealth subsequently describe driving pattern analysis ev machinelearning approach namely growing hierarchical selforganizing map cluster collected ev big data contains analysis energy consumption driving range estimation ev including powertrain simulation driving behavior analysis experimental result including simulating battery degradation analysis driving behavior demonstrate feasible solution improving driving range estimation ev big data ,2
BD_128,number web service increased dramatically last year resulted increase volume candidate service task composition system led growth variety nonfunctional property selection resulting uncertainty veracity issue among property severely affected nphard aspect selection despite consumer many area would like access variety selection method linear programming dynamic programming technique additional problem composition length number task workflow increased incorporation research domain data science trending composition issue challenging computational power existing method concern opened door research involving big data space propose flexible distributed selection algorithm facilitates heterogeneousselection method satisfy multiobjective composition requirement rather rigid specific composition requirement however serviceselection process big data space inevitably increase traffic congestion caused increased volume internal communication particularly external traffic zipf pareto phenomenon internal traffic shuffling address concern propose solution case experiment demonstrate proposed trafficefficient multiobjective method well behaved selecting service big data space ,2
BD_129,cloud computing emerged powerful paradigm delivering dataintensive service internet cloud computing enabled implementation success big data recent phenomenon handling huge data generated different source competing cloud made challenging select cloud provider guarantee quality cloud qocs also cloud provider claim guaranteeing qocs exaggerated marketing purpose hence often trusted therefore comprehensive trust model necessary evaluate qocs prior making selection decision propose multidimensional trust model big data workflow processing different cloud evaluates trustworthiness cloud provider based uptodate cloud resource capability reputation evidence measured neighboring user recorded personal history experience cloud provider ultimate goal ensure efficient selection trustworthiness cloud provider eventually guarantee high qocs fulfills key big data workflow requirement various experiment conducted validate proposed model result show model capture different component trust ensures high qocs effectively adapts dynamic nature cloud ,2
BD_130,present firsttime literature focused significance big data generated nanosensors nanocommunication network intended future healthcare biomedical application aimed toward development modern smart healthcare system enabled p ie predictive preventive personalized participatory capability perform diagnostics monitoring treatment analytical capability produced substantial amount data gathered network aid exploiting practical intelligence learning capability could integrated conventional medical health data leading efficient decision making also proposed big data analytics framework gathering intelligence form healthcare big data required futuristic smart healthcare address relevant problem exploit possible opportunity future application finally challenge future direction researcher evolving healthcare domain presented ,2
BD_131,background cyberphysical system industry intelligent manufacturing become orientation produced revolutionary change compared traditional manufacturing environment intelligent manufacturing characteristic highly correlated deep integration dynamic integration huge volume data accordingly still face various challenge summarize analyze current research status domestic aboard including industrial big data collection modeling intelligent product line based ontology predictive diagnosis based industrial big data group learning product line equipment product line reconfiguration intelligent manufacturing based research status problem propose research strategy including acquisition scheme industrial big data environment intelligent ontology modeling deduction method based intelligent product line predictive diagnostic method production line based deep neural network deep learning among device based cloud supplement selforganized reconfiguration mechanism based supplement cloud view accelerate implementation smart factory ,2
BD_132,explosive data growth smart city making domain big data hot topic knowledge extraction nontaxonomic relation refer relation concept pair except isa relation important part knowledge graph toward big data smart city multiphase correlation search framework automatically extract nontaxonomic relation domain document different kind semantic information used improve performance system first inspired work network representation propose semantic graphbased method combine structure information semantic graph context information term together nontaxonomic relationship identification second different semantic type verb set extracted based dependency syntactic information ranked act nontaxonomic relationship label extensive experiment demonstrate efficiency proposed framework f value reach % identification nontaxonomic relationship total precision nontaxonomic relationship label extraction % % nontaxonomic relation provided good label hope article provide useful way domain big data knowledge extraction smart city ,2
BD_133,nowadays telemedicine emerging healthcare healthcare professional diagnose evaluate treat patient telecommunication technology diagnose evaluate patient healthcare professional need access electronic medical record emr patient might contain huge multimedia big data including xrays ultrasound ct scan mri report efficient access supporting mobility healthcare professional well patient emr need kept big data storage healthcare cloud spite popularity healthcare cloud face different security issue instance data theft attack considered one serious security breach healthcare data cloud focus given secure healthcare private data cloud fog computing facility end triparty oneround authenticated key agreement protocol proposed based bilinear pairing cryptography generate session key among participant communicate among securely finally private healthcare data accessed stored securely implementing decoy technique ,2
BD_134,ehealthcare promise next big wave healthcare offer advantage benefit imaginable patient however current ehealthcare system yet fully developed mature thus lack degree confidentiality integrity privacy trust necessary widely implemented two primary aspect operational healthcare enterprise quality healthcare service patient trust healthcare enterprise trust intertwined issue like confidentiality integrity accountability authenticity identity data management name privacy remains one biggest obstacle ensuring success ehealthcare solution winning patient trust indirectly cover security concern addressing privacy concern requires addressing security issue like access control authentication nonrepudiation accountability without endtoend privacy ensured achieving privacy point data collection wireless sensor network incorporating internet thing communication link data storage access huge undertaking requires extensive privacy requirement compounded fact data handled enterprise extremely personal private nature mismanagement either intentionally unintentionally could seriously hurt patient future prospect ehealthcare enterprise research carried order address privacy concern homogenous nature focus failure certain part ehealthcare enterprise fully address aspect privacy middle ongoing research implementation gradual shift occurred moving ehealthcare enterprise control away organizational level toward level patient intended give patient control authority decision making regarding protected health informationelectronic health record lot work effort necessary order better ass feasibility major shift ehealthcare enterprise existing research naturally ided basis technique used include data anonymizationpseudonymization access control mechanism primarily stored data privacy however result giving back seat certain privacy requirement accountability integrity nonrepudiation identity management review research carried regard explores whether research offer possible solution either patient privacy requirement ehealthcare possibility addressing technical well psychological privacy concern user ,2
BD_135,novel empirical data analysis methodology based random matrix theory rmt time series analysis proposed power system among ongoing research study big data power system application strong necessity mathematical tool describe analyze big data used rmt model empirical data also treated time series proposed method extends traditional rmt application nongaussian distribution environment three case study ie power equipment condition monitoring voltage stability analysis lowfrequency oscillation detection illustrate potential application value proposed method multisource heterogeneous data analysis sensitive spot awareness fast signal detection unknown noise pattern result showed empirical data power system modeled following rmt time series high sensitivity dynamically characterized system state well observability efficiency system analysis compared conventional equationbased method ,2
BD_136,advent age big data people collect rich erse data wide variety collection device internet thing knowledge hidden large data useful valuable frequent pattern mining basic method data mining applied every aspect society however application traditional frequent pattern mining method big data involves bottleneck due large number result set bottleneck make difficult produce practical value production life therefore mining representative pattern set proposed however existing algorithm select representative pattern mining frequent pattern set framework make runtime difficult evaluate large data environment solve abovementioned problem present online representative patternset parallelmining algorithm parallel mapreduce framework algorithm us horizontal segmentation process database applies online mining algorithm mine locally represented pattern set small database finally several performance optimization strategy proposed shown numerous experiment actual dataset algorithm proposed improves time efficiency one order magnitude several optimization strategy reduce execution time varying degree ,2
BD_137,fog computing disruptive technology big data analytics area smartphone user organization cellular service support decisionmaking disaster scenario data collected nevertheless regular communication infrastructure damaged disaster ntt provided easily deployable solution construct emergency communication network ecn ecns slow propagating big data due limited transmission capability one major issue efficiently integrating data processing ecn realize effective data processing transmission disaster scenario present—a detailed mathematical model represent data processing transmission ecn fog network nphard proof problem optimizing overall delay novel algorithm minimize overall delay wirelesslynetworked disaster area run realtime evaluated system across various transmission speed processing speed network size also tested calculation time accuracy percent age error system evaluation found proposed disaster area adaptive delay minimization daadm algorithm showed reduced overall delay various network size compared conventional solution proposed daadm algorithm matched curve genetic algorithm ga even result yield delay small ga daadm one major advantage ga processing time allows daadm implemented realtime system ga solution would take far much time ,2
BD_138,reliable data congestion analytics crowdsourced ehealth network becomes particularly important especially big data era wide adaption ubiquitous crowdsourced healthcare participant since crowdsourced ehealth network intermittent connectivity remote healthcare provider researcher usually wellstudied network model novel network data congestion analytics still big problem intermittent connecting network case data congestion analytics may realized fixing number forwarded copy sometimes suit changing network environment well problem could solved modifying packet forwarding condition dynamically detecting realtime network environment based idea optimized routing algorithm named rsw reduced variable neighborhood searchbased spray wait proposed algorithm node exchange store others buffer status communication based current network environment evaluated quantified realtime threshold spray wait adapts threshold data congestion control simulation show proposed algorithm increase data packet delivery probability optimize overhead ratio dramatically ten time lower standard algorithm ,2
BD_139,today highly intertwined network society demand big data processing framework continuously growing widely adopted model process big data parallel distributed computing document significant progress achieved field distributed computing framework particularly apache hama top level project apache software foundation based bulk synchronous parallel processing comparative study empirical evaluation performed reveal hamas potential efficacy big data application particular benchmark evaluation hamas graph package apache giraph pagerank algorithm result show performance hama better giraph term scalability computational speed however despite great progress number challenging issue continue inhibit full potential hama used large scale also describes challenge analyzes solution proposed overcome highlight research opportunity ,2
BD_140,cyber security context big data known critical problem present great challenge research community machine learning algorithm suggested candidate handling big data security problem among algorithm support vector machine svms achieved remarkable success various classification problem however establish effective svm need define proper svm configuration advance challenging requires expert knowledge large amount manual effort trial error formulate svm configuration process biobjective optimization problem accuracy model complexity considered two conflicting objective propose novel hyperheuristic framework biobjective optimization independent problem domain first time hyperheuristic developed problem proposed hyperheuristic framework consists highlevel strategy lowlevel heuristic highlevel strategy us search performance control selection lowlevel heuristic used generate svm configuration lowlevel heuristic different rule effectively explore svm configuration search space address biobjective optimization proposed framework adaptively integrates strength decompositionand paretobased approach approximate pareto set svm configuration effectiveness proposed framework evaluated two cyber security problem microsoft malware big data classification anomaly intrusion detection obtained result demonstrate proposed framework effective superior compared counterpart algorithm ,2
BD_141,straggler commonly accepted great impact performance big data system however reason cause straggler complicated previous work mostly focus straggler detection scheduling optimization coarsegrained rootcause analysis method fail provide useful insight help user optimize program propose bigroots general method incorporating framework system feature rootcause analysis straggler big data system bigroots analyzes straggler feature big data framework shuffle readwrite byte jvm garbage collection time well system resource utilization cpu io network able detect internal external cause straggler verify bigroots injecting high resource utilization across different system component perform case study analyze different workload hibench experimental result demonstrate bigroots effective identify root cause straggler provide useful guidance performance optimization based root cause identified bigroots workload achieve significant performance improvement % best case optimization ,2
BD_142,internetofthings iot allow healthcare professional remotely monitor patient analyzing sensor output big data analytics sleeping condition one influential factor health however literature lack appropriate simulation tool widely support research recognition sleeping posture proposes agentbased simulation framework simulate sleeper movement simulated smart bed load sensor framework allows one define sleeping posture recognition algorithm compare outcome pose adopted sleeper novel presented absbediot simulator allows user graphically explore result starplots evolution chart final visual representation state bed sensor simulator also generate log text file big data applying offline big data technique source code absbediot example log freely available research repository current approach illustrated algorithm properly recognized simulated sleeping posture average accuracy % accuracy higher one reported existing alternative area ,2
BD_143,security threat economic loss caused network attack intrusion vulnerability motivated intensive study network security normally data collected network system reflect used detect security threat define data network securityrelated data studying analyzing securityrelated data help detect network attack intrusion thus making possible measure security level whole network system obviously first step detecting network attack intrusion collect securityrelated data however context big data g exist number challenge collecting securityrelated data first briefly introduce network securityrelated data including definition characteristic application network data collection provide requirement objective securityrelated data collection taxonomy data collection technology moreover existing collection node collection tool collection mechanism term network data collection analyze based proposed requirement objective toward high quality securityrelated data collection finally discus research issue conclude suggestion future research direction ,2
BD_144,growth prevalence plethora digital device resulted growing volume disparate data potential relevance criminal civil investigation increase data volume opportunity build greater caserelated knowledge discover evidence implication stage digital forensic analysis process growth digital device potentially contribute growth big digital forensic data need practitioner consider wider range data device may relevant investigation process data reduction selective imaging quick analysis coupled automated data extraction give potential undertake analysis growing volume data timely manner outline process bulk digital forensic data analysis including disparate device data research process research data corpus apply process realworld data challenge growing volume device data require forensic practitioner expand ability undertake research newly developed data structure able explain court judge jury investigator ,2
BD_145,today city generate tremendous amount data thanks boom affordable smart device sensor resulting big data creates opportunity develop erse set contextaware service system ensuring smart city service optimized dynamic city environment critical resource smart city rapidly deployed region need region predicted imminent prospective need example crime data analytics may used optimize distribution police medical emergency service however smart city service become dependent data also become susceptible disruption data stream data loss due signal quality reduction due power loss data collection present dynamic network model improving resilience data loss network model identifies statistically significant shared temporal trend across multivariate spatiotemporal data stream utilizes trend improve data prediction performance case data loss dynamic also allow system respond change data stream loss addition information flow network model demonstrated citybased crime rate reported montgomery county md usa resilient network developed utilizing shared temporal trend city provide improved crime rate prediction robustness data loss compared single citybased autoregression maximum improvement performance % silver spring found average improvement % among city high crime rate model also correctly identifies optimal network connection according prediction error minimization citytocity distance designated predictor shared temporal trend crime weather shown strong predictor crime montgomery county ,2
BD_146,era big data artificial intelligence data sharing desirable vigorous development datadriven service improves daily life although data sharing supported certain extent current mechanism technology organization especially potential competitive relationship might refuse share data due worry data sharing improves competitor competitiveness address problem focus competitivenessdriven target winwin provides incentive encourage potentially competing organization share data introducing concept data competitiveness data transaction driving force incentive mechanism based data competitiveness established formulated stackelberg game gradientbased iteration algorithm proposed obtain stackelberg equilibrium solution data sharing incentive problem simulation result substantiate performance data sharing improved significantly proposed scheme ,2
BD_147,era big data recommender system r become effective information filtering tool alleviates information overload web user collaborative filtering cf one successful recommendation technique widely studied various research institution industry applied practice cf make recommendation current active lot user historical rating information without analyzing content information resource however recent year data sparsity high dimensionality brought big data negatively affected efficiency traditional cfbased recommendation approach cf context information time information trust relationship among friend introduced r construct training model improve recommendation accuracy user satisfaction therefore variety hybrid cfbased recommendation algorithm emerged mainly summarize traditional cfbased approach technique used r recent hybrid cfbased recommendation approach technique including latest hybrid memorybased modelbased cf recommendation algorithm finally discus potential impact may improve r future direction aim introducing recent hybrid cfbased recommendation technique fusing social network solve data sparsity high dimensionality provide novel point view improve performance r thereby presenting useful resource stateoftheart research result future researcher ,2
BD_148,big data framework enable company various field build model allow increase profit margin improving decision making different level middle management senior management board attempting boost sale customizing consumer experience based history feedback institution entity also big data coming kind sensor data used detect real time retrospect possible problem eg fraud malfunction supply shortage identify pattern trend organize large volume community electricity consumption data coming smart meter smart plug sensor also data regarding consumer preference order assist dynamically optimize electricity consumption regard develop novel optimization approach reschedules every fifteen min appliance residential consumer reduce consumption peak payment community level consumer send dayahead schedule optimized implemented extent thus monitor electricity consumption via sensor smart meter dynamically adjust schedule case real consumption deviate optimized plan considering appliance constraint consumer preference every fifteen min algorithm evaluates difference optimized schedule actual consumption control operation interruptible appliance stick dayahead schedule much possible ,2
BD_149,bigdatadriven traffic flow prediction system robustness prediction performance depends accuracy timeliness present mapreducebased nearest neighbor nn approach foritalictraffic flow predictionitalicusingitaliccorrelationitalicanalysis tfpc hadoop platform particular develop realtime prediction system including two key module ie offline distributed training odt online parallel prediction opp moreover build parallelinlineformulatexmath notationlatex $ k $ texmathinlineformulanearest neighbor optimization classifier incorporates correlation information among traffic flow classification process finally propose novel prediction calculation method combining current data observed opp classification result obtained largescale historical data odt generate traffic flow prediction real time empirical realworld traffic flow big data leaveoneout cross validation method show tfpc significantly outperforms four stateoftheart prediction approach ie autoregressive integrated moving average naïve bayes multilayer perceptron neural network nn regression term accuracy improved % best case average mean absolute percent error % addition display excellent speedup scaleup sizeup ,2
BD_150,modern society demand radio spectrum resource increasing information carrier wireless transmission data radio signal exhibit characteristic big data term volume variety value velocity uniformly handle radio signal obtain value problem need studied big data processing architecture radio signal presented approach endtoend signal processing based deep learning discussed detail radio signal intelligent search engine used example verify architecture system component experimental result introduced addition application architecture cognitive radio spectrum monitoring cyberspace security introduced finally challenge discussed unified representation radio signal feature distortionless compression wideband sampled data deep neural network radio signal ,2
BD_151,novel modeling method based minbatch gradient descent neural network mgd nn proposed establish adaptive dynamic model turbofan engine large flight envelope establishing high precision engine dynamic model large flight envelope need big training data proposed method adopts mgd algorithm suitable train neural network big training data due consumes much le time update nn parameter dramatically huger training data mgd nn better generalization performance would furthermore regularization strategy also improve generalization performance mgd nn applied finally compared popular support vector regression svr modeling method proposed method adaptive dynamic model turbofan engine validated supersonic cruise envelops result show proposed method much higher precision also le data storage better realtime ability svr method ,2
BD_152,issue high system stability one major obstacle realtime computing fluctuating big data stream stable scheduling important efficient scheduling stream application especially scheduling rescheduled dynamically runtime stable online scheduling strategy makespan guarantee somg discussed includes following feature profiling mathematical relationship system stability response time resource utilization indicating condition meet high system stability acceptable response time objective optimizing structure data stream graph quantifying adjusting vertex graph scheduling data stream graph heuristic critical path scheduling mechanism subject response time constraint rescheduling key vertex dynamically changing critical path graph considering historical information current scheduling maximize system stability response time aware experimental result conclusively demonstrate somg framework higher potential providing enhancement efficient system stability guaranteeing significant response time efficiently effectively make tradeoff high system stability acceptable response time objective big data stream computing environment ,2
BD_153,rapid expansion road traffic vehicle scale citizen face serious life safety risk caused vehicle accident enjoying increasingly convenient life fortunately vehicular ad hoc network vanets provided u important information vehicle big data make u method analyze vehicle traffic accident tackle problem predicting risk vehicle accident propose trichotomy adaboost smote onehot encoding adaboostso algorithm attain vehicle accident risk prediction model predicting accident risk mainly based big data mining analysis reallife accident data firstly experimental dataset reconstructed synthetic minority oversampling technique smote complement missing data encode sample feature onehot code secondly trichotomy adaboost algorithm respectively used train series weak classifier experimental dataset combine strong classifier get prediction model finally extensive simulation result illustrate prediction model trichotomy adaboostso algorithm take area curve auc realtime account risk prediction early warning provides intelligent transportation system driving safety assistance theoretical foundation ,2
BD_154,incomplete data one major kind multidimensional dataset randomdistributed missing node dimension difficult retrieve information type dataset becomes large finding topk dominant value type dataset challenging procedure algorithm enhance process efficient dealing small incomplete data one algorithm make application topk dominating tkd query possible bitmap index guided big algorithm algorithm greatly improves performance incomplete data designed find topk dominant value incomplete big data several algorithm proposed find tkd query skyband based upper bound based algorithm performance also questionable algorithm developed previously among first attempt apply tkd query incomplete data however algorithm suffered weak performance proposes mapreduced enhanced bitmap index guided algorithm mrbig dealing aforementioned issue mrbig us mapreduce framework enhance performance applying topk dominance query large incomplete datasets proposed approach us mapreduce parallel computing approach involving multiple computing node framework separate task several computing node independently simultaneously find result method achieved two time faster processing time finding tkd query result compared previously proposed algorithm ,2
BD_155,present empowering project big data environment aimed helping domestic customer save electricity managing consumption positively achieved improving information received energy bill offering online tool contribution empowering creation novel workflow electricity utility sector regarding implementation data analytics customer fast implementation datamining technique massive datasets big data platform achieve scalability result obtained show empowering customer electrical supplier changing energy habit decrease consumption increase environmental sustainability ,2
BD_156,edge computing network refers paradigm edgeside big data computing network integrates network computing storage business core capability close user internet thing iot data source side edge computing network generated common development cloud computing iot core massive uplink monitoring collection downlink decisionmaking control big data generated intelligent sensing device solving problem low data computing efficiency performance centralized cloud computing model compared traditional cloud computing network edge computing network abundant terminal type frequent data realtime interaction complex transmission network technology system intelligent interconnected business system moreover situation aggravated mobile edge computing eg model proximity increasingly prevalent daily life however ubiquitous feature edge computing network expose network security risk part system facing severe security protection challenge solve linkage disposal minimum cost response complex attack propose attack linkage disposal decisionmaking method edge computing network system based attribute attack graph simplified attribute attack graph constructed network security alarm association falsealarm determination formal correlation analysis performed causal relationship alarm information basis linkage defense strategy decision computing transformed minimum dominance set solution attribute attack graph finally linkage disposal strategy execution point decision algorithm based greedy algorithm designed construct set attack linkage disposal decisionmaking technology optimal defense cost provides powerful guarantee timely effectively active defense ,2
BD_157,recently massification technology adopted large majority world population accumulated tremendous amount data including clinical data clinical data gathered interpreted medical organization order gain insight knowledge useful clinical decision drug recommendation better diagnosis among many us highlight enormous impact big data medical stakeholder patient physician pharmaceutical medical operator healthcare insurer also review different challenge must taken account get best benefit big data available application ,2
BD_158,social internet thing siot support many novel application networking service iot powerful productive way introduced hierarchical framework feature extraction siot big data mapreduced framework supervised classifier model moreover gabor filter used reduce noise unwanted data database hadoop map reduce used mapping reducing big database improve efficiency proposed furthermore feature selection performed filtered data set elephant herd optimization proposed system architecture implemented linear kernel support vector machinebased classifier classify data predicting efficiency proposed result maximum accuracy specificity sensitivity % % % moreover analyzed time memory result compared existing literature ,2
BD_159,extracting valuable information enhance performance forecasting model imbalanced big data requires scalable implementation advanced statistical learning method proposes online mixture model omm applies mach number forecasting treating key variable eg mach number forecasting working condition entire viewing inidual working condition subtask omm separate dense sample sparse one basis subtasks subtask model independently learnt sample reduced volume updated working condition without retaining sample old working condition moreover treestructure ensemble tsefeature subset ensemble f algorithm presented fit nonlinear function subtask model fse local model lowdimensional input feature established nonoverlapping sample subset constructed tse method tsefses reduce volume data also perform distributed computing parallel structure thus advantage learning big data experiment carried measurement data wind tunnel indicate omm tsefses outperforms learning algorithm mach number forecasting meet precision forecasting speed requirement engineering ,2
BD_160,conduct comprehensive application big data machine learning electrical power grid introduced emergence nextgeneration power system – smart grid sg connectivity lie core grid infrastructure provided internet thing iot connectivity constant communication required system also introduced massive data volume demand technique far superior conventional method proper analysis decisionmaking iot integrated sg system provide efficient load forecasting data acquisition technique cost effectiveness big data analysis machine learning technique essential reap benefit complex connected system sg cyber security becomes critical issue iot device data turning major target attack security concern solution also included key information obtained literature tabulated corresponding section provide clear synopsis finding rigorous listed give concise picture area promising future field academic industrial research current limitation viable solution effectiveness ,2
BD_161,layered architecture proposed big datadriven processing management future smart home proposed representational state transfer restbased architecture includes seven layer physical fogcomputing network cloudcomputing session application efficient data exchange processing task future smart home smart home physical layer includes sensing technology smart device smart home monitor home environment resident data sensor sent smart home fogcomputing layer limited data storage processing required data sent cloudcomputing layer smart home network layer cloudcomputing layer provides scalable solution data processing storage processed data cloudcomputing layer provided datadriven service different smart home thirdparty eg smart city application via smart home layer based proposed architecture application utilize session layer restful apis datadriven service smart home proposed smart home architecture provide ubiquitous shared data environment key aspect internet thing iots system ,2
BD_162,clinical practice call reliable diagnosis optimized treatment however human error health care remain severe issue even industrialized country application clinical decision support system cd cast light problem however given great improvement cd past several year challenge widescale application still including decision making cd complicated complexity data regarding human physiology pathology could render whole process timeconsuming loading big data related patient information incompatibility among different health information system make cd information island ie additional input patient information might required would increase burden clinician one popular strategy integration cd directly read electronic health record ehrs analysis however gathering data ehrs could constitute another problem ehr document standard unified addition could different default clinical terminology define input data could cause additional misinterpretation several proposal published thus far allow cd access ehrs via redefinition data terminology according standard used recipient data flow mostly aim specific version cd guideline view problem different way compared conventional approach suggest fundamental change specifically uniform updatable clinical terminology document syntax used ehrs integrated cd facilitated data exchange increase overall data loading efficacy enabling cd read information analysis given time furthermore proposed cd based selflearning dynamically update knowledge model according datastreambased upcoming data set experiment result show system increase accuracy diagnosis treatment strategy design ,2
BD_163,recent year rapid development industrial internet thing rapid growth data become severe challenge precious opportunity faced many industry information society entered era big data feature selection frequently used reduce number feature many application internet thing data high dimensionality involved best knowledge fewer researcher focus physical distribution data anisotropy data characteristic end introduces novel feature selection approach based potential entropy evaluation criterion fmpe fmpe method considers distribution data measuring importance feature data mapped highdimensional space better isibility extending data field generalized multidimensional data field related experiment analysis uci data set face data set show fmpe algorithm effectively eliminate unimportant feature noise feature improve performance classification algorithm high classification accuracy achieved combination selected feature subset variety classifier fmpe algorithm independent specific classifier ,2
BD_164,living standard improve health consciousness enhances healthcare industry become hot spot nowadays society health monitoring system emerge one another recent year however mostly existing system focus logic reasoning ignore factor user emotion regarded important factor impact human health design system big data application emotionaware healthcare bdaeh pay attention logic reasoning emotion computing meanwhile sdn g technology adopted bdahe system improve resource utilization overall network performance system bdaeh system includes following function healthcare data collection healthcare data transmission healthcare data storage healthcare data analysis humanmachine interaction healthcare data generated wearable device sensingless sensor healthcare data regarded foundation expand series data processing healthcare data transmission performed leveraging sdn g technology data center related technology based cloud computing utilized store analyze healthcare data obtains emotion health state user relation emotion illness finally bdaeh system return analysis result user doctor treatment scheme rehabilitation advice presented system expected validly improve healthcare service considering emotion factor ,2
BD_165,vast availability data additional focus health industry increasing number study aim leverage data improve healthcare conducted health data growing increasingly large complex source increased tremendously include computerized physician order entry electronic medical record clinical note medical image cyberphysical system medical internet thing genomic data clinical decision support system type data source like social network service genomic data used build personalized healthcare system hence health data obtained various form varied source context technology nature impede proper analysis analytical research must overcome obstacle mine data produce meaningful insight save life investigate key challenge data source technique technology well future direction field big data analytics healthcare provide doityourself delivers holistic simplified easily understandable view various technology used develop integrated health analytic application ,2
BD_166,application internet thing iot technology smart city intelligent medical terminal play significant role daily life terminal monitor physical condition get lot medical data time sake data security practicality collected big data encrypted stored cloud server authorized user data owner doctor access however smart terminal usually limited computing power user privacy issue remain tackle challenging problem efficient medical data sharing scheme presented solve privacy issue user data sharing utilize attributebased encryption enable data sharing addition remove attribute matching function attribute bloom filter hide attribute access control structure order improve efficiency encryption introduce onlineoffline encryption technology encryption phase message known large amount needed encryption stage done message known ciphertext generated quickly besides initialization stage system need specify attribute overall attribute system user increase system need reinitialized also improve system efficiency security analysis performance analysis show data sharing scheme secure improve data processing ability iot based data sharing ,2
BD_167,clinical data often multimodal consist structured data unstructured data modeling clinical data become important challenging problem healthcare big data analytics existing system focus one type data propose knowledge graphbased method build linkage various type multimodal data first build semanticrich knowledge base medical dictionary practical clinical data collected hospital second propose graph modeling method bridge gap different type data multimodal clinical data patient fused modeled one unified profile graph capture temporal evolution patient clinical case profile graph represented sequence evolving graph third develop lazy learning algorithm automatic diagnosis based graph similarity search evaluate method conduct experimental study icu patient diagnosis orthopaedics patient classification result show method could outperform baseline algorithm also implement real automatic diagnosis system clinical result obtained hospital demonstrate high precision ,2
BD_168,data leakage growing insider threat information security among organization iniduals series method developed address problem data leakage prevention dlp however large amount unstructured data need tested big data era volume data grows dramatically form data become much complicated challenge dlp deal large amount transformed data propose adaptive weighted graph walk model solve problem mapping dimension weighted graph approach solves problem three step first adaptive weighted graph built quantify sensitivity tested data based context improved label propagation used enhance scalability fresh data finally lowcomplexity score walk algorithm proposed determine ultimate sensitivity experimental result show proposed method detect leak transformed fresh data fast efficiently ,2
BD_169,international deep seabed resource survey accumulated large amount valuable marine geochemical data data however derive number autonomous heterogeneous information source show characteristic big data ie multidisciplinary multidimensional multisemantic strong correlation traditional database federation method thus applicable achieve marine geochemical data interoperation approach proposed approach first build marine sample ontology mso based marine geochemical metadata standard support mso ontology serf specification semantics model multisource heterogeneous data data integration unified query apis accomplished across different database experiment applied three database icpaes database model odp project petdb marine petrology database model compiled lamontdoherty earth observatory georoc database model operated german max planck institute experimental result show method improves efficiency marine geochemical data integration also realizes reuse data model premise ensuring independence security timeliness data source ,2
BD_170,smart device tablet phone revolutionizing access healthcare service bringing forth mhealth ehealth revolution aiming empower consumer make difference health wellbeing connecting data personalized analytics timely insight however consumercentric journey smart connected health presenting challenge opportunity big data analytics research whether integrating developing machine learning algorithm heterogeneous longitudinal data developing novel system application developing experience framework ensuring privacy security data ,2
BD_171,iot device complex requirement limitation term storage network computing data analytics scalability big data management require used technology like cloud computing iot backend cloud computing way offer service massively scalable dynamically configured delivered demand large scale infrastructure resource however single cloud infrastructure might unable deal increasing demand cloud service hundred user might accessing cloud resource leading big data problem need efficient framework handle large number request iot service challenge require functional element provisioning scheme end propose usage multiclouds iot optimize requirement allowing choose best iot service many service hosted various cloud platform provide infrastructure platform resource meet requirement present novel framework dynamic secure iot service access across multiclouds cloud ondemand model facilitate multicloud collaboration novel protocol designed implemented cloud platform various stage involved framework allowing user access iot service multiclouds matchmaking ie choose best matching requirement authentication ie lightweight mechanism authenticate user runtime granting access sla management including sla negotiation enforcement monitoring sla management offer benefit like negotiating required parameter enforcing mechanism ensure execution external cloud according agreed slas monitoring verify cloud provider complies slas detailed system design establish secure multicloud collaboration presented moreover designed protocol empirically implemented two different cloud including openstack amazon aws experiment indicate proposed system scalable authentication protocol result limited overhead compared standard authentication protocol sla violation cloud provider could recorded reported back ,2
BD_172,world growing disparity quality life available people developed developing country healthcare developing world fraught numerous problem lack health infrastructure human resource result limited health coverage field health informatics made great stride recent year towards improving health system developing world augmenting stateoftheart information communication technology ict realworld deployment technology real hope health industry developing world progress current largely dysfunctional state one effective personalized cost effective health informatics usher era personalized health analytics potential transform healthcare developing world conjunction mhealth ehealth many important health informatics trends—such artificial intelligence ai machine learning ml big data crowdsourcing cloud computing—are also emerging exponentially growing heterogeneous data help big data analytics potential provide descriptive predictive prescriptive health insight well enable application telemedicine remote diagnostics surgery system could enhance overall process monitoring diagnosis prognosis disease ,2
BD_173,brain big data empowered intelligent analysis provide unrivalled opportunity probe dynamic brain disorder typical example identify evolving synchronization pattern multivariate electroencephalography eeg routinely superimposed intensive noise epilepsy research practice circumstance insufficient priori knowledge subject dependency domain problem becomes even important adaptively classify synchronization dynamic accurately characterize intrinsic nature seizure activity represented eeg first measure global maximal information coefficient mic eeg data channel form time sequence correlation matrix lightweight vggnet visual geometry group designed adapt need prune massive eeg datasets vggnet characterizes synchronization dynamic captured correlation matrix automatically identifies seizure state eeg experiment performed childrens hospital bostonmassachusetts institute technology chbmit scalp eeg dataset evaluate proposed approach seizure state identified accuracy sensitivity specificity % ± % % ± % % ± % respectively resulting performance superior existing method dataset approach directly applies raw eeg analysis hold great potential handling brain big data ,2
BD_174,recent development internet thing related technology caused shift towards smart application smart city smart home smart education system ehealth well online application run business turn introduced significant additional load existing network infrastructure addition application big data require relatively short response time introducing scheduling routing approach enhance end experience utilize network resource providing improved transmission speed big data application approach considers source destination requirement term data size expected delay link load link capacity extensive simulation performed result obtained show efficiency approach competitive approach term innetwork delay network throughput dropped packet ,2
BD_175,matrix inversion fundamental operation solving linear equation many computational application especially various emerging big data application however challenging invert largescale matrix extremely high order several thousand million common webscale system social network recommendation system lower upper decompositionbased blockrecursive algorithm largescale matrix inversion welldesigned implementation optimized data structure reduction space complexity effective matrix multiplication spark parallel computing platform experimental evaluation result show proposed algorithm efficient invert largescale matrix cluster composed commodity server scalable inverting even larger matrix proposed algorithm implementation become solid foundation building highperformance linear algebra library spark big data processing application ,2
BD_176,starting july ministry science technology china several national agency sponsor month million rmb chinese yuan project knowledge engineering big data wwwbigkeorg top research development institution fundamental theory application bigke bigdata knowledge engineering framework handle fragmented knowledge modeling online learning multiple information source nonlinear fusion fragmented knowledge automated demanddriven knowledge navigation project seek provide petabytescale data knowledge service identified application domain discus bigke framework novel application scenario bigke service ,2
BD_177,boom big data graphic processing unit technology allowed u explore appropriate data structure algorithm smaller time complexity however application machine learning potential alternative traditional data structure especially deep learning relatively largely uncharted territory propose novel recurrent neural networkbased learned inverted index called pavo efficiently flexibly organize inverted data basic hash function traditional inverted index replaced hierarchical neural network make pavo able well adapt various data distribution showing lower collision rate well higher space utilization rate particular feature approach novel unsupervised learning strategy construct hash function proposed best knowledge similar result unsupervised learning strategy employed design hash function existing literature extensive experimental result show unsupervised model owns advantage supervised one approach demonstrate feasibility deep learningbased data structure index also provide benefit developer make accurate decision design configuration data organization operation parameter tuning neural network improve performance information searching ,2
BD_178,due imbalanced distribution business data missing feature many reason directly big data technique realistic business data tends deviate business goal difficult model insurance business data classification algorithm logistic regression support vector machine svm exploit heuristic bootstrap sampling approach combined ensemble learning algorithm largescale insurance business data mining propose ensemble random forest algorithm us parallel computing capability memorycache mechanism optimized spark collected insurance business data china life insurance company analyze potential customer proposed algorithm fmeasure gmean evaluate performance algorithm experiment result show ensemble random forest algorithm outperformed svm classification algorithm performance accuracy imbalanced data useful improving accuracy product marketing compared traditional artificial approach ,2
BD_179,information technology equipment found data center aircooled electrical component produce heat must removed prevent temperature equipment rising unacceptable level energy consumption data center cooling system positively related air temperature outside data center difference data center internal temperature outside air temperature varies data center location reschedule workload internet cloud service least temperature difference cooling energy consumption biggest saving cooling energyconsumption model query characteristic cloud service provide methodology formulate energy consumption workload rescheduling however cloud must meet tail latency constraint rescheduling solve problem estimating highpercentile tail latency scheduling cloud meet tail latency constraint last proactive weatheraware geoscheduling algorithm called ecsupsup proposed distribute endusers load among data center reduce cooling energy consumption tracedriven experiment real cloud data center workload trace show effectiveness design reducing data center cooling consumption ,2
BD_180,proposes three hierarchical level competitive bigdata market model consider provider gather data multiple data source provides valuable information refined data customer approach provider determines optimal data procurement multiple data source budget constraint multiple data source follow provider action independently submitting bidding price provider customer decide whether subscribe based subscription fee willingnesstopay quality refined data economic benefit market model analyzing hierarchical decision making procedure stackelberg game show existence uniqueness nash equilibrium ne ne solution given closed form finally reveal obtained unique equilibrium solution maximizes payoff market participant ,2
BD_181,datadriven approach tasked situation awareness suitable complex grid massive datasets challenge however efficiently turn massive datasets useful big data analytics address challenge based random matrix theory proposes datadriven approach approach model massive datasets large random matrix modelfree requires knowledge physical model parameter particular large data dimension n large time span spatial aspect temporal aspect respectively lead favorable result beautiful thing lie linear eigenvalue statistic le built data matrix follow gaussian distribution general condition due latest breakthrough probability central limit theorem le numerous case study simulated data field data given validate proposed algorithm ,2
BD_182,emergence internet thing number connected device dramatically increasing causing severe spectrum shortage problem fully explore spectrum resource big data cloud computing employed cognitive radio network make efficient various sensing result different sensing source however massive growth sensing data brings tremendous load pressure data center resulting long response time poor quality experience edge computing fog computing deal issue placing computation resource network edge however compared data center capability edge server limited therefore service routingbased caching scheme srcs proposed greatly lighten load data center maintain advantage global intelligent computing traditional cloud computing specifically srcs first introduces concept transmitting flow edge layer data converted flow network hardware software thus achieving network architecture centered computing srcs proposes routing based similarity transmits similar service path data fused path minimize transmission load moreover srcs cache service content router cr requested cr used provider return data thus achieving nearest access content theoretical analysis experiment result demonstrate comparing existing scheme srcs improves response time % – % reduces transmitting data amount % – % make energy consumption balanced ,2
BD_183,electronic health record ehrs providing increased access healthcare data made available advanced data analysis used healthcare professional make informed decision providing improved quality care however due inherent heterogeneous imbalanced characteristic medical data ehrs data analysis face big challenge address challenge imbalanced medical data brain tumor diagnosis problem morphometric analysis histopathological image rapidly emerging valuable diagnostic tool neuropathology oligodendroglioma one type brain tumor good response treatment provided tumor subtype recognized accurately genetic variant pq recently found high chemosensitivity morphological attribute may lend automated image analysis histological processing diagnosis aim achieve fast affordable objective diagnosis genetic variant oligodendroglioma novel data mining approach combining feature selection ensemblebased classification instance brain tumor oligodendroglioma obtained due prevalence incidence tumor variant order minimize effect imbalanced healthcare data set global optimizationbased hybrid wrapperfilter feature selection ensemble classification applied experiment result show proposed approach outperforms standard technique used brain tumor classification problem overcome imbalanced characteristic medical data ,2
BD_184,exploring big amount data without clear target providing interactive experience becomes really difficult since tentative inspection usually defeat early decision data structure indexing strategy also true physic domain specifically highenergy physic huge volume data generated detector normally explored via c++ code batch processing introduces considerable latency interactive tool integrated existing data management system add great value usability platform intend current stateoftheart interactive data exploration aiming satisfying three requirement access raw data file stored distributed environment reasonably low latency follows guideline systematic mapping study well suited gathering classifying available study summarize result classifying paper passed inclusion criterion many proposed solution tackle problem different manner little evidence available implementation practice almost solution found cover subset requirement one partially satisfying three solution data exploration abound active research area considering continuous growth data volume variety become harder niche research solution cover requirement required building block ,2
BD_185,wireless sensor network wsns almost everywhere exploited thousand application densely distributed manner deployment make wsns one highly anticipated key contributor big data nowadays hence data aggregation attracting much attention researcher efficient way reduce huge volume data generated wsns eliminating redundancy among sensing data propose efficient data aggregation technique clusteringbased periodic wireless sensor network local aggregation sensor node level technique allows clusterhead eliminate redundant data set generated neighbouring node applying three data aggregation method proposed method based set similarity function oneway anova model statistical test distance function respectively based real sensor data analyed performance according energy consumption data latency accuracy show method significantly improve performance sensor network ,2
BD_186,today society collecting massive exponentially growing amount data potentially revolutionize scientific engineering field promote business innovation advent cloud computing order analyze data costeffective practical way user outsource computing task cloud offer access vast computing resource ondemand payperuse basis however since user data contains sensitive information need kept secret ethical security legal reason many user reluctant adopt cloud computing end researcher proposed technique enable user offload computation cloud protecting data privacy recent advance secure outsourcing largescale computation big data analysis first introduce two fundamental common computational problem ie linear algebra optimization provide extensive data privacy preserving technique explain researcher exploited data privacy preserving technique construct secure outsourcing algorithm largescale computation ,2
BD_187,aggregating finegranular data measurement smart meter present opportunity utility company learn consumer power consumption pattern several research study shown power consumption pattern reveal range information consumer many people home type appliance eating sleeping routine even tv program watch move toward liberalized energy market many different party interested gaining access data enormous economical societal environmental benefit however concern many beneficial us smart meter big data would severely curtailed data excessively protected due iniduals privacy propose game theoretic mechanism balance beneficial us data iniduals privacy deregulated smart grid mechanism solves problem access control fairly compensating consumer participation data market based concept differential privacy result experiment show importance taking consumer attitude toward privacy crucial element designing balanced market fair data sharing furthermore experiment provide principled way choose reasonable value privacy level relevant realworld scenario ,2
BD_188,big data analytics simplified processing complexity extremely large data set ecosystem hadoop mapr cloudera apache hadoop opensource ecosystem manages large data set distributed environment mapreduce programming model process massive amount unstructured data set hadoop cluster recently hadoop enhances homogeneous storage function heterogeneous storage store data set multiple storage medium ie ssd ram disk development increase performance data block placement strategy allows client store large data set multiple storage medium efficiently homogeneous storage however evolution increase consumption computing capacity memory usage mapreduce scheduling scheduler process mapreduce homogeneous container configuration cpu memory disk volume network io access process store data set heterogeneous storage medium produce processing latency locating pairing source data set mapreduce task result abnormal high consumption computing capacity memory usage datanode similarly scheduler assigns mapreduce job multiple datanodes processing latency severely affect performance whole cluster storagetagaware scheduler stas reduces processing latency scheduling mapreduce job heterogeneous storage container ie ssd disk ram container stas endorses tag storage medium jobssd jobdisk jobram par heterogeneous sharedqueues assign processing configuration enlist job stas manager schedule sharedqueue job heterogeneous mapreduce container generates output storage medium cluster experimental evaluation show stas optimizes consumption computing capacity memory usage efficiently available scheduler hadoop cluster ,2
BD_189,design implementation affordable bedside device neo capable acquiring vital data real time integrating erse device connected newborn neonatal intensive care unit nicu nicu equipped multiple vital sign monitoring device connected premature newborn acquire gigabyte data every day continuous vital data device manually documented every hour introduces error loses large amount highresolution data intermittent documentation physiological data also make difficult clinician visualize detect trend diagnostic utility neo built affordable internet thing platform aggregate sends realtime data cloudbased big data platform called integrated nicu apart minimizing documentation error device enables data acquisition sufficiently realtime rate indicate current status patient nicu neo automates immediate vital sign status past trend graph chart doctor nurse view anywhere internet physiological signal clinical parameter neo used score different disease like sepsis respiratory distress syndrome necrotizing enterocolitis retinopathy prematurity score predicts physiological health newborn aid clinician decisionmaking ensuring timely intervention ,2
BD_190,field instant voice communication ivc steganalysis traditional detecting method mainly based supervised learning scheme result large amount complex manual preprocessing training data set accuracy supervised learning scheme easily destroyed difference distribution training testing data set actual voice application disadvantage method obvious big data environment regard initially introduced novel semisupervised hybrid learning detection model ivc network provides progress manually annotating training data set removed solve problem complex operation poor applicability classifier therefore model simpler structure extensive detection scope huge amount data designed multicriteria fusion module automatically generate pseudolabel set testing data set train classifier model thus scheme affected distribution shift module defined confidence level representative level judge feature vector pseudolabeled experimental analysis low bitrate speech coding steganalysis ggilbc speech codecs analyzed quantization index modulation common codecs ivc network result show method higher accuracy unsupervised method proposed approach le affected accurate previous supervised method distribution different training testing data set experiment also proved method deployed different kind ivc codec considering huge amount data set ,2
BD_191,era big data availability massive amount information make privacy protection necessary ever among variety anonymization mechanism microaggregation common approach satisfy popular requirement kanonymity statistical database essence kanonymous microaggregation aggregate quasiidentifiers hide identity data subject group k subject perturbative mechanism however anonymization come cost information loss may hinder ulterior released data often building machinelearning model macrotrends analysis ass impact microaggregation utility anonymized data necessary evaluate resulting accuracy said model address problem measuring effect kanonymous microaggregation empirical utility microdata quantify utility accordingly accuracy classification model learned microaggregated data evaluated original test data experiment indicate consistency impact de facto microaggregation standard maximum distance average vector performance machinelearning algorithm often minor negligible wide range k variety classification algorithm data set furthermore experimental evidence suggest traditional measure distortion community microdata anonymization may inappropriate evaluating utility microaggregated data ,2
BD_192,last year much multimedia digital watermarking domain primary limitation watermark strength visibility multimedia watermark invisibility defined human term term human sensory limitation recent development nonmedia application data watermarking emerged last decade exciting subdomain since definition intended receiver able detect watermark redefine invisibility acceptable way often applicationspecific thus easily generalized particular true data intended directly consumed human example loose definition robustness might term resilience watermark normal host data operation invisibility resilience data interpretation change introduced watermark classify data term data mining rule complex type data timeseries symbolic sequence data stream forth emphasize challenge involved nonmedia watermarking term common watermarking property including invisibility capacity robustness security aid example watermarking application demonstrate distinction look latest research regard make argument clear meaningful last aim look challenge digital watermarking arisen evolution big data ,2
BD_193,massive flow represent inidual level movement communication easily obtained age big data generalizing spatial temporal flow pattern data essential demonstrate spatial connection mobility trend clustering approach provide effective method handle data set contain massive iniduallevel flow however existing flow clustering study obscure geometric property flow data direction length significantly indicate movement trend addition temporal information often ignored previous approach mainly focused perspective spatial cluster flow data resulting loss temporal pattern introduce spatial temporal similarity measurement flow propose clustering approach flow data based stepwise strategy method identify cluster distinct flow distribution discover significant spatiotemporal trend large flow data simulated experiment synthetic flow case beijing taxi trip data conducted validate usefulness proposed method ,2
BD_194,isolate data among different campus information system much effective information among big data generated system cause challenge predicting achievement student design student achievement predicting framework includes data processing student achievement predicting data processing data extraction data cleaning feature extraction designed data data warehouse propose layersupervised multilayer perceptron mlpbased method predict achievement student supervision fed corresponding hidden layer mlp improve performance student achievement prediction compared svm naive bayes logistic regression mlp method get better performance ,2
BD_195,proliferation ubiquitous internet mobile device brought exponential growth inidual data big data era network data confronted serious privacy concern extracting valuable information process data mining differential privacy preservation paradigm independent adversary prior knowledge protects sensitive data maintaining certain statistical property adding random noise put forward differential privacy preservation multiple core dbscan clustering schema based powerful differential privacy dbscan algorithm network data effectively leverage privacy leakage issue process data mining enhancing data clustering efficaciously adding laplace noise perform extensive theoretical analysis simulation evaluate schema result show better efficiency accuracy privacy preservation effect previous schema ,2
BD_196,brain health quality premonitoring become urgent need system complex engineering perspective intelligent decisionmaking based big data intelligent air index prediction introduced popular classification algorithm introduced hidden information historical data mined brain health quality prediction realized brain health quality monitoring system based internet thing constructed classification algorithm used realize realtime acquisition intelligent processing data order improve data processing speed enhance realtime performance brain health quality prediction introduces cloud computing technology accelerate data processing order enable user understand air index anytime anywhere also designed based problem large historical data air index realtime data collection android platform develops air index forecast client ,2
BD_197,computer server equipped increasing number memory module capacity making mainmemory system second energyconsuming component trailing processor bigmemory server bigmemory server mainmemory system offer high energy efficiency pursuit energyefficient mainmemory system prior exploited mobile low power double data rate lpddr device advantage lower power ddr device attempting surmount limitation longer latency lower bandwidth however show mainmemory architecture based latest lpddr device longer effective even hurt overall energy efficiency server % memoryintensive workload compared one based ddr device reason power consumption modern ddr device substantially reduced adopting strength mobile graphic memory whereas lpddr focused increasing data transfer rate sacrificing energy efficiency power consumption ddr device significantly vary across manufacturer analysis moreover exploring energysaving feature ddr device depth show activating feature often hurt overall energy efficiency server performance penalty subsequently propose simple effective scheme adaptively exploit dram powerdown mode hence improves system energydelay product % ,2
BD_198,vehicle test big data important significance vehicle performance characteristic aiming test dynamic stiffness characteristic bogie suspension system rail vehicle simplified rigidflexible hybrid model bogie established force condition bogie suspension system analyzed based simplified model mathematical model dynamic stiffness primary suspension secondary suspension integrated suspension established addition method testing threeway dynamic stiffness bogie suspension system complete assembled state proposed dynamic stiffness test model bogie primary suspension secondary suspension comprehensive suspension established dynamic stiffness test primary suspension secondary suspension integrated suspension carried according big data analysis bench test dynamic stiffness curve suspension frequency – hz obtained test result show dynamic stiffness suspension bogy varies nonlinearly change frequency dynamic stiffness value suspension different frequency vary greatly result vehicle operating characteristic evaluated based suspension static stiffness suspension stiffness single frequency indicating necessity suspension dynamic stiffness test bogie assembled ,2
BD_199,improve localization accuracy big challenge highly dynamic sparse industrial scenario active rfid tag since antenna active tag anisotropic emitting signal propagates damply transmission distance emitting orientation aim modeling anisotropic signal attenuation active rfid tag analyzing measurement data real environment feature signal attenuation transmission distance different signalemitting orientation two basic model regressed experimental data firstly directional signaldistribution model horizontal vertical orientation certain distance attenuation model rf signal transmitting distance one direction afterwards anisotropic signal attenuation model active rfid tag asam deduced furthermore noise filtering model taggrid environment optimized spatial model asam finally experimental result squaremeter experimental field show average standard deviation std optimized model reduces % std bigger db probability distribution % deviation le ,2
BD_200,due recent development cyberphysical system big data cloud computing industrial wireless network era industrial big data introduced deep learning brought revolutionary change computer vision natural language processing variety application significant potential solution providing sophisticated industrial application concept device electrocardiogram decg presented algorithm based deep denoising autoencoder dda regression operation proposed prediction remaining useful life industrial equipment first concept electrocardiogram explained problem statement based manufacturing scenario presented subsequently architecture proposed algorithm called integrated dda algorithm workflow provided moreover decg compared traditional factory information system feasibility effectiveness proposed algorithm validated experimentally proposed concept algorithm combine typical industrial scenario advance artificial intelligence great potential accelerate implementation industry ,2
BD_201,big data era upon u data generated analyzed used unprecedented scale datadriven decision making sweeping aspect society since value data explodes linked fused data addressing big data integration bdi challenge critical realizing promise big data bdi differs traditional data integration dimension volume velocity variety veracity first data source contain huge volume data also number data source million second rate newly collected data made available many data source dynamic number data source also rapidly exploding third data source extremely heterogeneous structure content exhibiting considerable variety even substantially similar entity fourth data source widely differing quality significant difference coverage accuracy timeliness data provided book explores progress made data integration community topic schema alignment record linkage data fusion addressing novel challenge faced big data integration topic covered systematic way first starting quick tour topic context traditional data integration followed detailed exampledriven exposition recent innovative technique proposed address bdi challenge volume velocity variety veracity finally present merging topic opportunity specific bdi identifying promising direction data integration community ,2
BD_202,recent marked increase amount spatial data collected smart phone space telescope medical device among others increased volume brought focus need specialized system handle big spatial data era big spatial data survey summarizes stateoftheart area classifies existing considering six aspect big spatial data system namely approach architecture language indexing querying visualization describes component detail give example implemented existing system also provides reader case study real application make system provide service end user era big spatial data survey invaluable reference researcher practitioner interested getting handle state art big spatial data storage querying ,2
BD_203,hit power limitation even aggressive outoforder execution processor core many architect past decade turned singleinstructionmultipledata simd execution increase singlethreaded performance simd execution single instruction drive execution identical operation multiple data item already well established technique efficiently exploit data parallelism furthermore support already included many commodity processor however past decade simd execution seen dramatic increase set application motivated big improvement hardware support mainstream microprocessor easiest way provide big performance boost simd hardware make wider— ie increase number data item hardware operates simultaneously indeed microprocessor vendor done however exploit data parallelism application certain challenge negatively impact performance particular conditional execution noncontiguous memory access presence dependence across data item key roadblock achieving peak performance simd execution book first describes data parallelism common popular application describe simd execution explain performance energy benefit come compared technique exploit parallelism finally describe simd hardware support current commodity microprocessor includes expected design tradeoff well unexpected one overcome challenge encountered trying map real software simd execution ,2
BD_204,domain adaptation active emerging research area attempt address change data distribution across training testing datasets availability multitude image acquisition sensor variation due illumination viewpoint among others computer vision application natural test bed evaluating domain adaptation method monograph provides comprehensive overview domain adaptation solution visual recognition problem starting problem description illustration discus three adaptation scenario namely unsupervised adaptation source domain training data partially labeled target domain test data unlabeled ii semisupervised adaptation target domain also partial label iii multidomain heterogeneous adaptation study previous two setting source andor target one domain account case feature used represent data domain different scenario domain adaptation visual recognition discus existing adaptation technique literature technique motivated principle maxmargin discriminative learning manifold learning sparse coding well lowrank representation shown improved performance variety application object recognition face recognition activity analysis concept classification person detection domain adaptation visual recognition concludes analyzing challenge posed realm big visual data term generalization ability adaptation algorithm unconstrained data acquisition well issue related computational tractability draw parallel effort vision community image transformation model invariant descriptor facilitate improved understanding vision problem uncertainty ,2
BD_205,data quality one important problem data management since dirty data often lead inaccurate data analytics result wrong business decision according insightsquared poor data across business government cost united state economy trillion dollar detect data error data quality rule integrity constraint ic proposed declarative way describe legal correct data instance subset data conform defined rule considered erroneous also referred violation various kind data repairing technique different objective introduced algorithm used detect subset data violate declared integrity constraint even suggest update database database instance conforms constraint algorithm aim minimally change database others involve human expert knowledge base verify repair suggested automatic repeating algorithm trend cleaning relational data consistency deduplication discus facet direction designing error detection repairing technique proposes taxonomy current anomaly detection technique including error type automation detection process error propagation also set taxonomy current data repairing technique including repair target automation repair process update model concludes highlighting current trend big data cleaning ,2
BD_206,adaptation learning optimization network deal topic information processing graph presentation largely selfcontained cover result relate analysis design multiagent network distributed solution optimization adaptation learning problem streaming data localized interaction among agent result derived monograph useful comparing network topology comparing networked solution centralized batch implementation many good reason peaked interest distributed implementation especially day age word network become commonplace whether one referring social network power network transportation network biological network type network reason benefit cooperation term improved performance improved resilience failure reason deal privacy secrecy consideration agent may comfortable sharing data remote fusion center situation data may already available dispersed location happens cloud computing one may also interested learning data mining big data set motivated consideration adaptation learning optimization network examines limit performance distributed solution discus procedure help bring forth potential fully adaptation learning optimization network adopts useful statistical framework derives performance result elucidate meansquare stability convergence steadystate behavior learning network time monograph illustrates distributed processing graph give rise revealing phenomenon due coupling effect among agent phenomenon discussed context adaptive network example variety area including distributed sensing intrusion detection distributed estimation online adaptation network system theory machine learning ,2
BD_207,cloud computing emerged successful paradigm serviceoriented computing revolutionized way computing infrastructure used success seen proliferation number application deployed various cloud platform also increase scale data generated well consumed application scalable database management system form critical part cloud infrastructure attempt address challenge posed management big data led plethora system book aim clarify important concept design space scalable data management cloud computing infrastructure question book aim answer appropriate system specific set application requirement research challenge data management cloud novel cloud database researcher ? also aim address one basic question whether cloud computing pose challenge scalable data management reincarnation old problem ? provide comprehensive background stateoftheart system scalable data management analysis also identify important aspect design different system applicability scope system thorough understanding current solution precise characterization design space essential clearing cloudy sky data management ensuring success dbms cloud thus emulating success enjoyed relational database traditional enterprise setting table content introduction distributed data management cloud data management early trend transaction colocated data transaction distributed data multitenant database system concluding remark ,2
BD_208,timely costeffective analytics big data emerged key ingredient success many business scientific engineering discipline government endeavor web click social medium scientific experiment datacenter monitoring among data source generate vast amount raw data every day need convert raw data useful information spawned considerable innovation system largescale data analytics especially last decade massively parallel database mapreduce system address design principle core feature system analyzing large datasets massivelyparallel computation storage technique large cluster node first discus requirement data analytics evolved since early parallel database system describes major technological innovation spawned distinct category system data analytics unique system category described number dimension including data model query interface storage layer execution engine query optimization scheduling resource management fault tolerance concludes summary trend largescale data analytics massively parallel database mapreduce system ideal reference anyone research professional interest largescale data analytics ,2
BD_209,summary form given big data problem today usually researcher talk big data however data isnt big inefficient solution stack based direct product datasets mapreducehadoop cramming data square peg whatever datastore available round hole moving data around datasevers computerservers ok bigdata big happens data big data actually get big ? talk discus big data software solution stack must evolve address future big data problem guiding principle world big data really big one size fit data must match data store data movement everything move query processing data visualization must first class citizen big data solution stack developing reference implementation sort big data solution stack envision play key role future call bigdawg solution stack research behind bigdawg occurring intel science technology research center mit collaborator brown university university washington university tennessee portland state university ,2
BD_210,age big data efficient algorithm higher demand ever big data take u asymptotic world envisioned pioneer also challenge classical notion efficient algorithm algorithm used considered efficient according polynomialtime characterization may longer adequate solving today problem desirable essential efficient algorithm scalable word complexity nearly linear sublinear respect problem size thus scalability polynomialtime computability elevated central complexity notion characterizing efficient computation scalable algorithm data network analysis survey family algorithmic technique design scalable algorithm technique include local network exploration advanced sampling sparsification geometric partitioning also include spectral graphtheoretical method used computing electrical flow sampling gaussian markov random field method exemplify fusion combinatorial numerical statistical thinking network analysis scalable algorithm data network analysis illustrates technique basic problem fundamental analyzing network data particularly identification significant node coherent clusterscommunities social information network also discus framework beyond graphtheoretical model studying conceptual question arise network analysis social influence ,2
BD_211,order meet challenge big data enhance intelligent level distribution grid better power starting characteristic v big data link power supply system industrial chain ie planning design construction operation management & amp regulation distribution grid equipment design manufacturing relatively mature degree angle need big data application distribution network analysed b method f swot analysed doubleedged sword effect big data distribution gird provides opportunity challenge benefit opportunity big data bringing data view changing thinking method tool expanding application scene providing better society enhancing value opportunity time big data lead challenge distribution grid example security challenge big data big data concentrated cause safety challenge distribution grid serious energy consumption challenge big data big data privacy threat distribution grid demand big data application distribution grid industrial chain strong weak management & amp regulation distribution grid operation equipment design manufacturing construction design planning big data source power supply enterprise internal operation including part physical grid operation marketing service grid enterprise operation power system technology innovation three wheel drive experimental science theoretical science computational science increased four wheel drive experimental science theoretical science computational science data intensive sciencedata exploration science paradigm big data still explosion control fourth paradigm data intensive science also need redouble effort non structure data distribution grid rapid growth % amount data next five year ,2
BD_212,address rise machine learning big data analytics first machine learning several term related machine learning defined explained detail term include artificial intelligence data mining data science data analytics knowledge discovery statistic business intelligence definition show term interrelated definition big data outlined based three term volume velocity variety implementing good big data strategy crucial order guarantee success applying machine learning learning big data result trending big data also illustrated defined based landscape big data infrastructure analytics application crossinfrastructuresanalytics source data source api incubator school also address source facility available order ensure large scale machine learning application realized finally conclusion big trend last month big data analytics increasing focus artificial intelligence help analyze massive amount data derive predictive insight aimachine learning precipitating trend towards emergence application layer big data combination big data ai drive incredible innovation across pretty much every industry perspective big data opportunity probably even bigger people thought ,2
BD_213,big data becoming technology focus science industry motivate technology shift data centric architecture operational model vital need define basic informationsemantic model architecture component operational model together comprise socalled big data ecosystem discus nature big data may originate different scientific industry social activity domain proposes improved big data definition includes following part big data property also called big data v volume velocity variety value veracity data model structure data analytics infrastructure security discus paradigm change traditional host based data centric architecture operational model big data big data architecture framework bdaf proposed address aspect big data ecosystem includes following component big data infrastructure big data analytics data structure model big data lifecycle management big data security analysis requirement provides suggestion mentioned component address big data challenge presented intends provide consolidated view big data phenomenon related challenge modern technology initiate wide discussion ,2
BD_214,big data come aureate haste clef enabler social business big data gift opportunity create extraordinary business advantage better delivery big data bringing positive change decision making process various business organization several offering big data come several issue challenge related big data management big data processing big data analysis big data challenge related volume velocity variety big data v volume mean large amount data velocity mean data arrives high speed variety mean data come heterogeneous resource big data definition big mean dataset make data concept grow much becomes difficult manage existing data management concept tool map reduce playing significant role processing big data includes brief big data related issue emphasizes role mapreduce big data processing mapreduce elastic scalable efficient fault tolerant analysing large set data highlight feature mapreduce comparison design model make popular tool processing large scale data analysis performance factor mapreduce show elimination inverse effect optimization improves performance map reduce ,2
BD_215,collection storage manipulation retention massive amount data resulted serious security privacy consideration various regulation proposed handle big data privacy iniduals violated example even personally identifiable information removed data data combined data inidual identified essentially inference aggregation problem data security researcher exploring past four decade problem exacerbated management big data different source data exist related various iniduals collecting massive amount data cause security privacy concern big data analytics application cyber security exploding example organization outsource activity identity management email filtering intrusion detection cloud massive amount data collected application data analyzed question development big data management analytics technique used solve security problem ? problem include malware detection insider threat detection intrusion detection address challenge big data security privacy well big data analytics cyber security application organized workshop sponsored national science foundation september presented result interagency workshop washington dc since several development reported big data security privacy well big data analytics cyber security talk summarize finding workshop discus development direction ,2
BD_216,data larger size maintained term mega byte mb giga byte gb termed big data big data usually size peta byte supλsup research say data referred big data today life data collected past three year resource big data social networking site collect vast data face book twitter linkedin billion user post data daily basis share market also contribute big data process stock exchanging also collecting data share transaction ecommerce site collect data useful provider introduce good item satisfies requirement resource big data weather station telecom company etc three important feature big data velocity volume veracity size big data increasing rapid way data double every two year big data sometimes structured data sometimes unstructured data data maintained table structure row column data called structured data data cctv footage example unstructured data attempted discus growth life cycle stage handling huge data hadoop framework publication frequency advantage challenge handling big data ,2
BD_217,recent year online social networking revolutionized interpersonal communication newer research language analysis social medium increasingly focusing latter impact daily life personal professional level natural language processing nlp one promising avenue social medium data processing scientific challenge develop powerful method algorithm extract relevant information large volume data coming multiple source language various format free form discus challenge analyzing social medium text contrast traditional document research method information extraction automatic categorization clustering automatic summarization indexing statistical machine translation need adapted kind data book review current research nlp tool method processing nontraditional information social medium data available large amount big data show innovative nlp approach integrate appropriate linguistic information various field social medium monitoring healthcare business intelligence industry marketing security defence existing evaluation metric nlp social medium application effort evaluation campaign shared task datasets collected social medium task organized association computational linguistics semeval task national institute standard technology via text retrieval conference trec text analysis conference tac concluding chapter discus importance dynamic discipline great potential nlp coming decade context change mobile technology cloud computing virtual reality social networking second edition added information recent progress task application presented first edition discus method result number research project publication social medium data constantly increasing due continuously growing amount social medium data need automatically process added reference reference first edition besides updating section added application digital marketing section medium monitoring augmented section healthcare application extended discussion recent research detecting sign mental illness social medium ,2
BD_218,cloud computing environment big data transmission channel easily affected multipath effect lead poor channel equalization high bit error rate ber big data transmission order improve capacity big data transmission channel equalization scheduling cloud computing environment cloud computing big data equalization scheduling algorithm proposed based porter interval equalization fuzzy cmeans clustering big data transport channel model cloud computing environment constructed multipath characteristic big data transmission channel cloud computing environment analyzed big data output feature analyzed combining similarity feature extraction association rule mining method autocorrelation beamforming method used analyze information clustering fusion big data equalization scheduling process decision feedback equalization scheduling method used design channel equalization big data output cloud computing environment spread spectrum technology used extend big data transmission channel improve equalization channel scheduling big data clustering processing cloud computing environment combined fuzzy cmeans clustering method realize big data equalization scheduling cloud computing environment simulation result show big data equalization scheduling cloud computing environment better channel equalization strong antijamming ability improved accuracy big data classification scheduling ,2
BD_219,big data governance requires data governance satisfy need corporate governance governance itaea existing data governance focus processing structured data big data governance need established consideration broad sense big data service including unstructured data achieve goal big data strategy need established together goal aligned vision objective organization addition preparation infrastructure proper preparation component required effectively implement strategy big data service propose big data governance framework big data governance framework present criterion different existing criterion data quality level focus timely reliable meaningful sufficient data service focusing data attribute achieved based data attribute big data service addition quality level big data personal information protection strategy data disclosureaccountability strategy also needed achieve goal prevent problem performed case analysis based big data governance framework national pension south korea big data service sector inevitable choice improve quality people life big data governance framework essential component realization big data ,2
BD_220,seeing surveillance understanding poor security performance common problem security system although recent year significant progress achieved biometric identification technology progress single technology dramatically improve overall performance solve systemlevel problem social security currently addition improvement single technology following systemlevel technical bottleneck must solved improve overall performance social security blind spot perception exist surveillance area due nonoverlap surveillance sensor performance single identification technology decrease sharply complex surveillance scenario poor lighting condition disguise traditional warning technology become invalid due multistage nonstationary evolution feature complex event three challenge listed closely relate three scientific problem analysis technology big visual data three level sensing data identification technology pattern recognition aim exploiting complete mapping mechanism physical space multivariate sensing space fillin blind spot sensing data exploring correlative mechanism multimodal object multivariate sensing space improve analytical performance single identification technology studying spatialtemporal evolution mechanism entire lifecycle complex event extend pattern recognition local space time security space physical space comprehensive protective ability includes ubiquitous sensing reliable identification penetrating trend analysis approaching danger warning time location object behavior aiming build theory security space ided three level information acquisition perceptional computation scene analysis evolution prediction resource scheduling system application ided five task visual object recognition big data based identification situational awareness group multiscale revolution semantic analysis scene correlative computation multivariate space big scale visual retrieval security risk analysis warning system security space application corresponds first level sensing identification object basis analysis correspond second level since group behavior event scene evolution crucial prediction warning security event correspond third level order develop high performance computing platform conduct system evaluation application demonstration big visual data contains massive highdimensional sensing data implying complicated relationship among social object fact world data spatialtemporal relationship big data object essential causal relationship private implicit relationship compose core value big data social analysis analysis iniduals group scene big visual data based core element social security analysis social structure social activity support strategic transference urban security system investigation afterwards warning advance overall build big data analysis system security space realizing intelligent big visual data system support data analysis hundred billion feature data billion image data million visual sensing terminal expected achievement warning protection system large space reach international leading level based achievement project plan develop intelligent big data analysis product category expected benefit industrialization promotion reach billion promotes upstream downstream industry realize economic benefit billion also strive become internationally leading industry field big security data analysis ,2
BD_221,architecture system data management community pay greater attention innovative big data system architecture pressure benchmarking evaluating system rise however complexity ersity frequently changed workload rapid evolution big data system raise great challenge big data benchmarking considering broad big data system sake fairness big data benchmark must include ersity data workload prerequisite evaluating big data system architecture stateoftheart big data benchmarking effort target evaluating specific type application system software stack hence qualified serving purpose mentioned present joint research effort issue several industrial partner big data benchmark suitebigdatabench cover broad application scenario also includes erse representative data set currently choose big data benchmark dimension application scenario operation algorithm data type data source software stack application type comprehensive fairly measuring evaluating big data system architecture bigdatabench publicly available project home page httpprofictaccnbigdatabench also comprehensively characterize big data workload included bigdatabench varying data input typical stateofpractice processor intel xeon e following observation first comparison traditional benchmark including parsec hpcc speccpu big data application low operation intensity measure ratio total number instruction ided total byte number memory access second volume data input nonnegligible impact microarchitecture characteristic may impose challenge simulationbased big data architecture research last least corroborating observation cloudsuite dcbench smaller data input find number l instruction cache li miss per instruction short mpki big data application higher traditional benchmark also find l cache effective big data application corroborating observation dcbench ,2
BD_222,recent technology big data could used order help improvement field except telecommunication field due health field big data technology could contribute aim help analysis management huge amount health data objective research proposal analytical technology iot cloud computing cc largescale data big data resolve various issue facing health sector relation technology research proposal collection medical ehealth big data real time collection performed sensor device actuator wear patient suffer various ailment following transfer data network cloud server additionally data processed cloud make analysis become meaningless analysis data done data mining finally address various problem health sector transfer analyzed health data herecent technology big data could used order help improvement field except telecommunication field due health field big data technology could contribute aim help analysis management huge amount health data objective research proposal analytical technology iot cloud computing cc largescale data big data resolve various issue facing health sector relation technology research proposal collection medical ehealth big data real time collection performed sensor device actuator wear patient suffer various ailment following transfer data network cloud server additionally data processed cloud make analysis become meaningless analysis data done data mining finally address various problem health sector transfer analyzed health data held device relevant person also deal security medical data constitute personal data must protectedld device relevant person also deal security medical data constitute personal data must protected ,2
BD_223,big data owing fact creating massive amount data every day big data huge quantity data includes sort concept like social medium analytics nextgeneration datamanagement capability realtime data much contains structured unstructured data dealing large volume data extracting useful information knowledge big data infeasible many situation knowledge extraction process wellorganized close real time since storing pragmatic data almost infeasible unprecedented data volume require effective data analysis prediction platform achieve fast response realtime classification big data explore big data analyzed several challenge data model system level big data often stored different location data volume may continuously grow effective computing platform take distributed largescale data storage consideration computing key characteristic big data huge heterogeneous erse data source also autonomous distributed decentralized control complex evolve data knowledge association big data occupies medical area wide manner especially period pregnancy blood sugar woman go gestational diabetes occurs even woman diabetes need treatment diabetes pregnancy treated frequent checkup carried proper manner may lead serious problem mother baby discus big data big data medicine proposed solution lead maintain bloodglucose level pregnancy woman frequent checkup intimate relative friend regarding variation bloodglucose level internet connectivity ,2
BD_224,summary form given convergence multiple revolution internet data software computing hardware personalized attention transforming government across world provide service citizen remain relevant convergence multiple force enables government leverage big data smart data dark data leveraging concept big data big data provides holistic view citizen entity realtime delivery information protect citizen prevent fraud abuse country resource focus innovation strategy better faster decision government maximize benefit big data harnessing big data proven value many enterprise organization many pitfall pitfall avoid presented big data virtue narrow definition creates fear privacy security governance data one pillar big data virtual taking advantage pillar six pillar big data address governance privacy security aspect big data ,2
BD_225,living era big data age huge information big data incorporate endless information big data getting larger industry providing better business change world term predicting customer behaviour another buzz word day social network relation two obvious yet complicated big data social network interdependent data generating social networking site big data useful actual challenge big data collecting managing making sense working big data crucial part predicting whether bring money spent storage maintenance several tool designed better understanding huge data make better business researcher practitioner trying look future big data benefit taken large amount data hadoop mapreduce getting prominent field big data big data used several research area related healthcare location based service satellite information usage well online advertising retail marketing coming year internet thing iot increase amount data world exponential raise data noticed ,2
BD_226,disaster earthquake debris flow forest fire landslide etc lot people away home gather shelter addition refugee suffer shortage necessary resource due impaired life infrastructure damaged road communication network degree reducing damage depends amount food water daily necessity communication resource required shelter effectively efficiently allocate resource according grasp exact need disaster situation important issue estimate degree disaster collecting analyzing big data sn building platform communication resource efficiently effectively allocated order achieve goal challenging following issue understanding situation requirement disaster occur sn stream large scale semantic information real time situation society especially disaster domainspecific computational challenge processing heterogeneous large data set extract exact situational content reduced semantic uncertainty machine learning ml natural language processing npl tool kit useful semantic analysis still need domainspecific implementation computational improvement situation understanding sn big data b understanding distribution pattern situationsusers requirement disaster related situation spatiotemporally correlated varies dynamically space time also domainspecific computational challenge estimating spatiotemporal distribution pattern disaster affect based spatial big data sn scan statistic spatial scan provided well tested mathematical tool software spatial data mining however methodology necessary since assumption different meet spatial big data sn computational complexity spatial big data also bottleneck realtime processing c solving uncertainty big crowd data one major feature big crowd data eg sn data uncertainty behind data especially disaster scenario collecting time period long enough smooth data automatically efficiently solve uncertainty problem big crowd data disaster scenario becomes big challenge disaster management ,2
BD_227,follows first trying conceptualize big data social problem second would like explain difference big data conventional mega information third would like recommend role government utilization big data policy tool fourth referring copyright cclcreative common license case would like explain regulation big data data sovereignty finally would like suggest direction policy design big data result policy design big data distinguished policy design mega information solve data sovereignty issue law system perspective big data generated autonomously accessed openly shared without intention market perspective big data created without intention big data changed automatically case openness reference feature linked data policy issue responsibility authenticity raised big data generated distributed erse way without concrete form technology perspective need different approach ,2
BD_228,nowadays big data analytics broad area academia industry big data analytics attracted intense interest academia industry recently attempt extract knowledge information wisdom form big data big data cloud computing two important trend defining emerging analytical tool big data analytical capability cloud delivery model could ease adoption many industry important thinking cost saving could simplify useful insight could providing different kind competitive advantage many company provide online big data analytical tool top company like amazon big data analytics platform hive web based interface sap big data analytics ibm infosphere biginsights teradata big data analytics data big data platform cloudera big data solution etc company analyze huge amount data help different type tool also provide easy simple interface analyzing data deal big data v definition analysis requirement tool frame work different type cloud based big data analytics tool provide different company functioning hadoop mapreduce process ,2
BD_229,advancement technology data science network technology world stepped era big data medical field rich data suitable analysis thus recent year much research medical big data mainly targeting data collection data analysis visualization however work provide full survey medical big data chronic disease health monitoring investigates recent research effort conduct comprehensive overview medical big data especially related chronic disease health monitoring focus full cycle big data processing includes medical big data preprocessing big data tool algorithm big data visualization security issue big data also attempt combine common big data technology special medical need analyzing detail existing work medical big data best knowledge first survey target chronic disease health monitoring big data technology ,2
BD_230,big data security privacy key concern cloud computing initial stage security considered processing big data insufficient research adequate security technology researcher think way cloud storage big data security overcome exiting security challenge big data storage rapid big data processing encryption often considered big obstacle clear data processing much faster encrypted data cloud system encrypted data processing big deal massive processing power cloud system encryption obstacle degrade performance process encrypted big data cloud big challenge store provide security small chunk cloud system also key management provides novel approach big data security cloud namely secured high performance distributed big data storage shdbds model data split uploaded distributed cloud storage system single split data worthless unless joined part data algorithm provided split join data experimentation performed different data set mbgb local system aws cloud performance measured evaluation done considering security performance big data ,2
BD_231,increasing interest big data big data security development network technology cloud computing however big data entirely technology extension data mining describe background big data data mining big data feature propose attribute selection methodology protecting value big data extracting valuable information goal analyzing big data need protected therefore relevance attribute dataset important element big data analysis focus two thing firstly attribute relevance big data key element extracting information perspective studied secure big data protecting valuable information inside secondly impossible protect big data attribute consider big data single object attribute assume attribute higher relevance important attribute ,2
BD_232,summary form given security privacy big data primary concern many application example case smart meter data consumer must protected else private information leaked similarly due costefficiency reduced overhead management dynamic resource need content owner outsourcing data cloud act provider behalf however outsourcing data cloud owner may lose access control privacy data cloud becomes third party data storage service data owner relieve burden local data storage maintenance however since data owner cloud server trusted domain outsourced data may risk cloud server may longer fully trusted therefore data integrity critical importance cloud let owner trusted third party check integrity data storage without demanding local copy data owner often replicate data cloud server across multiple data center provide higher level scalability availability durability however data owner need strongly convinced cloud storing data copy agreed level contract dataupdates correctly executed remotely stored copy tutorial problem explored topic covered include security privacy issue big data management secure data processing access control big data cloud data integrity verification big data cloud security privacy sensing data big data application ,2
BD_233,abundance data many discipline science engineering national security health care business led emerging field big data analytics run cloud computing environment process massive quantity data cloud developer leverage dataintensive scalable computing disc system google mapreduce hadoop spark currently developer easy mean debug disc application cloud computing make application development feel like batch job nature debugging therefore postmortem developer big data application write code implement data processing pipeline test local workstation small sample data downloaded tbscale data warehouse cross finger hope program work expensive production cloud fails get suspicious result data scientist spend hour guessing source error digging postmortem log case data scientist may want pinpoint root cause error investigating subset corresponding input record vision provide interactive realtime automated debugging service big data processing program modern disc system minimum performance impact investigates following research question context big data analytics necessary debugging primitive interactive big data processing ? scalable fault localization algorithm needed help localize characterize root cause error ? improve testing efficiency iterative development disc application reasoning semantics dataflow operator userdefined function used inside dataflow operator tandem ? answer question synthesize innovate idea software engineering big data system program analysis coordinate innovation across software stack userfacing api way system infrastructure ,2
BD_234,development various technology field network technology also cloud computing also lot data involved thus concept big data introduced entirely technology extension data mining thus securing big data important well challenging since size data large possible secure whole big data therefore introducing big data security mechanism wherein first select certain attribute higher value rest secure turn provides security whole big data since selection mechanism relevance attribute dataset important therefore focus two thingsfirstly securing big data protecting valuable information inside secondly impossible protect big data attribute consider big data single object attribute assume attribute higher relevance important attribute focus securing data mobat technique propose data masking technique protect attribute data masking technique replace original set data another set data real realistic big data masked mathematical formula make modulus operator thus technique providing security big data ,2
BD_235,traditional data mining usually deal data single domain big data era facing ersity datasets different source different domain datasets consist multiple modality different representation distribution scale density big data volume range exabyte ten power eighteen large number data stored big data storage every second instance youtube every second video size hour uploaded show big data big scope handling large data big data learning intelligence data fusion social network mining many play vital role big data technology machine learning algorithm developed lot advanced development field social mining network social medias also developed many challenge data storage handling representation mining analysing behaviour many social mining text symbol also analysed effective mining user introduce highlevel principle category method also give example technique used handle real big data problem data storage size optimized map reduce algorithm effective way data storage big data repeateddatas replaced reference storage optimized thus method implementation lead effective data mining analysing person behaviour effectively ,2
BD_236,development information technology university library mass data university library basic characteristic big data however current situation university library lack distributed storage computing model massive data lack capacity handl erse data source including structured semistructured unstructured data lack simple flexible application model big data order solve problem innovation university library china problem distributed storage computation massive data distributed management erse data source simple flexible application big data service analyzes research content big data processing hadoop ecosystem demand big data service university library present technology framework big data university library based hadoop framework includes distributed storage parallel computing model mass data distributed management model erse data source model ersified application university library framework take full account innovation change university library environment big data data storage calculation data management application et al solve key technical problem big data university library certain extent ,2
BD_237,data becoming world natural resource big data grows quickly trend computing technology everything merged internet big data integrated comprise complete information collective intelligence increasing size big data refining big data reduce data size keeping critical data useful information approach direction provide novel data consumption model separate consumption data raw data thus enable cloud computing big data application define dataasaproduct daap concept data product small sized summary original data directly answer user query thus separate mining big data two class processing module refine module change raw big data small sized data product applicationoriented mining module discover desired knowledge application welldefined data product practice mining big stream data including medical sensor stream data stream text data trajectory data demonstrated efficiency precision daap model answering user query ,2
BD_238,world generating lot different kind data data analyzed processed valuable information traditional system like data base used store process failing handle huge data range tera peta byte also known bigdata many tool used analyze bigdata apache hadoop one used bigdata analyzing framework hadoop us large number library handle manage bigdata process also handle different kind failure may occur system us mapreduce programing paradigm analyze distributed processing storage bigdata bigdata ided different block distributed network mapper function run parallel block bigdata parse filter required data used processing reducer function accepts data mapper function process required expected result observed intermediate data generated mapper processing bigdata hence system redundant operation generates result efficient resource delay performance speed system proposed system creates novel cache store intermediate data mapper output novel cache whenever system need analyze bigdata set fetch already processed data novel cache rather running mapper function whole bigdata set ,2
BD_239,development cloud computing iot dataintensive application come import process big data dataintensive application analysis basic concept big data semantic++ computing includes definition big data semantic computing semantic++ computing make detail analysis semantic++ understanding based big data mainly includes semantic++ storage big data resource semantic++ information acquirement big data resource semantic++ resource management semantic++ processing big data semantic++ big data semantic++ security privacy big data semantic++ interface application based big data two kind semantic++ application proposed semantic++ search recommendation system framework analyzed finally simulation experiment show semantic++ search recommendation method efficient traditional method ,2
BD_240,inventory warehouse system backoffice application dealing supplier essential application supporting front office application coping daily customer transaction increase inventory warehouse system performance business process online transactional processing oltp separated reporting process online analytical processing olap application big data current alluring technology undoubtedly top choice intelligent application implementation understand big data refer previous technology big data metamorphosis last olap technology data warehouse ds eis bi thus since big data metamorphosis previous technology apply big data olap process create intelligent application support reporting decisionmaking process big data implementation running one single nodecomputer hadoop window x installed proposed big data application split two subprocesses big data process big data result big data process read oltp database export input text file text file processed mapreduce algorithm import output text file meanwhile big data result show summarization map reduce process output text file ,2
BD_241,proposes method determining degree big data complexity based hierarchical structure group cluster big data method determining degree big data complexity us tree structure hierarchical group cluster attribute big data number group greater equal number cluster big data level layer group cluster determined tree structure big data grouping level defined last level leaf tree structure clustering level defined first level leaf tree structure degree big data complexity defined difference grouping level clustering level defines method determining degree big data complexity ii finding level layer big data complexity iii visualization big data complexity ,2
BD_242,summary form given big data cognitive computing driving fundamental change technology business society exponentially increasing volume velocity variety big data hailed world natural resource promise st century steam power th electricity th oil gas th biggest value big data lie deep actionable insight derived raw data leveraged competitive advantage cognitive computing key enabling technology turning big data insight different traditional programmable system cognitive system able scale extend human knowledge reason learn improve time rise cognitive system represents dawn era computing whose focus shifted automating world understanding world talk discus implication big data cognitive computing reflect experience ibm building watson health cloud discus big data cognitive computing come together enable innovative health solution tackle many clinical societal economic issue faced today health industry case highlight challenge describe approach relate client experience appropriate ,2
BD_243,nowadays big data analysis widely used information telecommunication domain benefit big data analysis telecommunication operator internet provider could analyze user interest effective predict user expectation accurate thus significant improve add value service identity management big data analysis application requirement considering characteristic big data analyzed requirement identity management big data analysis based general identity management model intention compatible advanced ersity identity management technology refer itut recommendation baseline capability enhanced global identity management interoperability analyze identity management capability general identity management model according analysis general identity model satisfy identity management capability required itut standard since design model based specific requirement characteristic big data analysis application prototype general identity management model used big data analysis also guide system design big data security ,2
BD_244,recent year big data technology draw wide attention academic industry patent analysis widely viewed one major tool tracking development technology traditional patent analysis method given keywords used query big data patent information related patent web site analyze trend big data big data technique involved lot application different patent applicant different subjectivity setting keywords view problem proposed method patent analysis big data precise way based analysis big data patent abstract china domestic method extracted keywords abstract big data patent document obtain accurate data deeper analysis patent found development big data china domestic ided two distinct stage entered quickly growth stage industry development faster academic community huawei quantity patent application serious unbalance development big data technology china development eastern region far beyond western region finding suggest government pay great attention imbalanced development big data increase support backward area also development big data expected improve government decisionmaking capability level ,2
BD_245,present key technology big data based condition monitoring power apparatus firstly characteristic big data big data power system discussed application prospect big data based condition monitoring power apparatus presented key technology system discussed term big data analyzing technology big data management technology big data processing technology big data visualization technology thirdly big data based condition assessment technique power apparatus discussed including data fusion signal collected different sensor historical trending analysis association analysis combined equipment finally introduce big data technique integrated condition monitoring system transformer gi power cable presented including system hardware structure big data based condition assessment ,2
BD_246,big data growing area information technology science need intellectual understanding interpretation theoretical philosophical societal perspective philosophy big data branch philosophy concerned foundation method implication big data definition meaning conceptualization knowledge possibility truth standard practice situation involving verylarge data set big volume velocity variety veracity variability philosophy big data evolving discipline two level one internal field generalized articulation concept theory system comprise overall conduct big data science external field consideration impact big data science broadly iniduals society world method tool concept evaluated level industry practice theory social impact three aspect considered might constitute philosophy big data discipline philosophy information philosophy big data developing example philosophy big data application dataintensive science field synthetic biology overall philosophy big data might helpful conceptualizing realizing big data science practice also transitioning datarich future human data entity productively coexisting mutual growth collaboration ,2
BD_247,base openstack private cloud delivery big data platform numerous entity yearn attaining agile standardized big data delivery platform reclaiming resource managing total cost ownership tco adapting multiple big data source commercial offtheshelf cot solution nevertheless regard big data platform running cloud computing big data platform disintegrated cloud computing system virtual machine since neither based openstack private cloud big data platform achieve endtoend resource delivery together ensuring quite convenient longterm operation accordingly establishing across framework private cloud big data platform quite essential big data cloud agile provision framework could realize fast resource delivery based predefined orchestration template private cloud operating system big data platform monitor inspection system etc deployment framework capable attaining delivery agile low cost standardized high adaptability big data cloud well highquality operation big data cloud help integration configuration management database cmdb automatic inspection system ,2
BD_248,impact big data although insubstantial inception however gradually originated make significant contribution variety sphere life development smart city big data ebusiness big data health care sector big data environmental science implementation big data area indisputably revealed critic achieved big data big data undeniably paradigm shift perception way understanding studying world big data utilized analyze fine grained data private big data utilization education sector relatively le started growing gradually matter fact big data effectively utilized improve education delivery equally utilized provide decision support higher management attain excellence field education research mere effort explore various possibility big data utilization educational establishment implication ,2
BD_249,summary form given big data hot topic still full mystery u realize multiple application various domain human endeavor business science engineering social security get know embrace power explain distinguishes big data data big data change way thinking even technology realization big data requires tight coupling idea data technology harvest deep insight great value big data many real example research team give audience glimpse great promise big data finally address government harness superabundant opportunity big data era ,2
BD_250,web massive amount usergenerated content available various channel eg text tweet web table database multimediasharing platform etc conflicting information rumor erroneous fake content easily spread across multiple source making hard distinguish true monograph give overview fundamental issue recent contribution ascertaining veracity data era big data text organized six chapter focusing structured data extracted text chapter one introduces problem ascertaining veracity data multisource evolving context issue related information extraction presented chapter two followed practical technique evaluating data source reputation authoritativeness chapter three including model bayesian approach trust management current truth discovery computation algorithm presented detail chapter four theoretical foundation various approach modeling diffusion phenomenon misinformation spreading networked system studied chapter five finally truth discovery computation extracted data dynamic context misinformation propagation raise interesting challenge explored chapter six supplementary material including source code datasets slide offered online text intended seminar course graduate level also serve useful resource researcher practitioner interested factchecking truth discovery rumor spreading ,2
BD_251,volume data world growing fast generated verity source like social medium sensor airline industry scientific data different format biggest challenge infer meaningful insight varietyful big data concern data storage management fast growing data size database used today enterprise growing exponential rate day day hence industry requirement quickly process analyze big data volume business decision making customer insight also grown exponentially data pouring various source may structured unstructured nature structured data refers relatively wellorganized information inserted traditional rdbms traditional rdbms efficient easy query simple straightforward search algorithm sql query contrast structured data unstructured data considered information come predefined data format well organized data storage model stored well relational table assumed fastest growing type data eg image sensor data web chat social networking messaging data video document log file email data many technique software available process provide efficient storage unstructured data help organization perform analytics unstructured data unstructured data wellorganized stored predefined manner eg log web chat variety ordered nature data make storage method structure make execution time resourceconsuming affair advancement technology floodgate push huge volume unstructured type data multimedia data one example unstructured big data span internet need high execution capability extract useful information rapid processing multimedia data video important eg criminal investigation surveillance monitoring news analysis sport analytics domain emotion extraction etc hence analysis multimedia data minimum timeframe one latest research area therefore researched technique analyzing unstructured data extract meaningful information hidden big data addition describe various technique software used manage process unstructured big data efficient manner increase performance complexity analysis ,2
BD_252,cyberphysicalsocial big data generated ubiquitous device erse space generally multisource heterogeneous deeply intertwined efficiently analyze handle ubiquitous cyberphysicalsocial big data tensor considered effective tool curse dimensionality still bottleneck tensorbased big data analysis tensor network considerably alleviate overcome tensor approximate theory therefore focus developing efficient big data processing framework based tensor network providing incremental tensor train decomposition approach streaming big data concretely first present hierarchical cyberphysicalsocial big data processing framework composed three plane namely data representation decomposition data storage processing data analysis tensor train tt quantized tt decomposition particularly introduced remarkably overcome curse dimensionality furthermore efficiently handle continuous streaming big data avoid repeated decomposition history data incremental tensor train decomposition ittd approach proposed complexity analyzed detail experimental result demonstrate ittd demonstrably outperforms nonincremental tt decomposition execution time precise guaranteeing nearly equal approximation error ,2
BD_253,rapid evolvement internet data acquisition technology well continuous advancement science technology amount data many field reached level terabyte petabyte data collection come internet thing iot rapid advancement iot big data provided valuable opportunity development people area society time also brought severe challenge various type current information processing system effectively big data technology discovering hidden law big data tapping potential value big data predicting development trend thing allocate resource reasonably promote overall development society however iot big data presented heterogeneous data high dimension different form expression lot redundant information current machine learning model work vector space make impossible gain big data feature vector simulate highly nonlinear distribution iot big data present deep learning calculation model called tensor deep learning tdl improves big data feature learning highlevel feature fusion us tensor model complexity multisource heterogeneous data extends vector space data tensor space feature extraction tensor space included fully understand underlying data distribution tensor distance adopted average square sum error term output layer reconstruction error based conventional backpropagation algorithm proposes highorder backpropagation algorithm extend data linear space multiple linear space train parameter proposed model evaluate performance proposed tdl model compared stacked auto encoder multimodal deep learning model furthermore experiment performed two representative datasets namely cuave stl experimental result show proposed model excels heterogeneous data fusion also provides higher recognition accuracy conventional deep learning model multimodal learning model big data ,2
BD_254,contemporary society supply chain becoming complex data supply chain increase mean volume variety velocity big data rise response proper time condition offer advantage node supply chain solve prewiously difficult problem big data project succeed must first depend highquality data merely quantity become increasingly important many big data project add external data mix company eventually turn looking inward also looking outward market mean big data must broadened considerably hence data supply chain internally externally become prime importance ict information telecommunication supply chain management especially important supply chain link world closely ict supply chain base supply chain today world though many initiative supply chain security developed taken practice emphasized physical supply chain addressed transporting cargo research ict supply chain security still preliminary stage big data promote normal operation ict supply chain greatly improve data collecting processing capacity turn ict supply chain necessary carrier big data produce software hardware infrastructure big data collection storage application close relationship big data ict supply chain make effective way research big data security analysis ict supply chain security first analyzes security problem ict supply chain facing information management system integrity cyberspace introduces several famous international model physical supply chain ict supply chain author describe case communication equipment big data ict supply chain propose series recommendation conducive developing secure big data supply chain five dimension ,2
BD_255,current era big data high volume wide variety valuable data easily collected generated broad range data source different veracity high velocity due wellknown v big data many traditional data management approach may suitable handling big data past year several application system developed cluster cloud grid computing manage big data support data science big data analytics well knowledge discovery data mining focus distributed big data management specifically method big data representation management distributed big data social network represent big graph data distributed setting support big data mining frequently occurring pattern social network ,2
BD_256,rapid development big data technology rapid growth big data industry market big data talent demand also substantial increase china order cultivate talented people satisfying need community designed big data course undergraduate big data course stress many theory also lot practice project big data talent development trend analysis designed experimental teaching big data project student master technology big data processing lifecycle including data collection data preprocessing data mining data visualization evaluate student master big data core technology multievaluation method design experiment evaluation system big data two year practice result show design achieved good effect improved teaching quality ,2
BD_257,big data name implies data thats large nature known big data big data used describe large volume structure way big data concern largeamount complex growing data set multiple autonomous source networking data storage data collection capacity data rapidly expanding science engineering stream including physical biological medical science different company different technology maintain big data technology make possible appreciate value big data instance retailer follow web click recognize behavioral trend develop campaign stock age utility detain household energy convention level predict outage invent efficient energy consumption government still google distinguish follow emergence bug outbreak social medium signal gas oil company receive output sensor drilling apparatus make additional capable safer drilling decision big data show data set huge composite unreasonable deal conventional software tool overview big data substance variety simple procedure advantage security challenge maintains big data discus privacy concern ,2
BD_258,big data denotes data volume range zettabyte beyond world technological percapita capacity store information roughly doubled every month since every day exabyte × data created every day zettabyte × data created every nasa national science foundation host contest across scientific community result often resonating academic business world latest challenge organization pull together right data variety source performing analysis drawing conclusion making decision ? sound like big data right ? encountered many limitation due advancement large set data generated captured science engineering technology various social economical human activity limitation also affect internet search finance business informatics big data world gotten far complex manager charge keeping business moving forward simplify architecture operation raising value innovative tool youve crafted meet business goal ? make dissimilar data set uniformly accessible ? extract relevant information fast scalable consistent way ? first focus various dimension big data big data analysis highlight major issue dimension took close look inconsistency big data effect outcome big data analysis discussed comparison enterprise big data analytical tool source big data analytical tool selecting right kind tool big data analytics finally conclude remark future ,2
BD_259,recent year due development pervasiveness information communication technology ict data generated tremendously increasing rate various type data source massive amount data widely referred big data contains large amount hidden rich information uncovering valuable information big data service envisioned bring huge potential commerce business research fact series sophisticated process involved big data service however exists structural gap holding back development big data service fourlayer cloudbased network architecture proposed support big data service proposed network architecture provides systematic efficient approach big data access storage retrieval specifically process supporting big data service categorized data transfer data collection data processing data retrieval furthermore cloudbased architecture presented followed closer look network architecture big data collection device level ,2
BD_260,ability collect analyze large amount data growing problem scientific community growing gap data user call innovative tool address challenge faced big data volume velocity variety one challenge associated big data variety automatically understanding underlying structure pattern data understanding required prerequisite application advanced analytics data big data set often contain anomaly error difficult know priori current approach understanding data structure drawn traditional database ontology design approach effective often require much human involvement effective volume velocity variety data encountered big data system dimensional data analysis dda proposed technique allows big data analyst quickly understand overall structure big dataset determine anomaly dda exploit structure exist wide class data quickly determine nature data statical anomaly dda leverage existing schema employed big data database today present dda applies number data set measure performance overhead dda low applied existing big data system without greatly impacting computing requirement ,2
BD_261,recent tremendous increase huge amount xml data web lead development technology special characteristic xml flexible structure make xml widely used data format big data generally refers large amount data type size xml data increased xml big data take advantage considering xml big data hence innovative technology essential handle xml big data therefore necessary technology emphasize storage management xml big data elucidate fundamental feature xml big data important aspect survey consideration storage technology xml big data realtime application provides latest technology store process manage xml big data efficiently particular outline efficient storage technology applied support xml big data whole based current technology literature enumerates xml big data storage technology available realworld application ,2
BD_262,big data driven cyber physical system make large amount data determine operation data clearly crucial correct operation big data driven cyber physical system example include aerospace system air traffic control system railway signaling system intelligent transportation battlefield management system big data driven cyber physical system used safetyrelated application safety overall system determined property constituent part correctness data also essential system going achieve overall safety therefore one key challenge providing specification modeling method data service big data driven cyber physical system big data driven cyber physical system deal large amount data timely secure fashion propose big data driven cyber physical system design method based aadl specify model requirement big data driven cyber physical system implement requirement big data platform advantage proposed approach capacity take account big data property cyber physical system property specialized concept rigorous easy expressive manner proposed approach illustrated case specifying modeling aviation cyber physical system ,2
BD_263,storing analyzing accessing data growing problem organization competitive pressure regulation requiring organization efficiently handle increasing volume variety data doesnt come cheap demand big data exceed constraint traditional relational database evaluating legacy infrastructure assessing technology become necessity organization gain competitive advantage also compliance purpose challenge well organization legacy infrastructure integrates big data without doubt one way another big data must accommodated legacy system legacy system contain significant invaluable business logic organization organization afford throw away replace business logic legacy system asset organization invaluable asset encoded ` business logic represent many year coding development reallife experience enhancement modification debugging etc legacy system developed without process model data model needed support integrate big data integrate big data legacy system modernization legacy system required many approach modernization legacy system none focused integrating big data legacy system legacy system hold valuable data important lost process modernization however addressing issue scope related incorporating big data legacy system allows mature legacy system become part groundswell change many area unaddressed integration big data legacy system incorporating data source specifically source existing legacy system technical challenge moreover sheer volume big data daunting present scope integrating big data modernization legacy system ,2
BD_264,living era big data high volume wide variety data may different veracity eg precise data imprecise uncertain data easily generated collected high velocity many reallife application embedded big data valuable knowledge useful information discovered big data science solution popular data science frequent pattern mining aim discover implicit previously unknown potentially useful information valuable knowledge term set frequently cooccurring merchandise item andor event many existing frequent pattern mining algorithm transactioncentric mining approach find frequent pattern precise data however situation itemcentric mining approach appropriate also situation data imprecise uncertain hence itemcentric algorithm mining frequent pattern big uncertain datain recent year big data gaining attention research community driven relevant technological innovation eg cloud novel paradigm eg social network big data typically published online support knowledge management fruition process big data usually handled multiple owner possible secure multipart computation issue thus privacy security big data become fundamental problem research context itemcentric algorithm mining frequent pattern big uncertain data also privacypreserving algorithm word present— paper—a privacypreserving itemcentric algorithm mining frequent pattern big uncertain data result analytical empirical evaluation show effectiveness algorithm mining frequent pattern big uncertain data privacypreserving manner ,2
BD_265,quality big data could great impact value extracted data automated filtering noisy data big data ideal approach improving quality big data however due large volume variety big data automated filtering noisy data big data grand challenging propose support vector machine based approach automated classification big data noisy data classified separated category regular data order improve classification accuracy training performance design experiment improving classification model finding optimized learning feature set approach iteratively improving quality training data set conducted thorough experimental automated classification massive image data biology cell explain approach automated selection big data demonstrate effectiveness finally compare performance svm based classification deep learning based classification data set proposed approach experience collected experimental help big data researcher practitioner design strategy improving quality big data designing high performance classifier building tool automated selection big data ,2
BD_266,recent technological advancement led deluge data distinctive domain eg health care scientific sensor usergenerated data internet financial company supply chain system past two decade term big data coined capture meaning emerging trend addition sheer volume big data also exhibit unique characteristic compared traditional data instance big data commonly unstructured require realtime analysis development call system architecture data acquisition transmission storage largescale data processing mechanism literature survey system tutorial big data analytics platform aiming provide overall picture nonexpert reader instill doityourself spirit advanced audience customize bigdata solution first definition big data discus big data challenge next systematic framework decompose big data system four sequential module namely data generation data acquisition data storage data analytics four module form big data value chain following detailed survey numerous approach mechanism research industry community addition prevalent hadoop framework addressing big data challenge finally outline several evaluation benchmark potential research direction big data system ,2
BD_267,overhead burden managing data complex process numerous dataproducing computational step become gating factor determines pace virtual organization constriction lack comprehensive system capture manage organize retrieve data throughout virtual organization constriction life cycle lead significant overhead scientist time effort reduced productivity lack reproducibility absence data sharing constriction life cycle collecting massive amount data people action sensor algorithm web handling big data become major challenge question still exists regarding data may called big data large big data ? correlation big data business intelligence ? optimal solution storing editing retrieving analyzing maintaining recovering big data ? cloud computing help handling big data issue ? role cloud based architecture handling big data ? important big data business intelligence ? ,2
BD_268,large number structured unstructured data core big data organization institution potentially analysis business well requirement big data platform data information basically come different source importantly collected outcome scientific experiment used internet thing big data system data may treated source intelligent system mechanism separate software tool analytics important fact technology rising everyday eg social medium creation information take second user data science program another terminology big data data science also referred business analytics simply analytics domain several application big data found different sector include healthcare banking finance information foundation well corporate sector currently shortage data scientist analyst experience working big data medical emerging area application cloud based highly noticed day moreover analyzing big data management system help managing information multiple scale health care include particular disease detailed dna protein metabolite cell tissue organ organism ecosystem conceptual also kind policy several general aspect big data focused medical system illustrated also explores potentiality creating manpower medical informatics similar professional adequate knowledge big data analytics technology ,2
BD_269,many sector taking interest big data due huge potential associated big data big data demand large computing power distributed storage handle data problem cloud provides elastic ondemand compute power storage big data cloud data center act infrastructure layer big data volume big data increasing high speed cloud data center also scaling consume huge amount energy provide infrastructure layer big data continuously aim extensively cover big data efficiently utilize cloud data center big data virtualization energy saved ,2
BD_270,big data term defining data three characteristic first involves great volume data second data structured regular database table third data produced great velocity must captured processed rapidly oracle add fourth characteristic kind data low value density meaning sometimes big volume data process finding valuable needed information big data relatively term came need big company like yahoo google facebook analyze big amount unstructured data need could identified number big enterprise well research development field framework processing big data consists number software tool presented briefly listed hadoop source platform consists hadoop kernel hadoop distributed file system hdfs mapreduce several related instrument two problem occur studying big data storage capacity processing power area grid technology provide help grid computing refers special kind distributed computing grid computing system must contain computing element ce number storage element se worker node wn ce provides connection grid network us workload management system dispatch job worker node storage element charge storage input output data needed execution article way processing big data grid technology framework managing big data presented way implement around grid architecture ,2
BD_271,prevalence computing cloud computing service emerging internet generating huge volume data trace log qos information relationship etc overwhelming servicegenerated data become large complex effectively processed traditional approach store manage create value serviceoriented big data become important research problem hand increasingly large amount data single infrastructure provides common functionality managing analyzing different type servicegenerated big data urgently required address challenge provides overview servicegenerated big data big dataasaservice first three type servicegenerated big data exploited enhance system performance big dataasaservice including big data infrastructureasaservice big data platformasaservice big data analytics softwareasaservice employed provide common big data related service eg accessing servicegenerated big data data analytics result user enhance efficiency reduce cost ,2
BD_272,big data refers large complex data four characteristic volume variety velocity veracity typically different type big data structured semistructured unstructured last two pose challenge application query processing especially query processing semistructured data enormously challenging big data characteristic documented large volume literature however comprehensive discussion characteristic specific type big data missing therefore solid understanding characteristic sine quo non process complex query efficiently big data generic term categorise big data instead focus big linked data called blinked data variant big semistructured data set characteristic critical modeling processing investigate characteristic challenge blinked data aim provide comprehensive description concept blinked data addition research present challenge processing query blinked data empirical ,2
BD_273,recently high resolution high precision telescope developing world ska arecibo alma muser aid modern telescope human acquired indepth knowledge universe meanwhile big data challenge raised astronomical big data processing example mingantu spectral radioheliograph muser record tb raw data per month solar radio observation big data firstly cause big challenge archiving classifying recorded data especially need fast processing daily recorded data traditional data processing usually implemented manually emergence big data longer applicable current big data urgent develop automatic algorithm processing daily recorded data efficiently timely secondly big data also cause great difficulty storage transmission data data compression highly desirable report effort big data archiving classification activity forecast machine learning especially deep learning ,2
BD_274,big data analytics workflow long complex many program tool script interacting together general modern organization significant amount big data analytics processing performed outside database system creates many issue manage process big data analytics workflow general data preprocessing timeconsuming big data analytics workflow defend idea preprocessing computing model scoring data set inside database system addition discus recommendation experience improve big data analytics workflow pushing data preprocessing ie data cleaning aggregation column transformation database system discussion practical issue common solution transforming preparing data set improve big data analytics workflow case validation based experience reallife big data analytics project compare pro con running big data analytics workflow inside outside database system highlight task big data analytics workflow easier manage faster processed database system compared external processing ,2
BD_275,many internetbased application generate huge data stream known big data stream application comprise iotbased monitoring system data analytics monitoring online learning workspace moocs global flight monitoring system etc differently big data processing data available database file system etc processing big data stream data stream unbounded processed becomes available besides challenge processing huge amount data big data stream processing add challenge coping scalability high throughput enable real time decision taking big data processing mapreduce framework resulted successful batch mode processing show limitation process big data stream therefore proposed alternative framework yahoo ! twitter storm etc big data stream processing implement evaluate yahoo ! big data stream processing exemplify big data stream global flight monitoring system ,2
BD_276,usaf sponsored mitre research team undertook four separate domainspecific case study big data application case study initial investigation question whether data quality issue encountered big data collection substantially different cause manifestation detection data quality issue encountered traditionally sized data collection address several factor affecting big data quality multiple level including collection processing storage though unexpected key finding reinforce primary factor affecting big data reside limitation complexity involved handling big data maintaining integrity concern higher magnitude provenance data processing tool used prepare manipulate store data data quality extremely important data analytics problem study finding truth big data fundamentally dq issue big data analytics project dq issue exhibit returnstoscale effect become le pronounced big data analytics though big data quality varies one type big data another one big data technology another ,2
BD_277,big data business leverage benefit cloud optimized shared automated virtualized computing infrastructure one important challenge processing big data cloud effectively partition big data ensure efficient distributed processing data scalable yet customizable data partitioning framework called spa distributed processing big rdf graph data choose big rdf datasets focus investigation two reason first linking data cloud put forward good number big rdf datasets ten billion triple hundred million link second huge rdf graph easily overwhelm single server due limited memory cpu capacity exceed processing capacity many conventional data processing software system data partitioning framework two unique feature first introduce suite vertexcentric data partitioning building block allow efficient yet customizable partitioning large heterogeneous rdf graph data efficient mean spa data partition support fast processing big data different size complexity customizable mean spa partition adaptive different query type second propose selection scalable technique distribute building block partition across cluster compute node manner minimizes internode communication cost localizing query distributed partition evaluate data partitioning framework algorithm extensive experiment benchmark real datasets experimental result show spa data partitioning framework efficient partitioning distributing big rdf datasets erse size structure also effective processing big data query different type complexity ,2
BD_278,ondemand oncommand digital universe data prolifering institution iniduals machine high rate data category big data due sheer volume variety velocity data unstructured quasi structured semi structured heterogeneous nature volume heterogeneity data speed generated make difficult computing infrastructure manage big data traditional data management warehousing analysis system fall short tool analyze data due specific nature big data stored distributed file system architecture hadoop hdfs apache widely used storing managing big data analyzing big data challenging involves large distributed file system fault tolerant flexible scalable map reduce widely used efficient analysis big data traditional dbms technique like join indexing technique like graph search used classification clustering big data technique adopted used map reduce suggest various method catering problem hand map reduce framework hadoop distributed file system hdfs map reduce minimization technique make file indexing mapping sorting shuffling finally reducing map reduce technique studied implemented big data analysis hdfs ,2
BD_279,intelligent transportation system concept introduced increase road safety manage traffic efficiently preserve green environment nowadays application becoming dataintensive data described v big data thus fully utilize data big data analytics need applied internet vehicle iov connects device cloud computing centre data processing performed however transferring huge amount data geographically distributed device creates network overhead bottleneck consumes network resource addition following centralized approach process big data result high latency tolerated delaysensitive application fog computing considered promising technology realtime big data analytics basically fog technology complement role cloud computing distributes data processing edge network provides faster response application query save network resource however implementing fog computing lambda architecture realtime big data processing challenging iov dynamic environment regard novel architecture realtime big data analytics iov environment proposed proposed architecture merges three dimension including intelligent computing ie cloud fog computing dimension realtime big data analytics dimension iov dimension moreover give comprehensive description iov environment big data characteristic lambda architecture realtime big data analytics several intelligent computing technology importantly discus opportunity challenge face implementation fog computing realtime big data analytics iov environment finally critical issue future research direction section discus issue considered order efficiently implement proposed architecture ,2
BD_280,advancement technology industry ecommerce research large amount complex pervasive digital data generated increasing exponential rate often termed big data traditional data storage system able handle big data also analyzing big data becomes challenge thus handled traditional analytic tool cloud computing resolve problem handling storage analyzing big data distributes big data cloudlets doubt cloud computing best answer available problem big data storage analysis said potential risk security big data storage cloud computing need addressed data privacy one major issue storing big data cloud environment data mining based attack major threat data allows adversary unauthorized infer valuable sensitive information analyzing result generated computation performed raw data thesis proposes secure kmeans data mining approach assuming data distributed among different host preserving privacy data approach able maintain correctness validity existing kmeans generate final result even distributed environment ,2
BD_281,big data matter size emerging paradigm data large size volume fast inout velocity various source variety high value knowledge extraction decision making technological advance data gathering led rapid proliferation big data erse area remote sensing medicine internet social sector data brings opportunity challenge scientist engineer order u make massive amount data data management computational approach needed permit scientist engineer analyze data nearly real time often distributed streaming manner various technology discussed realized support handling big data addition big dataset stored one location massively parallel processing database scalable storage system designed store large datasets big data generates industry supporting architecture many cloud computing platform framework developed handle big data operation mapreduce deal different property big data different algorithm also need developed overall big data opportunity find insight emerging type data content make model agile answer question previously considered beyond reach special highlight recent advancement address challenge big data era ,2
BD_282,agrogeoinformatics deal collecting managing analyzing agriculturalrelated geospatial data domainspecific big data discus general characteristic big data specific feature agrogeoinformatics agrogeodata example agrogeoinformatics project dealing big agrogeodata adoption adaptation process general big data technology useful agrogeoinformatics solve technology need dealing big agrogeodata development agrospecific big data technology necessary supplement adoption general big data technology combination adoption general big data technology development agrospecific big data technology prof good strategy applying big data technology agrogeoinformatics ,2
BD_283,driven innovation mass customisation complex supply chain smart city emerging cyberphysical internet thing system big data presenting fascinating range challenge analytics field emerging big data analytics data science modeling & amp simulation & amp core analytics arguably contemporary & amp practice deal demand big data implication & amp may feature big data analytics technique tool future based recent experience ims fp european cloudbased simulation platform manufacturing engineering cloudsme associated industrial project talk outline key challenge big data & amp strongly argue & amp get big meet challenge exciting opportunity lie ahead multidisciplinary team practitioner researcher orms computer science domain specific field indeed big simulation present possibility talk conclude thought potential big simulation analytics move beyond big data future dynamic data driven application system ,2
BD_284,big data era telecom operator massive data resource call data online data location data network performance data data reach pb level distributed ne interface effectively carry collection parsing analysis amount data support network construction maintenance optimization major opportunity challenge telecom operator face proposes big data platform bdp solve problem telecom industry collection telecom network data bdp realize data parsing storage analysis mrmeasure cdrcall detail record omcoperation maintenance centre data etc achieve unified storage management type data based bdp operator carry big data analysis data mining realize value data finally build testing platform bdp test performance big data loading big data analysis result experiment show performance data loading analysis bdp better traditional data warehouse applied telecom operator foundational infrastructure carry future application big data ,2
BD_285,data valuable asset company proud quality degrades consequence unpredictable lead complete wrong insight big data context evaluating data quality challenging must done prior big data analytics providing data quality confidence given huge data size fast generation requires mechanism strategy evaluate ass data quality fast efficient way however checking quality big data costly process applied entire data propose efficient data quality evaluation scheme applying sampling strategy big data set sampling reduce data size representative population sample fast quality evaluation evaluation targeted data quality dimension like completeness consistency experimentation conducted sleep disorder data set applying big data bootstrap sampling technique result showed mean quality score sample representative original data illustrate importance sampling reduce computing cost big data quality evaluation concerned applied quality result generated quality proposal original data increase quality ,2
BD_286,introduce distributed deep learning platform baipas big data ai based predication analysis system case deep learning big data take much time train data reduce training time method us distributed deep learning big data exists external storage training take long time take lot network io time data loaded deep learning operation propose data locality management way reduce training time big data baipas distributed deep learning platform aim provide quick learning big data easy installation monitoring platform convenience developer deep learning model order provide fast training big data data distributed stored workerserver storage data locality shuffling training performed data locality manager analyzes training data state information worker server distributes data scheduling according available storage space worker server learning performance worker server however worker server conduct deep learning distributed training data model overfitting may occur compared method learning full training data set solve problem applied shuffling method move already learned data another worker server training performed thereby worker server contain full training data set baipas us kubernetes docker provide easy installation monitoring platform also provides preprocessing module management tool automation cluster creation resource monitoring resource developer easily develop deep learning model ,2
BD_287,focused topic big data management social networking site big data large term larger data traditional data processing technique unable handle analysis big data managed social networking site like facebook twitter done analysis medium content immense social networking site adding additionally massive chunk data like data source information produced collected sn structured also enormously large volume difficult handle human large quantity data structured managing huge amount data need big data management analyze social networking site like facebook billion active monthly user twitter million user us hadoop data analysis technology like mapreduce pig hive big data management facebook see big stats system process nearly billion content five hundred terabyte data every day almost billion like around three hundred million photo daily loaded user scan almost hundred five terabyte data every thirty minute enormous amount data facebook us hive store data hdfs hadoop distributed file system contrary twitter large data storage processing worked implement set solution storage inside hadoop store data lzo compressed compression sustains good balance speed compression ratio hadoop ,2
BD_288,rapid moving technology need respond massive change big data create another challenge government make deal huge amount data easier implement effectively multichannel platform digital transformation need technology social medium eparticipation tool model data generate big data also added challenge addition slow adoption sector citizen concept openness effective interaction electronic technology citizen improvement eparticipation process government innovation citizen satisfaction government need enhance collaboration engagement well need improve value delivers inside outside government sector also satisfies citizen demand better service collecting data citizen activity egovernment utilizing big data technology offer effective technology provide interactive service egovernment big data term big data must used egovernment author explore big data issue applied egovernment well challenge issue facing agency proposed possible solution challenge implementing big data egovernment recently published paper clearly show challenge difficult growing term big data increasing exponentially ,2
BD_289,describes general architecture functional component cloud based big data infrastructure bdi proposed bdi architecture based analysis emerging big data data intensive technology supported definition big data architecture framework bdaf defines following component big data technology big data definition data management including data lifecycle data structure big data infrastructure generically cloud based data analytics technology platform big data security compliance privacy provides example requirement analysis implementation two bioinformatics case cloud slipstream based cloud application deployment management automation platform developed cyclone project also refers importance standardisation component bdaf bdi provides short overview nist big data interoperability framework bdif discus importance automation stage big data application development deployment management refers existing cloud automation tool development slipstream cloud automation platform allows multicloud application deployment management ,2
BD_290,nowadays big data received attention researcher business industry education scientific community big data analytics deal large scale data consist structured unstructured data data handled properly extracting processing analyzing data obtain meaningful information limited time yield insightful information processing big data analytics requires high performance computing system storage network resource hence essential design high performance computing infrastructure sufficient bandwidth capable handle big data processing efficient manner however current network architecture infrastructure predefined network policy allow justintime reconfiguration networking infrastructure demanded big data analytics addressing limitation softwaredefined networking sdn offer mean dynamically configure network parameter dynamically provision network network sliced ondemand manner research aim characterize sdn respect demand big data analytics cluster grid cloud computing resource motivation behind research design develop intelligent framework named big data analytics management system bdams collectively managing compute storage network resource cluster grid cloud infrastructure big data analytics ,2
BD_291,last year global development characterized mass introduction information communication technology sphere economic development implementation digital technology acquired explosive character recently coincidence term digital economy indicating advanced digital technology various sector world economy emerged past year today digital transformation occurs virtually area economic development example industry industry fintech financial sector breakthrough technology digital transformation cloud computing technology cyber physical system artificial intelligence technology analysis processing big data one driver digital modernization big data direction rapid development sphere explained intermittent growth information lead impossibility applying classical method tool processing available data analyzes technology method processing information field big data future development sector field big data given research big data market various sector economic development conducted leader field identified direction big data financial institution one key player market analyzed big data market financial sphere carried financial indicator dynamic market growth determined reason prevent big data introduction financial institution shown prognosis development big data financial sphere given ,2
BD_292,healthcare big data tool technology potential create significant value improving outcome lowering cost inidual patient diagnostic image genetic test result biometric information increasingly generated stored electronic health record presenting u challenge data nature high volume variety velocity thereby necessitating novel way store manage process big data present urgent need develop scalable expandable big data infrastructure analytical method enable healthcare provider access knowledge inidual patient yielding better decision outcome briefly discus nature big data role semantic web data analysis generating smart data offer actionable information support better decision personalized medicine view biggest challenge create system make big data robust smart healthcare provider patient lead effective clinical decisionmaking improved health outcome ultimately managing healthcare cost highlight challenge big data propose need semantic datadriven environment address illustrate vision practical case discus path empowering personalized medicine big data semantic web technology ,2
BD_293,term big data popular topic recent year practice academe government realizing value data many information technology software proposed deal big data hadoop nosql database cloud computing however tool help u store manage search control data rather extract knowledge big data way mine nugget big data ability analyze characteristic complexity big data eg volume variety make traditional data mining algorithm invalid deal big data solving distributed highdimensional problem propose novel algorithm effectively extract knowledge big data according empirical propose method handle big data soundly ,2
BD_294,big data processing progressively becoming essential everyone extract meaningful information large volume data irrespective type user application area big data processing broad term includes several operation storage cleaning organization modelling analysis presentation data scale efficiency ordinary user significant challenge requirement powerful data processing system provisioning installation complex big data analytics difficulty usage docker containerbased virtualization technology recently introduced docker swarm development various type multicloud distributed system helpful solving problem ordinary user however docker predominantly used software development industry le focus given data processing aspect containerbased technology therefore proposes docker containerbased big data processing system multiple cloud everyone explores another potential dimension docker big data analysis docker containerbased system inexpensive userfriendly framework everyone knowledge basic skill additionally easily developed single machine multiple machine multiple cloud demonstrates architectural design simulated development proposed docker containerbased big data processing system multiple cloud subsequently illustrates automated provisioning big data cluster two popular big data analytics hadoop pachyderm without hadoop including webbased gui interface hue easy data processing hadoop ,2
BD_295,big data analytics latest technology field computer science information technology big data analytics technique useful widely applied type business organization many research area opportunity area big data analytics big data refer large size various type quickly generating data data important knowledge base help designing business strategy big data analytics extraction knowledge processing big data big data analytics many challenge deal first process large amount data second process faster third give result real time explores different facet big data analytics framework platform parallelism mechanism indexing technique present important future research direction ,2
BD_296,volume data generating increasing day day internet world term big data becoming popular buzzword today market big data used various sector internet world effort made demonstrate even healthcare industry stepping big data pool take benefit various advanced tool technology present various research effort made healthcare domain big data concept methodology thought big data used better health planning methodology used healthcare data analytics help better decision making increase business value customer interest provide ehealth service among various healthcare stakeholder messaging standard like health level ? digital imaging communication medicine dicom health insurance portability accountability hipaa message broker etc big data technique applied develop system early diagnosis disease understand connection hat hivaids tuberculosis silicosis also develop integrated data analytics platform presenting many positive progress big data healthcare also present hurdle faced healthcare system big data technology includes list various big data tool case study application worth implementing big data healthcare followed concluding remark ,2
BD_297,big data mine knowledge economic growth technical innovation recently received considerable attention many research effort directed big data processing due high volume velocity variety referred v challenge however addition v challenge flourishing big data also hinge fully understanding managing newly arising security privacy challenge data authentic mined knowledge unconvincing privacy well addressed people may reluctant share data security investigated dimension veracity big data article aim exploit challenge big data term privacy devote attention toward efficient privacypreserving computing big data era specifically first formalize general architecture big data analytics identify corresponding privacy requirement introduce efficient privacypreserving cosine similarity computing protocol example response data mining efficiency privacy requirement big data era ,2
BD_298,due data generated rapidly many data become knowledge processed suitably many application like weather forecast stock market traffic control energy saving surveillance control etc developed based big data processing big data also creates serious problem like huge dimensionality data inconsistency access security privacy uncertainty etc people like smart city quite convenient access thing especially internet thing device connected internet human being also connected internet smarter city bigger data create manage big data becomes challenge problem especially dimensionality becomes huge really efficient way handle know big data really generated via internet thing hence sensor important device human being rfid usually sensor attached device human being sensor face fingerprint vein iris etc designed get specific physiological characteristic owned human talk introduce big data smart city biometric recognition technology point problem face need solve several practical system also introduced based big data processing ,2
BD_299,research area digital forensics subject rapidly developing society cyber security big data cloud getting attention ever computing breach requires digital forensics seize digital evidence determine responsible done maliciously possible consequence particular big data attack case digital forensics facing even challenge earlier digital breach investigation ppi protection personal information gdpr general data protection regulation law launched implemented supthsupmay compulsory regulation important impact healthcare ppi cloud ico deloitte nowadays big data characteristic three v volume velocity variety either synchronized cloud stored cloud order solve storage capacity problem made digital forensics investigation even difficult big data digital forensics issue cloud difficult one need identify physical device compromised data distributed cloud customer digital forensics practitioner full access control like traditional investigation smart city making ict information communication technology collect detect analyze integrate key information data core system running city meanwhile control centre making intelligent response different requirement include daily livelihood ppi security environmental protection safety industrial commercial activity city service smart city healthcare big data collected gathered iot internet thing liu qi applying gdpr prevent cyberstalking cybercrime summerises trend digital forensics used big data evidence acquisition challenge discussed case smart city project iot service collecting big data stored cloud computing environment represented technique generalised big data cloud environment ,2
BD_300,faced torrent data generated captured digital form result advancement science engineering technology various social economical human activity big data phenomenon usher era human endeavor scientific pursuit aided human capital physical financial asset also data asset research issue big data big data analysis embedded multidimensional scientific technological space first take close look dimension big data big data analysis focus attention issue inconsistency big data impact inconsistency big data analysis offer classification four type inconsistency big data point utility inconsistencyinduced learning tool big data analysis ,2
BD_301,big data cluster introduce intermediate cache layer computing framework underlying distributed file system enable upperlevel application end user efficiently access big datasets cache effectively share among different computing framework cache shared multiple application end user directly applying existing ondemand caching strategy result intense conflict big datasets cached whole meanwhile big data application usually involve massive number file scan cachedin data block may little chance accessed cached make way ondemand data block thus unwise cache data block long actually accessed propose novel justenough big data caching scheme justintime block prefetching improve cache effectiveness big data cluster justintime block prefetching block cached begin process block rather cached block dataset processed monitor block access measure average processing time data block estimate minimal number block kept cache big dataset speed data processing match data prefetching upperlevel obtain input block cache time experimental result show proposed cache method restrain overrequirement cache resource big data application provides performance improvement data block cached ,2
BD_302,global construction business point paradigm shift exponential growth digital technology increasing impact climate change impending brexit looming social environmental pressure driving change construction industry increasingly policy press adoption sustainability construction organisation realising small sustainable impact longer enough therefore measurement one key implementation sustainable construction strategy advance data gathering computing power connectivity mean construction organisation information data ever collecting analysing understanding large volume available data known big data organisation operates sustainably lead knowledge improve decision making refine goal focus effort however come sustainability great thing big data unlocking ability business understand act typically biggest sustainable ie economic social environmental impact one outside control measuring understanding business really affect natural world opportunity bringing sustainability inside organisation creating change cutting cost boosting longterm profitability resourceconstrained world still issue challenge around gathering sustainabilityrelated data well analysing interpreting data point therefore aim research explore barrier adopting big data related sustainable strategy relationship policy making big data sustainability still early stage already several application mention environment health construction bioersity loss monitoring pollution zone identification endangered specie location smart energy management cost reduction investment assessment way barrier opportunity identified instance lack financial resource business case skill training unequal opportunity security disclosure issue among barrier partnership emerging accessible technology personalization environment among opportunity finally biggest challenge presented implementation big data concept standardization since many area one way another making technology without recognized way greatest asset represents big data sustainability identification future cause consequence climate change subsequent prevention mitigation time ,2
BD_303,china unicom largest wcdma g operator china meet requirement historical mobile internet explosion surging mobile internet traffic mobile terminal according internal statistic china unicom mobile traffic increased rapidly compound annual growth rate cagr % currently china unicom monthly store trillion record data volume tb highest data volume reached peak pb since october china unicom developing homebrewed big data storage analysis platform based source hadoop distributed file system hdfs longterm strategy make full big data mobile internet traffic well served big data platform currently writing speed reached record per second record retrieval time table contains trillion record le m take advantage opportunity big data operator china unicom developed function multiple innovation solve space time constraint challenge presented data processing introduce big data platform detail based big data platform china unicom building industry ecosystem based mobile internet big data considers telecom operator centric ecosystem formed critical reach prosperity modern communication business ,2
BD_304,recent year development internet enables rapid growth global data volume arrival era big data brought great challenge traditional computing big data system hadoop spark becoming important platform handle big data due design flaw big data application unreasonable distributed framework configuration performance application big data system difficult achieve peak speed computer theory locate performance bottleneck big data system analyze bottleneck cause worthy research layer performance evaluation model big data system proposed reliable basis performance analysis time performance optimization model big data system also proposed assist performance bottleneck location bottleneck analysis optimize performance based two performance model eventbased performance tool profile performance data implemented experimental result show two performance model effective performance evaluation optimization big data system improve average running time big data system % ,2
BD_305,potential benefit big data adoption significant initial success already realized remain many research technical challenge must addressed fully realize potential big data processing storage analytics course major challenge easily recognized however additional challenge related instance big data collection integration quality enforcement proposes hybrid approach big data quality evaluation across big data value chain consists assessing first quality big data involve process cleansing filtering approximation assessing quality process handling big data involve example processing analytics process conduct set experiment evaluate quality data prior preprocessing quality preprocessing processing large dataset quality metric measured access three big data quality dimension accuracy completeness consistency result proved combination datadriven processdriven quality evaluation lead improved quality enforcement across big data value chain hence recorded high prediction accuracy low processing time evaluate wellknown classification algorithm part processing analytics phase big data value chain ,2
BD_306,big data softwaredefined networking sdn attracted great interest academia industry two important area traditionally addressed separately previous work however one hand good feature sdn greatly facilitate big data acquisition transmission storage processing hand big data profound impact design operation sdn good feature sdn solving several issue prevailing big data application including big data processing cloud data center data delivery joint optimization scientific big data architecture scheduling issue show sdn manage network efficiently improving performance big data application addition show big data benefit sdn well including traffic engineering crosslayer design defeating security attack sdnbased intra inter data center network moreover discus number issue need addressed jointly consider big data sdn future research ,2
BD_307,big data technology technology aim efficiently obtain value big volume wide variety data enabling high velocity capture process store discovery andor analysis ensuring veracity automatic quality control order obtain big value make decision big data described often represented multiv model multiv model volume velocity variety item commonly recognized big data driven cyber physical system refer cyber physical system large quantity complex data perform function data important correct specification analysis design implementation operation big data driven cyber physical system design big data driven cyber physical system requires concept used model classical data structure v feature big data spatiotemporal constraint moving object dynamic continuous behavior physical world propose approach integrate architecture analysis & ampamp design language aadl modelicaml hybrid relation calculus big data driven cyber physical system development illustrate proposed method specifying modeling vehicular ad doc network vanet ,2
BD_308,digitalization daytoday activity resulted huge volume data data called big data used many organization extract valuable information either take marketing decision track specific behavior detect threat attack processing data made possible multiple technique called big data analytics allow getting enormous benefit dealing massive volume unstructured structured semistructured content fast changing impossible process conventional database technique however big data represents immense opportunity many industry decision maker also represents big risk many user risk arises fact analytics tool consist storing managing efficiently analyzing varied data gathered possible available source consequence people become widely vulnerable exposure combining exploring specific behavioral data possible collect data lead many security privacy violation therefore research community consider issue proposing strong protection technique enable getting benefit big data without risking privacy highlight benefit big data analytics challenge security privacy big data environment furthermore available protection technique propose possible track enable security privacy malicious big data context ,2
BD_309,summary form given follows complete presentation made available publication part conference proceeding constitutes big data problem ? application domain best suited benefit big data analytics computing ? trait characteristic application make suited exploit big data analytics ? big data system framework designed allow integration analysis complex data set ? research big data analytics benefit latest advance supercomputing high performance computing hpc architecture ? goal workshop address question like fundamental advancement big data computing process build erse research community shared vision advance state knowledge discovery big data computing ,2
BD_310,smart factory characterized high value industrial big data application iotinternet thing technology cloud computing technology developing industrial big data system comprehensive challenge involves software hardware big data pervasive lifecycle industrial product thus developing industrial big data system different traditional business process system noticed much emphasis design concern industrial big data system product lifecycle view smart factory domain challenge industrial big data system meet smart factory domain discussed domain requirement analyzed design concern industrial big databased system abstracted product lifecycle view design concern focused requirement acquirer system builder stakeholder smart factory furthermore demonstrate instantiation define solution smart fault diagnosis complex equipment based big operation data including architecture design data management data analysis service provider ,2
BD_311,big data phenomenon information era big data dimension explore collecting big data fix time big data function including impact society form spatiotemporal structure change world future integration society technology important aspect risk cloud computing leverage risk secure cloud service get additional benefit integrated approach applied important separate various kind security need considering cloud computing issue also security analyst included data science team datadriven economy based three point data legislation big data education student important practical training engages student culture big data analytics opportunity provides emc academic alliance russia & amp ci establishment adhoc big data analytics team among university result first stage launched big data analytics multicenter presented ,2
BD_312,nowadays data produced fast pace lead generation big data need properly managed especially due increased complexity size introduces data usually subject processing obtain addedvalue knowledge current system seem focus optimally perform processing neglect data placement tremendous effect processing performance respect big data placement algorithm already proposed however either suggested isolation big data processing system dynamic deal required big data placement change runtime proposes novel dynamic big data placement algorithm optimally find best placement solution considering multiple optimisation objective solving precise manner big data placement problem respect stateoftheart novel suggestion optimally combining algorithm big data application management system proposed ability address conjunction big data placement processing resource management issue respective experimental evaluation result showcase efficiency algorithm producing optimal big data placement solution ,2
BD_313,application big data technique power system contribute sustainable development power industry company establishment strong smart grid article introduces universal framework electric power big data platform based analysis relationship among big data cloud computing smart grid key technique electric power big data discussed four aspect including big data management technique big data analysing technique big data processing technique big data visualization technique finally article present three typical application example electric power big data technique renewable energy integration wind turbine condition monitoring assessment data base integrative backup electric power enterprise ,2
BD_314,good decision support absolutely necessary nowadays need improve gain value organization vital obtain value anything huge amount data big data_pushes big data enough important thing smartly order gain valuable decision support making sense big data would happen able data get important hint direction impediment big data concept obtain support fast obtained real time possible solution used need malleable information technology evolution evolution ease managing data elastic stack chose elastic stack manage big data process making sense big data based three big step collect process order make sense proposes elastic stack solution also known elk elasticsearch logstash kibana easily rapidly manage big data problem making sense big data succeeding extract valuable information stand decision support order achieve obtain valuable information big data component used process data analyze result offer support decision making ,2
BD_315,big data mine knowledge economic growth technical innovation recently received considerable attention many research effort directed big data processing due high volume velocity variety referred v challenge however addition v challenge flourishing big data also hinge fully understanding managing newly arising security privacy challenge data authentic mined knowledge unconvincing privacy well addressed people may reluctant share data security investigated dimension veracity big data article aim exploit challenge big data term privacy devote attention toward efficient privacypreserving computing big data era specifically first formalize general architecture big data analytics identify corresponding privacy requirement introduce efficient privacy triple de example response data mining efficiency privacy requirement big data era ,2
BD_316,today world massive set data generated different organization throughout world huge heterogeneous data called big data big data analytics offer tremendous insight different organization especially healthcare traditional database architecture mark face challenge huge data pouring organization today creates big havoc big data play important role achieving predictive analysis healthcare domain big data handle huge explosion data found many medical organization big data analytics play major role solving issue challenge arises healthcare domain give overview storing retrieval method big data tool technique used healthcare cloud role big data analytics healthcare discus benefit outlook nascent field predictive analytics face challenge provides solution result also show astronomical role big data analytics healthcare ,2
BD_317,constant upsurge size network data massively produced made data analysis challenging principally data attaining boundary big data becomes even difficult detect intrusion case big data era expert find limited tool method analyze big data security reason either need device tool existing tool novel manner achieve big data security analysis apache spark big data tool analyzing big dataset anomaly detection anomaly detection performed different machine learning algorithm like logistic regression support vector machine naïve bayes decision tree random forest kmeans le aforementioned algorithm capable detect anomaly big data need know efficiently performs objective investigation find efficient algorithm context anomaly detection regard set compare training time prediction time rate accuracy analysis implemented kddcup dataset although dataset size megabyte meet big data security analytics ,2
BD_318,high volume wide variety valuable data different veracity easily generated collected high velocity nowadays big data visualisation visual analytics demand various reallife application musical data example big data embedded big data useful information valuable knowledge many existing big data mining algorithm return useful information valuable knowledge textual tabular form knowing picture worth thousand word big data visualisation visual analytics also demand system visualising analysing big data particular system focus big data science discovery exploration frequent pattern ie collection item frequently occurring together musical data evaluation result show applicability system big data visualisation visual analytics music data mining ,2
BD_319,lifelogging represents phenomenon whereby people digitally record daily life varying amount detail variety purpose sense represents comprehensive black box human life activity may offer potential mine infer knowledge life recently observed convergence technology foster emergence lifelogging mainstream activity computer storage become significantly cheaper advancement sensing technology allows efficient sensing personal activity location environment best seen growing popularity quantified self movement life activity tracked wearable sensor hope better understanding human performance variety task lifelogging personal big data provides comprehensive summary lifelogging cover research history current technology application thus far lifelogging research focused predominantly visual lifelogging hence book maintains focus however also reflects challenge lifelogging pose information access retrieval general lifelogging personal big data suitable reference seeking information retrieval scientist perspective lifelogging quantified self ,2
BD_320,development ecommerce social network internet thing mobile internet massive data produced every day data contains information people life thinking mining massive data analyze past development mode something degree also forecast future development trend result something effect social aspect improve society efficiency also create industry cluster data analysis professional seriously lacked every country particular china order meet society need big data analysis professional help young people learn apply big data promote big data science innovation setting big data specialty would necessary university china analysis big data specialty university china presented big data majoring core course hadoop technology elective course window big data processing technology analyzed construction experiment base training student mode provided reference thinking path setting big data specialty chinese university ,2
BD_321,enormous amount data generated high speed era data processing age started ` big data processing big data deal data high volume high velocity high variety high veracity also known v big data managing big data tradition system possible due v property big data system required could manage big data economically efficiently cloud computing emerging major breakthrough information technology provide economical solution client payasyouuse basis service cloud managing big data could provide effective economic solution proposed framework could manage big data cloud environment providing schema big data end could easily query system without extra programming skill ,2
BD_322,big data refers data large complex processed big data handle voluminous amount structured semi structured unstructured data standard tool big data also refers data volume velocity variety data combine historic data data predict outcome regard providing security data challenging apache hadoop one tool designed handle big data apache hadoop software product used process interpret result big data hadoop includes various component like map reduce hdfs handling big data cloud computing technology provides online data storage providing security key issue integrated approach introduced encrypt decrypt data sending cloud achieve better performance security performance analysis different technique applied based different parameter ,2
BD_323,big data cognition become dominant problem interactive visual analytics event detection response metereology cosmology large smart city application including traffic monitoring management search rescue operation crowd management logistics problem mainly due big data volume velocity case variety dimension type practical approach understanding viewing big data feature streaming operation streaming allows volume velocity characteristic big data often variety well however performing analytics interactive rate currently challenge big data application cloud computing platform provide practical support leverage solving big data visual analytics problem especially dealing volume velocity characteristic current data generation order interact streaming data pattern elastic cloud environment elastic framework big data visual analytics cloud cloudet cloudet selfadaptive cloudbased platform treat data compute node elastic object objective readily achieve scalability elasticity cloud computing platform order process large streaming data adapt potential interaction data stream feature contribution include robust cloudbased framework cloudet flexibly process streaming data application illustrate setup operation framework framework includes cloud profile manager attempt optimize cloudet parameter order achieve expressivity scalability reliability proper aggregation data stream several density map dynamic visualization data feature ,2
BD_324,big data technology shown great promise managing geospatial data recent year order deal growing spatial data high performance spatial data processing system layered big data technology needed approach process big spatial data apache spark fast generic engine largescale data processing developed software development kit named sparkspatialsdk take spatial characteristic geospatial data consideration provides sparkenabled spatial data structure api allow user easily perform spatial analysis big spatial data spatial data structure couple geometric data structure point line polygon resilient distributed datasets rdd interface called spatialrdd provided access big spatial data stored distributed database system like hbase load data spark processing engine illustrates application api example processing function spatial range spatial knearest neighbor query result demonstrate applicability sparkspatialsdk big geospatial data processing ,2
BD_325,big data refers analyzing massive volume data combining different application order save time efficiency quality interpreting data controlling data transfer network fundamental question big data context transport model named data networking ndn architecture introduces several feature especially namebased retrieval policy smaller data transfer time thanks interest aggregation innetwork caching distinguishing feature make ndn suitable communication model big data transfer since ndn content retrieved multiple cache multiple path traditional hosttohost congestion control scheme become inconsistent hence need efficient congestion control scheme take account tremendous volume data generated big data processing ndn characteristic give detailed understanding ndn benefit traditional tcpip stack big data transfer focus efficient control big data transfer ndn give comprehensive overview recent named data congestion control solution evaluate discus relevance big data application ,2
BD_326,big data dataoriginated resource offered internet performance big data depends data bought data collector however problem optimal pricing data allocation big data service wellstudied propose auctionbased big data market model first define data cost utility based impact data size performance big data analytics eg machine learning algorithm big data service considered digital good uniquely characterized unlimited supply compared conventional good limited therefore propose bayesian profit maximization auction truthful rational computationally efficient optimal price data size obtained solving profit maximization auction finally experimental result realworld taxi trip dataset show big data market model auction mechanism effectively solve profit maximization problem provider ,2
BD_327,recently big data analytics emerged hot topic incredible growth information communication technology one exceedingly anticipated key contributor big data realtime earth observatory system eos although data generated inidual satellite eos may significant overall data generated across numerous satellite may yield significant amount big data thus extracting useful information efficient manner lead system towards major computational challenge eos analyze aggregate store data remotely collected therefore proposes set requirement achieving pervasive integrated information system eos associated service realtime offline data processing big data architecture also proposed address aspect big data ecosystem includes following component data acquisition unit data processing unit data storage unit data analysis decision unit proposed architecture termed holistic considers flow data satellite service designed efficiently process analyze big data finally detailed analysis remotely sensed earth observatory big data land sea area provided ubuntu lts core™i machine ghz processor gb memory result show proposed network architecture efficiently process eos data realtime well offline ,2
BD_328,modern sensing device play pivotal role achieving data acquisition communication dissemination internet thing iot naturally iot application intelligent sensing system supported sensing device wireless sensor network wsns closely coupled modern intelligent sensing system generate huge volume sensing data well beyond processing capability common technique tool result collecting managing processing iot big sensing data acceptable time duration challenge research industrial application massive size extreme complexity high speed big sensing data bring technical requirement including data collection data storage data organization data analysis data publishing real time deploying realworld iot application better facilitate iot application convergent research wsns big data iot cloud computing natural scientific development trend article concentrate bigsensingdata curation preparation issue cloud computing theme iot three especially critical issue need addressed scalable bigsensingdata cleaning scalable bigsensingdata compression cloudbased data curation response iot device optimization viewed iot side iot sensing device integrated together adaptive solution upload data onto cloud automatic response cloud intelligent sensor change status behavior sensing device therefore status iot ,2
BD_329,recent rapid rise availability big data due internetbased technology social medium platform mobile device left many market leader unprepared handling large random high velocity data conventionally technology initially developed tested lab appear medium press release advertisement technology adopted general case big data technology fast development ready acceptance big data community left little time scrutinized academic community although many book electronic medium article published professional author big data still lack fundamental academic literature survey method discus challenge different aspect big data data source content format data staging data processing prevalent data store issue challenge related big data specifically privacy attack countertechniques kanonymity tcloseness lersity differential privacy discussed tool technique adopted various organization store different type big data also highlighted identifies different research area address lack anonymization technique unstructured big data data traffic pattern determination developing scalable data storage solution controlling mechanism high velocity data ,2
BD_330,vital significance strong smart grid big data analytics technology apply power system multisource heterogeneous data integration technology based big data platform one indispensable content problem data heterogeneity data island dispatching control system multisource heterogeneous data integration model proposed big data analytics model exists data integration layer platform big data analytics model improve extracttransformload etl process big data platform according extracting rule transform rule made uniform data model panoramic dispatching control system research show integrating model developed efficient establish panoramic data adapt various data source building uniform data model power dispatching control system development big data technology expected data integration model improved used electric power application ,2
BD_331,asset remote sens digital world daily generate massive volume realtime data mainly referred term big data insight information potential significance collected aggregated effectively today era great deal added realtime remote sensing big data seems first extracting useful information efficient manner lead system toward major computational challenge analyze aggregate store data remotely collected keeping view mentioned factor need designing system architecture welcome realtime well offline data processing therefore propose realtime big data analytical architecture remote sensing satellite application proposed architecture comprises three unit remote sensing big data acquisition unit rsdu data processing unit dpu data analysis decision unit dadu first rsdu acquires data satellite sends data base station initial processing take place second dpu play vital role architecture efficient processing realtime big data providing filtration load balancing parallel processing third dadu upper layer unit proposed architecture responsible compilation storage result generation decision based result received dpu proposed architecture capability iding load balancing parallel processing useful data thus result efficiently analyzing realtime remote sensing big data earth observatory system furthermore proposed architecture capability storing incoming raw data perform offline analysis largely stored dump required finally detailed analysis remotely sensed earth observatory big data land sea area provided hadoop addition various algorithm proposed level rsdu dpu dadu detect land well sea area elaborate working architecture ,2
BD_332,era big data underway compared small data machine learning computerized database modern technology make possible big data handle massive data reveal information way inidual bit data cant random sampling accuracy depends ensuring randomness collecting data sample analyzing limited number data point mean error may get amplified may reduce accuracy overall result potentially meanwhile big data gather analyzes massive data produce excellent result could never know limited smaller quantity like address various societal ill offer potential insight erse field data come environment uncertainty rapid change bigger data may better data increasing volume data may lead inaccuracy return relaxing standard allowable error produce valuable information better result article elaborates reliability big data based analysis constructed model analyze reliability big data ,2
BD_333,big personal data growing explosively consequently increasing number internet user drowning sea data big personal data enormous commercial value kind data asset urgent problem thus arisen data market price big personal data fairly reasonably proposes pricing model big personal data based tuple granularity help comparative analysis existing data pricing model strategy model put forward implement positive rating reverse pricing big personal data investigating data attribute affect data value analyzing value data tuples varies information entropy weight value data reference index cost factor model adjusted dynamically according parameter increase data scale reduction cost improvement quality big personal data user thereby obtain greater benefit ,2
BD_334,rapid development social network internet thing cloud computing well technology big data age arriving increasing number data brought great value enterprise meanwhile manage big data better become focus walk life v characteristic big data brought lot issue big data processing key big data processing solve data quality issue ensure data quality prerequisite successful application big data technique recommendation system prediction system typical big data application try find data quality issue data collection data preprocessing data storage data analysis stage big data processing according elaboration analysis proposed issue corresponding solution also put forward finally problem solved future also raised ,2
BD_335,data increasing explosively due development social network cloud computing challenge storing processing analyzing large volume data traditional technology become proper solution process big data big data platform begun emerge certain big data platform help user develop analysis effectively however still take long time collect data develop algorithm analytics service collaborative big data analytics platform big data developer collaborate platform sharing data algorithm service therefore describes big data analytics platform effectively support manage big data develop analytics algorithm service collaborating data owner data scientist developer web finally introduce cctv metadata analytics developed platform ,2
BD_336,big data environment used support huge amount data processing environment ton ie giga byte tera byte data processed therefore various online application huge data request generated treated big data ie facebook google presented big data environment studied investigated data consumed big data supporting tool working hadoop storage furthermore keen understanding investigation cluster analysis technique specifically kmean clustering algorithm implemented hadoop mapreduce clustering part big data analytics unlabelled data processed utilized make group data addition observed traditional kmean algorithm much suitably work hadoop mapreduce thus small amount modification performed data processing technique addition cluster analysis various issue found traditional kmeans ie fluctuating accuracy outlier empty cluster therefore clustering algorithm modification traditional approach kmeans clustering proposed implemented approach first enhances data quality removing outlier point datasets bipart method used perform clustering proposed clustering technique implemented java hadoop mapreduce finally performance proposed clustering approach evaluated compared traditional kmeans clustering algorithm obtained performance show effective result enhanced accuracy cluster formation removal deefficiency thus proposed adoptable big data environment improving performance clustering ,2
BD_337,big data make drastic change pattern data center traffic traditional application based clientserver architecture data center traffic northernsouthern mode application big data developed socalled easternwestern traffic pattern widely used data center network moreover application cloud computing technology processing infrastructure data center storage made dynamic network traffic center large volume easternwestern data change traffic pattern dynamic manner immediate nature among importance characteristic application big data data center network posed several challenge traditional architecture data center technology therefore essential make drastic change network infrastructure data center execute several application big data article attempt made focus network issue requirement big data addressing recent method technology order solve network problem addition analyzed application impact modern technology softwaredefined network application relevant big data ,2
BD_338,currently deeply distill potential attribute big data become great challenge structured semistructured unstructured data ssu data unified model structured data refers data resides fixed field record file including data contained relational database spreadsheet unstructured data refers data text picture audio video source fit relational database semistructured data information doesnt reside relational database organizational property make easier analyze xml html document literature survey framework namely integrated big data ibd aim exploring approach constructing universal ibd model including representation storage management computation visual analysis firstly systematic framework decompose big data analytics four module next detailed survey numerous approach four module contribution summarized two dimension first propose novel integrated big data framework unified big data representation storage computation visual analysis second possible future method realizing framework reviewing method would like point promising research direction unified investigation application big data ,2
BD_339,privacy security big data priority topic current world scenario expertise relies big data data used different organization impose risk privacy breaching iniduals distributed system used big data need high computational power large storage different resource different system property used chance privacy violation processing big data protect privacy different technique like data anatomization data suppression etc used perform technique big data requires computational power time instead performing technique entire data advisable perform sensitive data item previous implementation sensitive data information identified statically information given data owner identification sensitive data item carried sensitive data detection framework dynamic neural network used security mechanism implemented sensitive item protect privacy security big data ,2
BD_340,recent decade big data attracted attention decision policy maker enterprise government market analyst data scientist growth information current decade exceeded moore law vast amount data increasing pain towards managing analyzing however high amount data great potential extremely useful information hidden dataintensive scientific discovery help identify big data problem big data problem found various area sector economic activity provide effective administration national security scientific research several progression various field made possible big data doubt future challenge business enhancement converge explore big data difficulty arise big data data visualisation data storage data analysis data capture aim give clear idea big data dataintensive application also covered several scheme handle quantum computing bioinspired computing cloud computing granular computing ,2
BD_341,data data data data data around data big data area gaining immense importance organization running ×× real time commercial transactionsdata need handled stored archived retrieved carefully current give overview big data related component like cloud computing distributed computing data mining etc research introduces v limitation relational database system root origin big data discus big data application big data datasets big data tool research demonstrates working big data tool mongodb nosql database ,2
BD_342,lot technological advancement recent year data generation increased outcome large amount data generated major issue organization example social medium flooding data day unmanageable would discus various risk issue associated big data big data describes large volume data either structured unstructured day data came many source usual database system able handle data need big data big data requires huge assurance hardware processing resource make big data costly order provide big data service every take help form cloud computing offer big data implementation cheaper cloud computing technology offer sharing computing resource server device etc instead personal one service cloud computing delivered via internet ,2
BD_343,big data big data analytics set emerging technology allow researcher organization business draw actionable insight large data set primary source large data set created healthcare medical context include data limited electronic health record mobile application mhealth diagnostic equipment genomics social medium consequently big data technology promise transformative impact healthcare health medical research among application area example researcher already developing standard protocol design suited mhealth intervention opposed traditional randomized clinical trial also easy availability data allows population level study scale previously unimaginable although big data analytics potential deliver significant benefit healthcare application full consequence technological shift yet unknown application big data healthcare often viewed inevitability technological imperative perspective discount role human agency dangerous way theoretical foundation relevant idea organizational communication literature discus theory technology acquisition adaptive structuration notion situatedness explored example drawn visualization augmented reality cultural heritage due significant interest systematic literature review metaanalyses topic big data healthcare already available review help delineate potential benefit challenge area particular emphasize challenge high human cost privacy patient data thoughtful design technological intervention atrisk population lastly show situated perspective necessary tool building next generation healthcare information system ,2
BD_344,witnessing everincreasing demand cloud computing service iot mm communication advanced telecom application addition application like commerce medical care education entertainment well scientific meteorological simulation genomics computational physic financial transaction social network service generate vast amount data big data result estimated digital data need processed stored data centre reach zettabyte level timesensitive big data analysis processing highperformance computing infrastructure huge interintra data exchange data centre becomes crucial topic attracts significant attention lately size datasets feasible processed reasonable amount time determined available processing capability also bandwidth latency interconnecting network requirement pose serious challenge datacenter network operator come flexible reliable solution considering operational benefit result potentially novel photonicplasmonic technology well advanced optical networking approach may offer capability transmitting processing big data low power consumption low latency high level flexibility relatively low cost tutorial discus impact big data underlying network infrastructure particular focus novel photonic technology optical networking approach highperformance computing hpc datacentre network dcn telecommunication network tcn utilized face requirement infrastructure requirement big data era outlined brief presentation roadmap optical technology introduced hpc dcns tcns order improve performance made finally third part tutorial focus shift discussion towards advanced networking solution enable flexibility virtualization application awareness qos support thus making network infrastructure suitable requirement ,2
BD_345,nowadays big data analysis widely used information telecommunication domain benefit big data analysis telecommunication operator internet provider could analyze user interest effective predict user expectation accurate thus significant improve add value service identity management big data analysis application requirement considering characteristic big data analyzed requirement identity management big data analysis based general identity management model intention compatible advanced ersity identity management technology refer itut recommendation baseline capability enhanced global identity management interoperability analyze identity management capability general identity management model according analysis general identity model satisfy identity management capability required itut standard since design model based specific requirement characteristic big data analysis application prototype general identity management model used big data analysis also guide system design big data security ,2
BD_346,great enthusiasm prospect big data among business industry leader academia researcher lot big data tool technology emerged recently capture store process analyze big data one remarkable achievement handful source technology introduced apache hadoop foundation allows organization undertake big data project many big data project implemented last year explores benefit achieved project big data applied erse field including scientific medical discovery project studying social science phenomenon conducting meaningful observation realworld phenomenon running analytics healthcare business many business organization want find business opportunity fraud detection customer sensitivity analysis product offering business organization still pondering long term value big data investment business leader manager want sure big data project deliver true value provide long term benefit provides account recent big data project initiative successful delivering business value highlight technology solution primarily used big data project ,2
BD_347,given surge interest research publication application big data last year potential big data seems wellestablished across business however business implementation big data still seem struggling deliver promised value roi result despite market leading big data solution talented deployment team forcing business manager think need done differently lay framework business manager understand big data process besides providing business overview big data core component present several question manager must ask ass effectiveness big data process based analysis several big data project never delivered comparison successful one hypothesis developed based information proposed first step business manager keen effectively leveraging big data ,2
BD_348,order gain benefit big data must shared published analyzed processed without harm facing violation finally get better value analytics literature report analytics brings issue privacy violation issue also protected law bring fine company institution iniduals result data collector avoid publish share big data due concern order obtain plausible solution number technique reduce privacy risk enable publishing big data preserving privacy time known privacypreserving big data publishing ppbdp model present privacy problem big data evaluates big data component privacy perspective privacy risk protection method big data publishing review existing privacypreserving big data publishing approach anonymization method literature result finally evaluated discussed suggestion presented ,2
BD_349,recent year big data technology become representative information technology also playing increasing important role electric power industry big data technology electric power company introduces business like accurate load forecasting behavior analysis etc help make quality upper level decision reasonable expounds concept big data characteristic electric power big data data processing step introduced well basis opportunity challenge faced big data analyzed problem countermeasure big data focused future development big data security summarized end guarantee technology management big data technology bright future big data industry provide strong support improving enterprise efficiency ,2
BD_350,big data analytics hottest technology help turn hidden insight big data business value support better decisionmaking however current big data analytics many challenge since big gap big data analytics business mainly lack business context around data lack expertise connect dot implicit business objective iris big data analytics framework aligning business goaloriented approach composed ontology business context model analytics method connecting big data business action process collaborative assistant tool utilizing spark framework problem current process solution future process hypothesized explicit business context model validated erse analytics method implemented top spark library also goaloriented approach enables explore select alternative among potential problem solution business process clearance pricing decision used show big data analytics turned business value framework align big data business goal well initial understanding applicability iris ,2
BD_351,rapid advance big data cloud computing building high quality big data system different application field gradually became popular research topic academia industry well government agency however quality problem lead application error although current research discussed ensure quality big data application several aspect systematic discussion ensure quality large data application therefore systematic big data application quality assurance necessary critical focus survey quality assurance technique big data application introduces big data property quality attribute mainly discus key approach ensure quality big data application testing modeldriven architecture mda monitoring fault tolerance verification also prediction technique addition also discus impact big data characteristic big data application ,2
BD_352,first big data driven cyber physical system cps big data characteristic big data usually described following aspect volume velocity variety veracity validity value volatility second big data driven cps special characteristic requirement must met system development big data characteristic special characteristic requires method technique data specification modeling capture transfer management algorithm collection transfer analysis storage processing design method big data driven cyber physical system meet multiple v characteristic also must meet special characteristic cps spatiotemporal requirement real time communication requirement model based approach proposed modeling big data driven cyber physical system based integration aadl modelicaml clock theory proposed approach allows design objectoriented component model big data driven cps advantage proposed approach capacity take account big data property cyber physical system property specialized concept rigorous easy expressive manner proposed approach illustrated case conceptual design aviation cyber physical system ,2
BD_353,homeland security network deployment evolve rely increasingly large amount data growing variety data source ability synthesize actionable information become progressively challenging similar problem seen information technology domain pursuing big data technique gain insight relationship among mountain data believe applying big data lesson learned world homeland security networking electromagnetic spectrum em problem application call big rf network made effective efficient commander gain understanding behavior problem identified rectified quickly many complex network management problem currently requiring human intervention automated examines parallel big data problem emerging cognitive radio related wireless application appropriate big data tool big rf big rf application homeland security network development needed enable warfighters first responder network manager cognitive radio maximize capability offered big data applied rf domain problem ,2
BD_354,big data enables organisation large volume data generated different device people increase efficiency generate profit south african retail organisation already data advantage loyalty card capability readiness big data clear present qualitative approach understand current capability readiness big data south african retail organisation two theoretical model technology organisation environment toe together technology fit ttf used understand factor enable adoption implementation big data retail organisation semi structured interview conducted iniduals retail organisation big data vendor professional provider get understanding current status big data south african context reveals south african retail organisation capable ready adopt implement big data however effort need placed organisational perspective big data technology vendor need provide support enable realisation benefit big data south african retail organisation ,2
BD_355,era big data began although application based big data bring considerable benefit industry government social organization bring challenge management big data platform fundamental infrastructure due complexity variety velocity volume big data offer healthy platform big data application propose novel signaturebased performance diagnosis approach employing mic invariant performance metric formalize performance diagnosis pattern recognition problem normal state big data application used train set mic maximum information criterion invariant one performance problem occurred big data application identified unique binary tuple consisted set violation mic invariant signature performance problem form diagnosis knowledge database kpi key performance indicator big data application deviate normal region approach identify real culprit looking similar signature signature database detect deviation kpi propose metric named unpredictability based arima model considering variety big data application build ensemble performance diagnosis approach mean unique arima model unique set mic invariant built specific kind application experiment evaluation controlled environment running state art big data benchmark find approach pinpoint real culprit performance problem average % precision % recall better correlation based single model based performance diagnosis ,2
BD_356,big data benchmark suite must include ersity data workload useful fairly evaluating big data system architecture however truly comprehensive benchmark pose great challenge architecture community first need thoroughly understand behavior variety workload second usual simulationbased research method become prohibitively expensive big data big data emerging field software stack proposed facilitate development big data application aggravates challenge first principle component analysis pca identify important characteristic metric characterize big data workload bigdatabench comprehensive big data benchmark suite second apply clustering technique principle component obtained pca investigate similarity among big data workload verify importance including different software stack big data benchmarking third select seven representative big data workload removing redundant one release bigdatabench simulation version publicly available httpprofictaccnbigdatabenchsimulatorversion ,2
BD_357,proposes big data application model system academic library perspective big data collection integration big data analysis method knowledge service shortage resource analyzes plight library big data application construct library big data application model system based large scale network analysis method library big data application model based knowledge management theory source cloud computing platform based large scale network analysis method face challenge big data academic library effectively promote development big data academic library ,2
BD_358,big data analytics picked pace offer meaningful information based analyzing big data big data various distinctive characteristic together led overwhelming available infrastructure hardware software moreover led creating complexity considering software engineering aspect big data application development introducing cloud computing mix complicates issue current effort big data analytics target finding way store organize process big data effectively addition investigating cloudbased big data application perspective however noticed much emphasis defining enhancing software development process developing application like software system important identify type application requirement constraint knowledge welldefined process model design develop effective cloudbased traditional big data analytics application investigate application attempt identify general requirement constraint better support software development process one important aspect able distinguish realtime delaytolerant big data analytics application requirement time constraint identified decide type infrastructure software architecture best match requirement result design deliver effective useful big data analytics application ,2
BD_359,big data become important technical force advance many industry many big data technique invented opensourced small business form major part whole business world still face great challenge applying big data solution business however case published procedure engineering big data small business fact lead insufficient reference small business take figure scenario applying big data pilot case small business applying big data electric signal process project describes detail procedure analyzing business logic identifying big data requirement selecting appropriate big data technique engineering solution also share lesson learned case general reference small business trying big data application case ,2
BD_360,privacy important issue big data including sensitive attribute case directly sharing publishing data privacy breach occurs order overcome problem previous study focused developing big data anonymization technique hadoop environment compared hadoop spark facilitates develop faster application help keeping data memory instead hard disk despite number project developed hadoop trend shifting spark addition problem anonymizing big data stream realtime application solved spark technology hence sum spark technology facilitates developing faster anonymization application big data stream anonymization solution anonymization technique big data technology privacy preserving big data publishing reviewed big data anonymization model based spark proposed first time expected proposed model might help researcher solve big data privacy issue also provide solution generation privacy violation problem ,2
BD_361,big data used find value brings u several benefit didnt know various analytics studied big data area benefit moreover reduce analysis time support realtime distributed processing alternative solution big data also requires high performance resource distributed analysis reason big data cloud computing seem naturally combinedcalled cloudbased big data however cloudbased big data criterion evaluation also hard decide cloudbased big data well designed much resource provided provide qualitied cloudbased big data hence surveyed enterprise product deduct criterion classify evaluate cloudbased big data ,2
BD_362,big data relatively novel research field attracted high interest industry academia wide applicability numerous definition big data given scholar different perspective think big data research field could better appreciated analyzing relevant scientific article published year however sheer volume big data related literature need efficient way analyze utilize knowledge domain analysis technique developed information scientist build intellectual structure uncover research theme afford u holistic view overall big data research field based analysis research theme big data may classified four category first one deal technology architecture aspect big data second one relates prospective application big data analytics third one cover level parallelism big data processing stack rest encompasses mostly machine learning related study miscellaneous topic may benefit big data processing capability ,2
BD_363,homotopy type theory developed u two decade applied big data eliminate inevitable bottleneck big data implementation originating inherent combinatorial explosion incrementally modular abstraction hierarchy imah short used layer starting homotopy type ending presentation big data cyber world formed cyberspace computational space cyberspace rapidly expanding web either intentionally spontaneously without design quite different emphasis homotopy type theory recently reported emphasis mathematical proof automation computer verification widespread intensive local activity melting web big data globally create cyber world major key player big data cyber world include efinance trade gdpequivalent day emanufacturing transforming industrial production web shopping product component assembly factory lacking proper theory design big data continued grow chaotic human understanding control research first present generic theoretical framework incrementally modular abstraction hierarchy based homotopy type theory provides axiomatic approach theorize potential big data cyber world show incrementally modular abstraction hierarchy automate big data application development eliminates need design verification validation also make system developed secure sort attack ,2
BD_364,summary form given complete presentation made available publication part conference proceeding constitutes big data problem ? application domain best suited benefit big data analytics computing ? trait characteristic application make suited exploit big data analytics ? big data system framework designed allow integration analysis complex data set ? research big data analytics benefit latest advance supercomputing high performance computing hpc architecture ? goal workshop address question like fundamental advancement big data computing process build erse research community shared vision advance state knowledge discovery big data computing ,2
BD_365,pervasive computing discipline evolved substantially since inception lot progress made scaling pervasive computing led societalscale capability mobile crowdsensing internet thing pervasive computing application also expanded smart appliance smart environment early day system much broader scope smart city smart transportation going forward important direction enable significantly heightened level smartness pervasive computing system leveraging development big data cognitive computing specifically exponentially increasing volume velocity variety big data hailed world natural resource driving fundamental change technology business society biggest value big data lie deep actionable insight derived integrating source modality data across pervasive sensor enterprise information system insight exploited business innovation competitive advantage cognitive computing key enabling technology turning big data insight different traditional programmable system cognitive system able understand human knowledge reason learn improve time pervasive application integrate big data across board cognitive thus insightful offer unprecedented level intelligence talk discus implication big data cognitive computing pervasive computing draw upon experience ibm watson health discus big data cognitive computing come together pervasive computing enable innovative health solution address many clinical societal economic issue case highlight challenge describe approach relate client experience ,2
BD_366,bigdata system increasingly used many discipline important task knowledge discovery decision making processing large volume data bigdata system rely harddisk drive hdd based storage provide necessary capacity however bigdata application grow rapidly erse demanding hdd storage becomes insufficient satisfy performance requirement emerging solidstate drive ssds promise great io performance exploited bigdata application still face serious limitation capacity cost endurance therefore must strategically incorporated bigdata system present bigcache ssdbased distributed caching layer bigdata system designed seamlessly integrated existing bigdata system transparently accelerate io erse bigdata application management distributed ssd cache bigcache coordinated management bigdata system order support cachelocalitydriven scheduling bigcache prototyped hadoop provide caching upon hdfs mapreduce application evaluated typical mapreduce application result show bigcache reduces runtime wordcount % runtime terasort % result also show bigcache able achieve significant speedup caching partial input benchmark owing ability cache partial input replacement policy recognizes application access pattern ,2
BD_367,era big data big data generates immense economic social value advance data collection massive increase cloud computing power making technology effectively analyze large set heterogeneous data ubiquitous despite benefit big data rise big data analytics private sector pose challenge privacy advocate discus essential technology challenge related big data analytics namely definition big data analytics ii essential technology related big data analytics particular reference cloud computing hydoop etc iii risk arising big data analytics especially privacy harm ,2
BD_368,considered first big data market china compared global scale china big data growth faster global average growth rate china usher rapid expansion big data market next year present overall big data development china term market scale development stage enterprise development industry chain technology standard industrial application point issue challenge facing big data development china proposes make police create support approach big data transaction personal privacy protection ,2
BD_369,big data get recognition everything stored electronically bulk termed big data nowadays effort made extract maximum useful information analyzing big data contains growing value organization actionable relationship abundantly found big data store compared small store big data various organization industry recognized basis certain characteristic dimension structure characteristic big data started v volume velocity variety dimension getting evolved day day thus broadening dimension definition big data growing characteristic structure big data definition academia corporate world elaborated ,2
BD_370,big data one representative phenomenon information era human society basic cognitive foundation big data science presented coherent set general principle analytic methodology big data manipulation lead set mathematical theory rigorously describe general pattern big data across pervasive domain science engineering society significant finding towards big data science big data system nature recursive ndimensional typed hyperstructure rnths fundamental topological property big data system enables inherited complexity unprecedented challenge big data formally dealt set denotational mathematical operation big data engineering cognitive relationship transformability data information knowledge intelligence formally revealed towards big data science ,2
BD_371,recent high profile forecast idc international data corporation predicts $ billion dollar industry big data hardware software service growth big data expected grow six time faster general investment information computing technology could justify expense ? business decisionmaking value technology ? market growth say emerging big data society ? let attempt overview variety business case made behalf big data perhaps gain clearer insight big data big data contributes value overview discussion suggests three distinct argument number distinct variation argument take look argument treating argument thought experiment role big data society evaluate respective merit argument light actual expenditure seems occurring ,2
BD_372,big data prominent paradigm nowadays big data start rule slowly expected rule dominate industry least furthermore big data conquer technological war easily capture entire market since big data blasting everywhere around world every domain big data massive amount data able generate billion revenue secret behind billion revenue ever growing volume present redefinition volume big data volume redefined engaging three v namely voluminosity vacuum vitality furthermore augments two v big data paradigm namely vendee vase explores v big data lot controversy confusion regarding v big data uncovers confusion v family big data ,2
BD_373,big data potential value across business sector received tremendous attention practitioner academia world huge amount data collected different form organization promise radically transform business landscape globally impact big data spreading across business sector potential create opportunity growth organization able store huge erse amount data different source form big data expected deliver tremendous value across business sector focus building business case big data adoption organization discus opportunity potential benefit associated big data adoption across various business sector globally discussion important making business case big data investment organization major challenge adoption globally us strategic grid understand current future potential benefit big data different business sector result suggest onesizefitsall big data adoption potential benefit organization ,2
BD_374,today era computer science technology evolved upto great extent augmented reality ar technology evolved artificial intelligence also follows principle pervasive computing ar achieved encapsulating algorithm snippet smart device laptop android phone smart device digitization data done aesthetic way technology ar big data share logical mature relationship inevitably converges describes advantage merging ar big data invent interesting application starting tangible presence aim uncover problem ease issue visualization big data time objective finding valid solution problem big data visualization remains section mentioned elaborates tool technique platform used visualization big data reveal disadvantage currently existing visualization method based result based result common approach proposed capability method virtual augmented reality could implemented achieve visualization big data also discus application ar big data field used later section discus interface presence tangibility advantage disadvantage trending technology vr ar display big data visualization ,2
BD_375,meaning term big data still subject debate spite widely used biomedical publication confusion definition lead missed opportunity peer exchange knowledge practice better understanding big data may help researcher identify big data community investigate distinguishing feature big datalabelled publication comparing publication without label nonbig data text mining machine learning method furthermore usage term big data analysed time model could successfully make distinction publication labelled ` big data without distinguishing feature consisted term ` omics ` computing ` storage ` mining observed publication term big data may also address topic fall wellaccepted definition big data trend suggest term big data increased used le reliably compared earlier year ,2
BD_376,querying big data cornerstone application big data database perspective query function defined domain range specified semantics querying big data domain big data becomes quite complicated characteristic large volume heterogeneous type strong timeliness weak authenticity etc describe analyze querying big data theoretically propose definition big data big data system includes querying big data aforementioned characteristic big data lead breakthrough normal form qualification closed world assumption cwa related traditional database therefore also point several challenge according characteristic domain analyzes detail firstorder language since complexity domain make traditionally tractable query infeasible analyzes summarizes classification query relational big data according structure computational complexity ,2
BD_377,integrating sensor cloud computing sensorcloud powerful system user obtain big data green city article toward big data green city first latest concerning big data sensorcloud respectively introduce three type sensorcloud ie psc asc ssc green city specifically psc participatory sensing incorporated sensorcloud sensing big data term asc agent incorporated sensorcloud transmitting big data ssc social network incorporated sensor cloud sharing big data finally research issue respect big data sensor cloud discussed respectively hope article serve enlightening guidance future research regarding big data green city ,2
BD_378,competitive environment broadcasting sector changing change broadcaster adapt keep relevant user bigdata technology play essential part technological side change objective identify broadcaster bigdata technology trajectory changing environment propose two research question narrow objective bigdata technology trajectory broadcaster ? also direction bigdata technology proposed broadcaster ? propose method analyze scientific paper keywords combine network analysis compare two datasets bigdata broadcaster bigdata set borrowed previous done author detected bigdata keywords proxy knowledge convergence broadcaster dataset created scientific publication reported bbc nhk match bigdata converging keywords keywords bbc nhk publication visualize behavior time analyze document linked shared keywords datasets identify bigdata technology trajectory propose future direction identified bigdata technological trajectory bbc linked data recommender system semantic web image processing nhk speech recognition generate metadata index nhks program augmented reality ar concerning future detected trajectory expected useful broadcaster organization related value chain ,2
BD_379,big data emerged promising technology handle huge special data processing big data involves selecting appropriate service resource thanks variety service offered different cloud provider selection difficult especially set big data requirement met propose dynamic cloud selection scheme ass big data requirement dynamically map available cloud service recommend best match service fulfill different big data processing request selection conducted two stage relies big data profile efficiently capture big data task requirement map qos parameter classify cloud provider best satisfy requirement us list selected provider stage select appropriate cloud service fulfill overall big data requirement extend analytic hierarchy process ahp based ranking mechanism cope problem multicriteria selection conduct set experiment simulated cloud setup evaluate selection scheme well extended ahp selection technique result show selection approach outperforms others select efficiently appropriate cloud service guarantee big data task qos requirement ,2
BD_380,big data emerging research topic term remains fuzzy seen umbrella term origin composition possible strategy outcome uncertain thus positioning publication addressing business administrated issue related big data impeded practitioner point view ability communicate value proposition impeded due difficulty scoping intended artifact interpretation arisen company result underlying relationship concept described missing theoretical fundament big data stated literature publication actually address need majority remain methodically weak previous deduced initial qualitative big data theory model based expert interview grounded theory paper goal verify given model quantitative way test structural equation modeling thereby hypothesis deduced big data indicator presented result big data theory model arises hypothesis research model significant make three principal contribution scientific discussion big data first unveils underlying characteristic big data second show addressability big data strategy hereby possible strategy address big data highlighted third found evidence positive outcome like return investment big data possible thereby latter two aspect major interest practice presented contributes scientific discussion support development domain ,2
BD_381,recent year rapid development internet internet thing mobile application cloud computing led explosive growth data almost every business industry area today big data technology concept gradually applied traditional industry internet industry big data become important driving force economic reform development market consumer analytics epicenter big data revolution first briefly introduce concept big data including definition feature value identify different perspective significance opportunity big data brings u next introduce relationship among traditional marketing analysis tma big data analysis bda product development npd propose big data analysis model analyze behavior consumer order improve competitiveness product finally conclude giving suggestion big data analysis npd future research idea ,2
BD_382,since difficult deal big data traditional model algorithm predicting estimating characteristic big data important remote sensing big data consist many largescale image extremely complex term structural spectral textual feature based multiresolution analysis theory natural image sparse obvious clustering persistence character transformed another domain group basic special function wavelet transform represent remote sensing big data large scale space domain correlated spectral domain continuous time domain decompose big data set approximate multiscale detail coefficient based wavelet transform order determine whether density function wavelet coefficient big data set peaky zero heavy tailed shape twocomponent gaussian mixture model gmm employed first time expectationmaximization likelihood method estimate model parameter remote sensing big data set wavelet domain variance gmm changing band time scale comprehensively analyzed statistical characteristic different texture also compared find cluster characteristic wavelet coefficient still obvious remote sensing big data set different band different scale however precise model longterm sequence data set gmm also found scale feature different texture big data set obviously reflected probability density function gmm parameter wavelet coefficient ,2
BD_383,executing big data workload upon high performance computing hpc infrastractures become attractive way improve performance however collocation hpc big data workload easy mainly core concept difference focus challenge related scheduling big data hpc workload computing platform classic hpc workload rigidity job tends create hole schedule idle resource dynamic pool big data workload propose idea based resource management system rjms configuration make hpc big data system communicate simple prologepilog mechanism leverage builtin resilience big data framework minimizing disturbance hpc workload first approach production rjms middleware oar hadoop yarn hpc big data ecosystem respectively technique evaluated real experiment upon grid platform experiment validate assumption show promising result system capable running hpc workload % cluster utilization big data workload fill schedule hole reach full % utilization observe penalty mean waiting time hpc job le % big data effectiveness % average ,2
BD_384,emerging big data application require significant amount server computational power big data analytics application rely heavily specific deep machine learning data mining algorithm exhibit high computational intensity memory intensity io intensity control intensity big data application require computing resource efficiently scale manage massive amount erse data however rapid growth data yield challenge process data efficiently current server architecture big xeon core furthermore physical design constraint power density become dominant limiting factor scaling server therefore recent advocate lowpower embedded core server little atom address challenge methodical investigation power performance measurement comprehensive system level microarchitectural analysis characterize emerging big data application big xeon little atombased server architecture characterization result across wide range realworld big data application various software stack demonstrate choice big v little corebased server energyefficiency significantly influenced size data performance constraint presence accelerator furthermore microarchitecturelevel analysis highlight improvement needed big little core microarchitecture ,2
BD_385,realworld physical abstract data object interconnected forming gigantic interconnected network structuring data object interaction object multiple type network become semistructured heterogeneous information network realworld application handle big data including interconnected social medium social network scientific engineering medical information system online ecommerce system database system structured heterogeneous information network therefore effective analysis largescale heterogeneous information network pose interesting critical challenge book investigate principle methodology mining heterogeneous information network departing many existing network model view interconnected data homogeneous graph network semistructured heterogeneous information network model leverage rich semantics typed node link network uncovers surprisingly rich knowledge network semistructured heterogeneous network modeling lead series principle powerful methodology mining interconnected data including rankbased clustering classification metapathbased similarity search mining relation strengthaware mining many potential development book introduces research frontier point promising research direction table content introduction rankingbased clustering classification heterogeneous information network metapathbased similarity search metapathbased relationship prediction relation strengthaware clustering incomplete attribute userguided clustering via metapath selection research frontier ,2
BD_386,recent year online social networking revolutionized interpersonal communication newer research language analysis social medium increasingly focusing latter impact daily life personal professional level natural language processing nlp one promising avenue social medium data processing scientific challenge develop powerful method algorithm extract relevant information large volume data coming multiple source language various format free form discus challenge analyzing social medium text contrast traditional document research method information extraction automatic categorization clustering automatic summarization indexing statistical machine translation need adapted kind data book review current research natural language processing nlp tool method processing nontraditional information social medium data available large amount big data show innovative nlp approach integrate appropriate linguistic information various field social medium monitoring health care business intelligence industry marketing security defense existing evaluation metric nlp social medium application effort evaluation campaign shared task datasets collected social medium task organized association computational linguistics semeval task national institute standard technology via text retrieval conference trec text analysis conference tac concluding chapter discus importance dynamic discipline great potential nlp coming decade context change mobile technology cloud computing social networking ,2
BD_387,big data era characterized explosion information form digital data collection ranging scientific knowledge social medium news everyones daily life example collection include scientific publication enterprise log news article social medium general web page valuable knowledge multityped entity often hidden unstructured loosely structured interconnected data mining latent structure around entity uncovers hidden knowledge implicit topic phrase entity role relationship monograph investigate principle methodology mining latent entity structure massive unstructured interconnected data propose textrich information network model modeling data many different domain lead series principle powerful methodology mining latent structure including latent topical hierarchy quality topical phrase entity role hierarchical topical community entity relation book also introduces application enabled mined structure point promising research direction ,2
BD_388,big volume bioinformatics data need high processing power bigbio one solution addressing challenge bigbio big data analyst mapreduce hadoop cluster bioinformatics application bigbio tested implementing bioinformatics wordcount problem application mapreduce programming pattern bigbio count number occurrence word text extract unique word molecular sequence application characterized almost lowweight computation big size data set performance bigbio tested bigbio framework could analyze bioinformatics big data faster efficient many bioinformatics application maintaining good processing capability scalability ease maintenance cheap commodity bigbio reduces processing time parallel bioinformatics algorithm compared legacy serial mpi based application testing bigbio stated scale automatically size data bigbio portable many hadoop infrastructure without modification accelerating dataintensive bioinformatics analysis ,2
BD_389,summary form given presentation discus dddas paradigm unifies system modeling instrumentation aspect creating revolutionary capability improved understanding analysis optimized autonomic management decision support operational engineered natural multientity system including human societal system key underlying concept dddas dynamic integration instrumentation data executing model system feedback control loop online data dynamically incorporated system executing model improve modeling accuracy speedup simulation reverse executing model control instrumentation selectively adaptively target data collection process dynamically manage collective set sensor controller dddas timely advent largescaledynamicdata largescalebigcomputing largescaledynamicdata encompasses next wave big data namely dynamic data arising ubiquitous sensing control engineered natural societal system multitude heterogeneous sensor controller instrumenting system opportunity challenge largescales relate size data heterogeneity data data collection modality data fidelity timescales ranging realtime data archival data tandem important dimension dynamic data extended view big computing includes dimension computing collective computing networked assembly multitude sensor controller dddas paradigm driving exploiting notion largescale dynamic data largescale big computing shaping research direction engendering transformative impact range natural engineered system application area spanning environment nanoscale terrascale extraterrascale environment example advance capability presented include material analysis decision support structural system manufacturing system cellular neural biorobotic system environmental system critical infrastructure system urban air transportation energy powergrids smart agriculture ,2
BD_390,internet plus big data science information era increasing rapidly seek special unknown object human exploration mystery universe pursue goal universe spectrum big data mining fairly complex data dimension high correlation dimension strong easy introduce noise missing data much difficult deal metering data article investigates lamost data release star spectrum based high resolution spectral parameter rfitsio software package r language used graphically analyze big data spectrum deep learning analysis extract information large data finding knowledge unknown outlier data fit format spectral large data information rise & ltsup & gt & ltsup & gt level data since big data imported large amount redundant information full spectrum signal star spectrum making full multivariable statistical analysis cluster clustering data characterized line index lick line index spectral feature spectral data clustered kmeans mean algorithm deep learning experiment show data strong physical correlation valid fast clustering outlier analysis big data feature spectral survey completed characteristic data ,2
BD_391,initial form writing current data center human pursue constantly collected information ascend tool led deluge data demand refined data storage system commencement timeline cover sudden increase information big data generated necessity manage save information swiftness information generation increase moore law commencement century exorbitant data making great trouble human being well society development information digitization massive amount data structured semistructured unstructured generated quickly user store vast amount clumsy well sensitive data big data platform sharing sensitive data help organization reduce cost providing user personalized service provide value added data service issue related data security privacy cardinal concern age big data data volume high growing popularity development big data technology bring serious threat security iniduals sensitive information implementing security privacy policy challenge era big data governmental agency healthcare industry private organization invest large resource collection aggregation sharing large amount personal data however secure data sharing problematic ,2
BD_392,biomedical data generated large quantity every day biomedical device also hospital equipment resource well mobile device one technology biomedical computing working called big data however large amount data big data rapidly disappearing since usually used stored research purpose today big data technology find various application area research field biomedical healthcare service biomedical informatics subfield biomedical research one favorite area big data analyzes frequently used recently study point enormous potential big data biomedical research quite important aim identify expectation challenge biomedical informatics term big data technology classifying data gathering data storage data management data analysis line organizational model offered biomedical informatics term big data ,2
BD_393,power system generate huge data operation center information system related equipment em scada gi pmu ami external system etc data posse various characteristic large volume high velocity strong mutual action tool technology seek manage dig value visualize data widely used power system combining advantage mainstream big data ecosystem proposes big data platform power system proposed big data platform includes data integration layer data storage layer data processing layer data visualization layer demonstrate effectiveness proposed big data architecture case salt nonsoluble deposit density big data application platform power system designed result verify effectiveness designed big data platform ,2
BD_394,statistic indonesia charge government duty field statistic census survey compilation statistical data done case survey environment getting worse statistical activity le efficient hand phenomenon called big data arises many research learn extract big data value researcher identified big data combined statistical methodology part data source researcher identified three survey consists consumer price survey business tendency survey data satisfaction survey survey researcher found big data could give opportunity generating statistical data making online submission system information extraction system sentiment analysis establishing legal cooperation private sector way get opportunity delivered big data nevertheless big data also offer many challenge combined statistical methodology researcher identified big data challenge come stage statistical methodology challenge also come legislation security privacy storage processing data access skill requirement financial ,2
BD_395,scalable database management system work online transaction processing system decision support system big data current era play critical role rdbms provide fast solution manage data cloud computing also played good role transformation traditional database management system big data service need provide cloud cloud computing another dimension data processing big data present challenge need addressed successful big data application cloud environment developer designer cloud provider handle issue big data online transaction support decision support adhoc query processing concluding section propose various big data model functionality data management lead bridge developed big data cloud computing boost performance large data reduced cost ,2
BD_396,big data cloud computing two emerging technology revolutionized data storage well analysis big data though defined differently different expert essentially implies large volume structured unstructured data cloud computing hand recent phenomenon technology development led paradigm shift collection collation analysis interpretation data cloud computing platform cloud based analytics center greatly assist big data processing two emerging technology integrated offer numerous advantage field data collection storage collation transfer access analysis interpretation enabling real time decision making thus providing competitive edge business however integration quite challenging presently data stored different platform first step towards integration big data cloud computing integration data single platform inherent challenge attempt explaining big data convergence cloud big data technology emergence hadoop enterprise solution ,2
BD_397,increasing degree information technology electricpower industry amount big data thermal power increased geometrically address problem computational bottleneck traditional data mining deal big data thermal power big data mining thermal power method based spark presented according characteristic actual operation unit proposed method determines steadystate condition big data thermal power ides working condition based external constraint addition data mining method based distributed computing used mine big data thermal power get strong association rule thus best value parameter working condition got lastly historical knowledge base established guide operation unit proposed method method applied mw unit power plant anhui province mine operation data unit day month result simulation show proposed method effectively mine big data thermal power advantage computational efficiency compared traditional data mining big data ,2
BD_398,record linkage aim find record dataset represent realworld entity across many different data source crucial data quality evolution big data difficulty appeared deal mainly v big data property ie volume variety velocity value veracity therefore record linkage big data challenging investigates way apply record linkage algorithm handle volume property big data investigation revealed four major issue first technique used resolve volume property big data mainly depend partitioning data number block processing block parallelly distributed among many executers second mapreduce famous programming model designed parallel processing big data third blocking key usually used partitioning big dataset smaller block often created concatenation prefix chosen attribute partitioning blocking key may lead unbalancing block known data skew data evenly distributed among block uneven distribution data degrades performance overall execution mapreduce model fourth best knowledge small number study done far balance load data block mapreduce framework hence dedicated balancing load distributed block ,2
BD_399,big data penetrated various industry business function become important factor production global economy big data technology system big data collection basis storage analysis integration visualization unstructured data semistructured data become important focus big data innovation traditional structured data longer core big data based life cycle theory digital technology acquisition processing storage organization copyright protection cluster high concurrency retrieval dynamic scheduling intelligent digital display coal mine industry information data collected integrated realize centralized management unified retrieval joint exhibition information resource provide technical mean reference digital construction heterogeneous coal mine information data mean big data thinking ,2
BD_400,every day large number earth observation eo spaceborne airborne sensor many different country provide massive amount remotely sensed data data used different application natural hazard monitoring global climate change urban planning etc application data driven mostly interdisciplinary based truly stated living age big remote sensing data furthermore data becoming economic asset important resource many application specifically analyze challenge opportunity big data bring context remote sensing application focus analyze exactly big data mean remote sensing application big data provide added value context furthermore describes challenging issue managing processing efficient exploitation big data remote sensing problem order illustrate aforementioned aspect two case study discussing big data remote sensing demonstrated first test case big data used automatically detect marine oil spill large archive remote sensing data second test case contentbased information retrieval performed highperformance computing hpc extract information large database remote sensing image collected terrorist attack world trade center york city case used illustrate significant challenge opportunity brought big data remote sensing application ,2
BD_401,increasing maritime traffic due worldwide trade tends increase risk wreck collision contact ship producing sinking high economical cost major environmental impact unfortunately loss life continuous news medium reporting issue government captain vessel traffic centre harbor safety rescue force need better tool prevent accident increase safety optimize operational cost current key technology used ship shore station displayed shown smart technology vessel big data analytic tool could improve safety sailor unmannedremote pilot ship going introduced finally sail tracker project initial development smart ship solution upload share information cloud used cognitive analytic tool ,2
BD_402,recent emergence ubiquitous smart communication device accelerate people post current trending topic real time micro blog tweet post multimedia content social medium site geographical location tag geotags specifically recent flood tamilnadu early warning flooded area emerged get posted popular social medium geoparsed hash tag continuously humanitarian view realtime crisis sparked great interest designing innovative methodology big social medium data analysis supervised machine learning technique actuate immediate disaster response rescue effort near future proposed system performs disaster tweet collection based trending disaster hash tag system performs naivebayesian multinomial ssvm classification collected tweet identify severity disaster based locationtointerpolation cluster proximity disaster geographic map generated affected area approach detects tweet fitted correct classifier label generate output detection rate % % time predicted disaster mapping result highly accurate % real time geoparsed tweet matched actual location atrisk flood ,2
BD_403,discover data skewness problem imposes adverse impact mapreducebased parallel knnjoin operation running cluster propose data partitioning approachcalled knndpto alleviate load imbalance incurred data skewness overarching goal knndp equally ide data object large number partition processed mapper reducer parallel heart knndp data partitioning module dynamically judiciously partition data optimize knnjoin performance suppressing data skewness hadoop cluster data partitioning decision largely depends data property eg distribution analysis highly expensive massive amount data speed dataproperty analysis incorporate sampling technique profile data distribution small sample dataset representing big datasets building datapartitioning cost model parallel knnjoins derive timecomplexity upper lower bound parallel knnjoin algorithm cost model offer u guidance systematically investigate knndps performance knndp obtains global nearest neighbor local nearest neighbor improve accuracy approximation solution augment node local data small amount redundant data develop two knndpbased scheme called lsh+ zvalue+ seamlessly integrate knndp existing lsh zvalue algorithm knnjoin computing implement evaluate lsh+ zvalue+ node hadoop cluster driven synthetic realworld highdimensional datasets experimental result show knndp significantly improves performance lsh zvalue offering high extensibility scalability hadoop cluster ,2
BD_404,electronic medical record emr system deliver many benefit healthcare organization patient serve however one biggest stumbling block garnering benefit limited adoption doctor employ unified theory acceptance technology utaut theoretical foundation adapt theory context emr system adoption doctor specifically suggest age significant moderator gender voluntariness experience play significant moderating role tested model longitudinal month period hospital implementing emr system collected wave survey data doctor used system log measure original utaut predicted % variance intention modified utaut predicted % model comparable prediction addition contributing healthcare utaut research hope serve foundation future integrates utaut theoretical perspective ,2
BD_405,petroleum analytics learning machine palm machinelearningbased brutally empirical analysis system managing internet thing iot upstream midstream oil gas operation palm developed unconventional shale oil gas play america simultaneous analysis hundred iot attribute hundred horizontal well thousand hydraulic fracture stage must analyzed near realtime palm validated shale oil gas well hydraulic fracture stage permian basin tx marcellus basin pa palm comprises machine analytics application apps bigdatacentric computational machine learning predictive prescriptive analysis technique maximize production natural gas hydrocarbon liquid minimizing cost operation palm predictive prescriptive technology utilize support vector machine learning signature realtime random forest decision tree steer hydraulic fracture become high instead low oil gas producer completion horizontal shale well progress palm also us support vector regression logistic regression bayesian model nearest neighbor neural network deep learning network uniquely combined ensemble learning tool weigh importance hundred thousand geological geophysical engineering attribute measured field iot computed theoretical analysis reservoir simulation model seismic monitoring production change time palm iot system since method written separate apps strung together operator utilizing oil gas well attribute compute importance weight predicted oil gas water production allows forecasting accurate estimated ultimate recovery eur lifetime well ,2
BD_406,advance computing capability palpably evident throughout many industry manifest unprecedented largescale data integration inferencing branded bigdata many case question whether technique leverage advance biomedicine clinical practice obvious highthroughput clinical analytics synthesizing genomic clinical attribute particular patient portends predictive model directly influence clinical care decision however make widely shared vision practical scalable barrier attributable data heterogeneity dominate method strategy increase comparability consistency healthcare related data discussed ,2
BD_407,order succeed global competition organization need understand monitor customer behavior could retain predicting preference behavior others recently marketing strategy changed productoriented strategy customeroriented strategy organization focused customer relationship management fact organization found retention customer valuable asset important therefore aim describing data mining ability churn management designing implementation customer churn prediction model standard crispdm cross industry standard process data mining methodology based rfm recency frequency monetary random forest technique database one biggest holding country solico food industry group explored model customer tending turn identified effective marketing strategy planned group customer behavior analysis indicates length relationship relative frequency average inter purchase time among best predictor ,2
BD_408,currently data gathered analyzed utilized easier ever aiding big data technology mobile device elastic computing platform convenient software tool thus privacy data could become bigger issue well propose extend capability prominent privacy preservation model k eanonymous provide better option privacy preservation propose add support privacysensitive ordinal datatype model since originally support numerical data experiment conducted show characteristic modified model result conclude characteristic applied similar original thus effectively applied privacy problem ,2
BD_409,nowadays creating huge amount data every day kind device different format independent connected application flood big data outpaced capability process analyze store understand datasets rapid expansion accelerated dramatic increase acceptance social networking application allow user create content freely increase already huge size web ,2
BD_410,cybersecurity incident short shelf life write fall breach moment theft million american information credit bureau equifax compromise three billion yahoo account russian government theft sensitive national security agency document government contractor home computer time read incident long since eclipsed dozen highprofile breach read recent data breach headline day maybe week publicly announced—we learn many record stolen embarrassing secret revealed breach find fired sue—and story typically fade consciousness overshadowed newer bigger even dramatic incident recent cybersecurity breach grab attention breaking news also there strong sense older incident one happened month ago—or even worse year ago—have nothing teach u already hopelessly outofdate adversary moved tactic technology waste time resource learning defend yesterday attack face constantly evolving threat ? ,2
BD_411,data science encompasses set principle problem definition algorithm process extracting nonobvious useful pattern large data set many element data science developed related field machine learning data mining fact term data science machine learning data mining often used interchangeably commonality across discipline focus improving decision making analysis data however although data science borrows field broader scope machine learning ml focus design evaluation algorithm extracting pattern data data mining generally deal analysis structured data often implies emphasis commercial application data science take consideration account also take challenge capturing cleaning transforming unstructured social medium web data bigdata technology store process big unstructured data set question related data ethic regulation ,2
BD_412,fast ethernet sipof system way mass production complete installation set available eg siemens pof technology offer much higher potential data rate gbps realized pmmagipof also multi carrier transmission sipof data rate gbps gbps demonstrated realized pfgipof parallel transmission pof ribbon presentation give overview presently available technology possible application advantage pof technology comparison glass fiber copper cable biggest application time pof car network even bigger pof market exploited applied home network interconnection solution ,2
BD_413,advent emerging technology cloud computing big data internet thing mobile computing producing tremendous amount data era big data storage device versatile characteristic required ultrafast processing higher capacity storage lower cost lower power operation ssds employing nand promising meet requirement since introduction nand technology marketplace memory array size nearly doubled every continue scaling nand array density essential scale vertically minimize total mold height however vertical scaling result critical problem increasing wl capacitance nonuniformity stacked wls due variation channel hole diameter tackle issue proposes scheme programming speed improvement power reduction onchip processing algorithm error correction ,2
BD_414,% world transoceanic flow message data carried undersea cable satellite dominant carrier today cable carry % much bigger evergrowing total reason bandwidth accurately channel capacity function bandwidth noise level well latest opticalfiber cable least time capacity coaxial forebear whereas today satellite improved modestly whats optical cable improving impressive rate current cable alcatel sa paris example carry gb wavelength total capacity gb single fiber likely grow wavelength besides enormous continuing increase capacity cable enjoy advantage satellite better longevity security adherence installation schedule booster rocket failure cable business name three undersea cablesall km league themlive comparatively sheltered life compared satellite threatened meteor shower space debris sun spot hazardous region shore line depth cable usually heavily armored buried beneath sea floor deep ocean hazard far simply lie bottom suspended occasionally sharp depression calm isothermal environment spl degc surrounded world largest heat sink ,2
BD_415,integration digital rf transmitter digital power amplifier dpa becoming great interest systemsonchip socs available nanometer technology small highspeed switching device directly benefit switching power amplifier achieving peak power high peak efficiency however pa backoff efficiency remains big challenge highdatarate system large peaktoaverage ratio par wlan different solution published enhance power backoff efficiency cost higher complexity larger area ,2
BD_416,describes operating condition volt transmission line pacific light power corporation delivers power big creek hydroelectric development los angeles cal mile away daily operation kw generated utilizing total hydraulic head ft two step plan future contemplate building two power house operating somewhat lower head particular interest complete success constant potential system e operation voltage generating receiving station mean synchronous condenser receiving end conjunction automatic voltage regulator one condenser well generator power house line operated unusual freedom short circuit appendix describe development system give data relating equipment big creek transmission line ,2
BD_417,describes operating condition volt transmission line pacific light power corporation delivers power big creek hydroelectric development los angeles cal mile away daily operation kw generated utilizing total hydraulic head ft two step plan future contemplate building two power house operating somewhat lower head particular interest complete success constant potential system e operation voltage generating receiving station mean synchronous condenser receiving end conjunction automatic voltage regulator one condenser well generator power house line operated unusual freedom short circuit appendix describe development system give data relating equipment big creek transmission line ,2
BD_418,today invehicle infotainment system requires external memory access bandwidth mabw especially high definition hd videoaudio demand maximum utilization sdram access instead expansion sdram capacity due limitation chip size lpddr @ bit sdram support gb efficiency limited around % sdram ac timing idea achieve even mabw limitation introduced placing lossless compression unit source request decompression unit dcu integrated inside memory controller mc number sdram command deducted increasing bus data bandwidth however latency becomes critical issue realtime request may nondecompression going dcu big number processing cycle adaptive solution applied bandwidth latency requirement satisfied nondecompression transaction separated processed outoforder relax latency whereas decompression transaction go dcu decompression processing simulation result lpddr @ bit show average gb mabw data rate decompression video playback data stream realtime requirement maintaining ,2
BD_419,many bigdata bd processor reduce power consumption employing ternary contentaddressablememory tcam prestored signature pattern filter reduce amount data sent processing following stage ie wireless transmission reduce standby power bdprocessors commonly nonvolatile memory nvm back signature pattern srambased tcam stcam power interruption frequentoff operation however macro stcam + nvm scheme suffers long delay requires considerable energy wakeup operation due wordbyword serial transfer data nvm tcam macro signature pattern seldom updated written therefore singlemacro nonvolatile tcam nvtcam used bdprocessors reduce area facilitate fastlowpower wakeup operation compared macro approach previous nvtcams designed diodeconnected tr sttmtj dtr tr pcm tr reram however suffer following issue large cell area high write energy esubwsub due two nvm r device limited wordlength wdl kbit caused small currentratio iratio isubmlmissubk×isubmlsub matchline ml mismatch current isubmlmissub ml leakage current k matched cell k × isubmlmissub long search delay tsubsdsub excessive search energy esubssub due large ml parasitic load csubmlsub small iratio reram promising nvtcam due low esubwsub high resistanceratio rratio multiplelevel cell mlc capability overcome issue develops mlcbased tr nvtcam bidirectional voltageider control bvdc ××b tr nvtcam macro fabricated backendofline beol reram nm cmos process × cell size reduction compared stcam technology tsubsdsubns wdlb ,2
BD_420,chapter saw transmission data could protected errorcorrecting code information could received accurately spite occasional noise code important ingredient getting reliable communication whole story although code correct detect small number bit lost garbled often there bigger failure overcome typical packet network whole packet many bit lost ensure communication still succeeds despite kind loss ? ,2
BD_421,meet requirement high datarates rf transceivers g standard must ultrawide bandwidth mmwave band big challenge g transceiver generate ultralowpn phase noise localoscillator lo signal suppress integrated pn ipn extremely wide bandwidth pll directly generates mmband lo signal good choice due powerhungry frequency iders relatively poor pn mmband lo generator cascading ghzrange pll frequency multiplier shown fig attractive solution first ghzrange pll higher fom mmband pll second cascaded architecture naturally able support band g g standard injectionlocked frequency multiplier ilfm popular mmband achieving ultralow pn even tight power budget however vulnerability pn pvt variation critical problem ilfm pn performance improved freerunning vco frequency fsubvcosub target frequency sufficiently close lock range fsublsub narrow especially high frequency calibrate fsubvcosubover pvt many frequencytracking loop ftls used powerhungry circuit replicavco tdc counter operating fsubvcosub suitable mmband ilfm subsampling ftl used voltage level vco output momentarily sampled injection pulse however accurate sampling pulse width injection pulse must narrow since sampling occurs edge pulse mmband vco pulse width must le p narrow pulse limit injection strength fsublsub mmband ilfm mixer iders consumed lot power envelope detector used another mmband ilfm enable calibration operating low frequency detect fsubvcosubafter vco injectionlocked prevent pn degradation due realtime drift fsubvcosub ,2
BD_422,summary bigger based result arrived orleans data base design workshop outline four major area data base design discus important issue result achieved future research problem ,2
BD_423,highperformance io essential bigdata analysis modern storage system utilize hdds ssds mainly achieving large capacity high performance respectively ssd cache access hdds one promising method improving largescale io performance modern computer addition increasing importance highperformance io processing investigate io performance storage system including ssd ssd cache experimental result show bigdata processing performance improve significantly ssd cache ,2
BD_424,big data extracting valuable information data order intelligent way revolutionize decisionmaking business science society bigdse discus link big data software engineering critically look issue costbenefit big data ,2
BD_425,accurate detection singular region groundpenetrating radar gpr useful assessing roadway pavement bridge deck concrete structure railroad ballast condition locate object large radargram involves extensive computational resource time especially data interest posse small portion whole big data set therefore efficient gpr signalprocessing technique highly demanded proposes entropy analysis narrow data scope interested region considerably reduce computational cost sophisticated data postprocessing joint timefrequency analysis shorttime fourier transform performed singular region location detection refinement proposed methodology tested different laboratory setup analysis result show good agreement physical configuration ,2
BD_426,big data seen number sample feature selection representative feature important uig data analysis reduce dimension feature selection method used handle problem research homogeneous distributed ensemble feature selection method dimensional partition used approach feature selection result showed proposed method improve accuracy feature selection method increase % several datasets addition also speed computation almost two time faster ,2
BD_427,highspeed data transmission expected communication control system conventionally wire halfduplex transmission system data transmitted direction time order increase transfer performance clock frequency must increased however transmission frequency exceeds khz transmission environment become selective call wire duplex transmission system treated lowfrequency highspeed data transmission available wire duplex transmission system however big problem transmission signal contaminated noise become difficult recognize component signal noisy signal research nonlinear wavelet thresholding applied wire duplex transmission signal order remove noise propose modified universal threshold noise estimation method instead median absolute deviation mad method recognition basic signal denoised transmission signal shown evaluated proposed method wire duplex transmission signal ,2
BD_428,wideband power amplifier pa high poweradded efficiency pae required softwaredefined radio highdatarate communication pa classab provide linear amplification pae better classa reported achieve bandwidth larger one octave however classab operation generates large amount & ltsup & gtnd & ltsup & gtharmonic current transistor output amplitude high % fundamental current theory output matching network providing optimum load impedance fundamental frequency insufficient achieve good power performance bringing big challenge integrated classab pa design octave bandwidth demonstrate toghz fractional bandwidth % classab pa designed nm cmos output matching technique based differential architecture enables pa achieve maximum pae % overall pae % proposed provide transistor output optimum load impedance fundamental & ltsup & gtnd & ltsup & gt harmonic octave bandwidth without predistortion pa deliver output power dbm evm & ampltdb qam signal ac format mhz bandwidth ghz ,2
BD_429,article examines key technology trend strategy facing cio including mobility & amp byod personal cloud byoc mobile apps html big data social medium corporate app store inmemory computing actionable analytics hybrid cloud video voice telepresence ,2
BD_430,following topic dealt edemocracy egovernment election big data publicprivatepeople partnership model smart city smart government ecollaboration collaborative working environment social voting recommendation opinion mining ehealth service decision support system ejustice eeducation collaborative learning ,2
BD_431,social medium become ubiquitous globally used social networking content sharing twitter wellknown micro blogging social medium site share exchange people opinion content different aspect life power twitter based prediction magnified importance greatly accepted research investigate tweetbased application deep neural network predict electoral result pakistan collected tweet data twitter api first tuned hyper parameter neural network trained model tweet dataset election tested trained model tweet data set election model showed pti clear winner result close actual outcome election also declared pti biggest political party ,2
BD_432,existing noninvasive lung cancer diagnostic equipment difficulty detecting early stage lung cancer abnormal tissue smaller cm size according study showing volatile organic compound vocs human breath gas provide biomarkers human disease especially lung cancer noninvasive method developed measure exhaled air cancer patient chromatographymass spectrometry gcms however traditional gcms equipment expensive requires specialist operate research demonstrate portable micro gas chromatography μgc system overcome limitation conventional method realize small chip big data ,2
BD_433,lightemitting diode led becoming dominant lighting source conventional counterpart besides benefit high efficiency long lifetime led also show great potential highspeed data transmission wide bandwidth bw addition offering general lighting light output modulated fastswitched led achieve visible light communication vlc though mb datarate demonstrated white led laboratory highfrequency modulation hardly supported commonly used dimmable driver switching converter regulate led current driver changing slope led current limited low loop bw large inductor capacitor linear multiplestring led driver free inductor big capacitor theoretically provide higher turn onoff speed however light output driver usually varies significantly doublelinefrequency considered harmful optical flicker also greatly affect effectiveness data transmission linear driver regulates product led current led voltage mitigate optical variation multiplier added regulation loop resulting limited bw ,2
BD_434,global influence big data growing seemingly endless trend leaning towards knowledge attained easily quickly massive pool big data today living technological world dr usama fayyad distinguished research fellow discussed introductory explanation knowledge discovery database kdd predicted nearly two decade ago indeed precise outlook big data analytics fact continued improvement interoperability machine learning statistic database building querying fused create increasingly popular sciencedata mining knowledge discovery next generation computational theory geared towards helping extract insightful knowledge even larger volume data higher rate speed trend increase popularity need highly adaptive solution knowledge discovery necessary research introducing investigation development bitquestions metaknowledge template big data processing clustering purpose research aim demonstrate construction methodology prof validity beneficial utilization brings knowledge discovery big data ,2
BD_435,jpls airborne snow observatory integrated imaging spectrometer scanning lidar measuring mountain snow albedo snow depthsnow water equivalent ice height exposed describes first project snow campaign course month aso flew tuolumne river basin sierra nevada california oshaughnessy dam hetch hetchy reservoir focusing initial tuolumne moved weekly flight uncompahgre basin colorado meet need customer including water resource manager keenly interested snow melt aso team develop end end hour latency capability processing spectrometer lidar data level level product describes big data processing architecture data system aso ,2
BD_436,big data structured unstructured data contains million attribute multiple dimension arisen threeissues measure structured unstructured multidimensional data pattern big data analysis display multidimensional data pattern normal size screen optimize data attribute big data visualization visual analyzed big datavariety based complexity multidimensional data firstly introduced dimension ided multidimensional dataset data pattern subset establish dratio algorithm measure dimension multiple data pattern second createtwo additional parallel ax dratio compare dimensional pattern visualization third dimension clustering shrunk attribute introduced dratio parallel coordinate reduce data overcrowed experiment show model efficiently accurately used big data analysis visualization ,2
BD_437,development flash memory drive flash based ssds enter enterprisescale storage system kernel ssd flash translation layer ftl attracts many attention generally two type ftls according granularity address mapping blocklevel pagelevel mapping ftls focus latter one typically pagelevel mapping scheme must employ cache alleviate memory pressure introduced big mapping table argue classic cache replacement policy arent competent page table cache ftls major contribution design dedicated cache replacement policy called two filter abbreviated f pagelevel mapping ftls f aim two goal first higher hit ratio replacement policy pursue f protects frequently accessed page also protects sequentially accessed page little cost achieve higher hit ratio second goal distinguish hot page cold goal special page table ftls hot cold page directed separate block garbage collection efficient order achieve goal f employ two filter one used containing sequentially accessed page another used selecting hot page trace driven simulation f outperforms classic replacement policy hit ratio data classification ,2
BD_438,demand low cost large scale storage increase recently several low throughput storage service pogo plug cloud developed service based amazon glacier low throughput low cost large capacity therefore service suited backup archive big data used instead offline storage tier low throughput storage low throughput also low reliability communication path need efficient retransferring mechanism proposed split file model represent big data efficiently low throughput storage split file model large file ided many small part stored directory developed tool command support transparent way split file command replicated data naturally excluded effective shallow copying supported furthermore propose split file mode based tier storage ,2
BD_439,several recent study shown dictionary learning sparse representation effectively reconstruct hundred interacting functional brain network simultaneously wholebrain fmri data however accurate classification recognition hundred functional network inidual population many subject still challenging problem due intrinsic variability functional network noise source tackle problem present effective deep learning framework train convolutional neural network large dataset hundred thousand available brain network volume map applied testing sample network classification recognition effectively applied computerlabeled data training set whole process automated experimental result showed proposed method quite robust handling noisy pattern dataset suggests offer computational framework modeling functional connectomes fmri big data future ,2
BD_440,great amount emerging data creating many opportunity data analysis visual analytics etc top explored angle put big data big data turn trash significant information extracted need presented & amp visualized manner visuals milk already previous accepted discussed conventional & amp novel approach data visualization & amp also future scope going upon future scope proposed previous ie interactive visualization blindly showing diagram sometimes may useful doesnt reveal much fact proper analyzable pattern insight concluded visuals interact also important one choose right chart data analyzed set right visualization therefore help seeing various angle topic & amp hence deriving various trend & amp result unknown u set visuals used commonly & amp latest corporate world also shown attempt made propose feature storytelling discussed brief ,2
BD_441,object detection play important role automation industry big challenge detect object image without knowing pose condition appropriate template obtained propose object detection method based line set matching algorithm us line segment represent model applies projection transform get several model set extract line segment image lsd hence object detection converted line set matching problem finally algorithm us ispd similarity measurement find best matching data set model set restricted steepestdescent local matching method experimental result show proposed method detect object image obtain pose simultaneously ,2
BD_442,hypertension associated increased morbidity mortality coronary heart disease chd however risk factor cause hypertension patient develop chd remain unclear aim traditional nontraditional risk factor chd hypertension population data extracted regional medical big data system shenzhen big city china included hypertension patient aged year old among chd event occurred year first followedup logistic regression model used evaluate risk factor quantitatively predict risk chd event result showed traditional generalpopulationbased chd risk factor age body mass index diabetes hyperlipemia chronic kidney disease still remained predictive hypertension patient addition odds ratio % confidence interval chd emotional mental disorder sleep disorder model showed good discriminative performance auc offered insight hypertension patient keeping psychological health maintaining good sleep quality could helpful preventing chd given high risk chd patient hypertension control risk factor may substantial preventive effect chd ,2
BD_443,numerous scientific application sparse matrixvector multiplication spmv one important kernel unfortunately due low ratio computation memory access spmv inherently memory bound problem hand memory bandwidth commercial offtheshelf cot architecture insufficient available computation resource platform well known memory wall problem result cot architecture unsuitable spmv furthermore spmv requires random access memory space far big cache hence becomes difficult utilize memory bandwidth already scarce propose algorithm large spmv problem specially optimized fully exploit underlying microarchitecture overall system capability algorithm implemented two step key feature first step convert memory random access streaming access reduces overall data transfer volume significantly ensures full utilization memory bandwidth top propose metadata compression technique namely variable length delta index vldi decrease data transfer volume even vldi particularly effective sparse matrix metadata payload ratio high eg sparse bit matrix ,2
BD_444,fast robust threedimensional reconstruction facial geometric structure single image challenging numerous application introduce learningbased approach reconstructing threedimensional face single image recent face recovery method rely accurate localization key characteristic point contrast proposed approach based convolutionalneuralnetwork cnn extract face geometry directly image although deep architecture outperform model complex computer vision problem training properly requires large dataset annotated example case threedimensional face currently large volume data set acquiring bigdata tedious alternative propose generate random yet nearly photorealistic facial image geometric form known suggested model successfully recovers facial shape real image even face extreme expression various lighting condition ,2
BD_445,increase number forest fire last year dispatch government take precaution besides prevention early intervention also important fire fighting firefighter know fire time would easier stop fire therefore big need simulating fire behavior exists proposing system simulate propagation fire time also system visualize propagation fire dgis environment accepts kmz file format besides demanded data visualized map system give chance fire planning firefighter system visualize result screen therefore better understanding terrain obtained ,2
BD_446,explore human pose estimation single rgb image many approach try directly predict pose image measurement explore simple architecture reason intermediate pose prediction approach based two key observation deep neural net revolutionized pose estimation producing accurate prediction even pose selfocclusions bigdatasets mocap data readily available making tempting lift predicted pose simple memorization eg nearest neighbor resulting architecture straightforward implement offtheshelf pose estimation system mocap library importantly demonstratethatsuchmethodsoutperformalmostallstateoftheart pose estimation system directly try regress pose measurement ,2
BD_447,time big data promotes increasingly higher demand finemotion analysis hand activity recognition however realworld scenario hand activity recognition suffers huge challenge variation illumination pose occlusion depth acquisition provides effective way solve issue simultaneously increase computational complexity significantly novel scaleand rotationinvariant descriptor called mosurf presented hand finemotion analysis outperforms previously proposed scheme respect robustness high efficiency data processing hierarchical classification based content hcc proposed activity recognition experiment based available rgbd datasets show consistently better performance realworld application finemotion analysis term high effectiveness efficiency ,2
BD_448,present attempt model ldquoa famosa fortressrdquo malaysia building built portuguese went several architectural development change largely destroyed british occupation biggest challenge research determine original fortress layout due lack authoritative documentation pertaining fortress detail analysis conducted identify reliable source reference available form text visual focus comparison selected textual visual data come verifiable conjectural layout fortress previsualized layout model sample model presented however still room improvement finalized output research tested application tourism education ,2
BD_449,visualization one intuitive perceptible way information representation especially true data complex large easily handled many visualization technique developed effectively representing different type information however dealt earthquake big data recent strong earthquake disaster occur frequently around world many scientist suggested earth entered active seismic period taiwan located seismically active zone therefore project developed visualization system aim enhance user awareness earthquake taiwan ,2
BD_450,current rgbd sensor provide big amount valuable information mobile robotics task like map reconstruction storage processing incremental data provided different sensor time quickly becomes unmanageable focus map representation propose growing neural gas gng network representation model input data gng method able represent input data desired amount neuron preserving topology input space experiment show gng method yield better input space adaptation stateoftheart map representation method ,2
BD_451,shapeconstrained iterative algorithm proposed register rigid template pointcloud given reference pointcloud algorithm embeds shapebased similarity constraint principle gravitation shapeconstrained gravitation induced reference control movement template iteration template better aligns reference term shape constraint enables alignment difficult condition introduced change presence outlier andor missing part translation rotation scaling discus efficient implementation technique least manual intervention registration shown important change detection pointcloud algorithm compared three stateoftheart registration approach experiment done synthetic realworld data proposed algorithm shown perform better presence big rotation structured unstructured outlier missing data ,2
BD_452,internet corporate data warehouse full type digital information simple text document complex application one type information gaining prominence threedimensional object computeraided design cad drawing complex engineering part digital representation protein complex molecule increasing amount information making way onto web corporate database advance computing power combined interactive modeling software let user create image query search made dsearch technology possible searching several important element voxel query formulation search process search engine help big company quickly find whether certain part inventory ,2
BD_453,proposes segmentation algorithm threedimensional dense point cloud specially designed natural environment ground unstructured may include big slope nonflat area isolated area technique based geometricfeatured voxel map gfv scene discretized constant size cube voxels classified flat surface linear tubular structure scattered undefined shape usually corresponding vegetation since pointbased technique computational cost significantly reduced hence may compatible realtime application ground extracted order obtain accurate result posterior segmentation process scene split object second segmentation region inside object performed based voxels geometric class evaluates proposed algorithm various version several voxel size compare result method literature segmentation evaluation algorithm tested several differently challenging handlabeled data set two metric one novel ,2
BD_454,describe method object scanning aligning depth scan taken around object timeofflight camera tof camera measure depth scan video rate due comparably simple technology bear potential low cost production big volume easytouse costeffective scanning solution based sensor could make scanning technology accessible everyday user algorithmic challenge face sensor level random noise substantial nontrivial systematic bias show surprising result scan reasonable quality also obtained sensor low data quality established filtering scan alignment technique literature fail achieve goal contrast algorithm based combination superresolution method probabilistic scan alignment approach explicitly take account sensor noise characteristic ,2
BD_455,many software service cloud computing provided unification management data low cost focus big data cloud computing source software openstack eucalyptus order consider interesting aspect big data cloud computing propose approach software reliability assessment based ahp three dimensional stochastic differential equation model moreover develop software tool based model ,2
BD_456,present method analyze crowd computer vision technique virtual environment overcome difficulty obtaining video evidence hazard situation meet demand big data machine learning method attempt virtual model simulate actual one prove reliability virtual crowd model simulated three situation people walk normally somebody run fast crowd gathered collected corresponding reallife video adopted technique pedestrian detection optical flow extraction examine virtual actual crowd model finally compared result model analysis found two kind model meet requirement stage proved method proposed could find video surveillance reconstruction demand combination computer vision computer graphic ,2
BD_457,advance memory technology including ddram memory high bandwidth memory hbm hybrid memory cube hmc system wide io memory promise large bandwidth lower power consumption address need highperformance computing well emerging big data application however order fully benefit bandwidth necessary understand optimally organize data across channel rank bank vault memory structure obtain large volume data fewer access schedule thread multi threaded application benefit memory organization examine different memory organization spread data across channel rank bank identify application feature benefit different organization applies generic ddr memory structure well ddrams also evaluate scheduling openmp thread eg static dynamic guided emphasis different scheduling method benefit different memory organization best scheduling application proper memory organization experiment show achieve percent performance gain depending workload ,2
BD_458,one keywords information society data data resource technology big data artificial intelligence internet thing iot etc also collect data via wireless connection lot medium access control mac protocol proposed additionally advance technology boundary node largened expansion node well sink mobility furthermore node deployed air submarine environment height node meaningfully different dimensional group management mac protocol mac protocol designed network type sensor node mobility deployed dimensional environment however still problem caused randomness sink mobility propose dimensional group management mac protocol controlled mobile sink ,2
BD_459,ct dynamic volume imaging system moving organ image quality comparable conventional ct dynamic conebeam ct realize several breakthrough largearea dimensional detector highspeed data transfer system reconstruction algorithm ultrahighspeed reconstruction computer highspeed continuous rotating gantry among development detector one biggest task wide dynamic range high data acquisition speed view rate ct detector developing ctscanner together keycomponents take one volume sec matrix spl time spl time describes concept design well preliminary development detector ,2
BD_460,recently deep learning dl become popular approach bigdata analysis image retrieval high accuracy fig show various application text image motion recognition dl due bestinclass recognition accuracy type dl supervised dl labeled data unsupervised dl unlabeled data unsupervised dl learning time spent massively iterative weight update restricted boltzmann machine mb training dataset & ampgt top computational capability ~gbs io sram data bandwidth required ghz cpu need & ampgt hour learning time k inputvector dataset take ~ second recognition far realtime processing thus dl typically done cloud server highperformance gpu environment learningonserver capability however wide smart portable device smartphones tablet result many application need bigdata processing machine learning tagging private photo personal device highperformance energyefficient dldi deep inference processor required realize usercentric pattern recognition portable device ,2
BD_461,propose novel time series analysis based persistent scatterer interferometry psi detect spatial big change construction occurrence time psi detects analysis persistent scatterer p point characterized strong coherent signal throughout timeseries sar image usually form buildingshaped pattern urban area hence potential p point disappear emerge specific date big change discarded define point big change bc point approach pixel high temporal coherence first detected p point standard psi processing introduce change index sequence pixel computed temporal coherence different image subset defined timeseries break date quantify probability bc point different date change index pixel used design automatic thresholding method extract bc point afterwards disappearing emerging date bc point detected break date based temporal variation change index sequence simulation test prof overall producer user accuracy better % real data test pattern disappearing emerging building successfully recognized berlin germany occurrence date ,2
BD_462,future cellular system employ socalled big three technology udn massive mimo mmwave andor terahertz communication goal support explosive demand mobile broadband service foreseen next decade investigate joint impact three technology systemlevel simulation evaluate performance twotier cellular network μ wave macrocells densely deployed mmwave small cell result show much higher capacity realized udns macrocellonly setup result also reveal performance scale proportionally increase employed mmwave bandwidth corresponding increase noise due larger bandwidth reduces sinr outdoor user experience promising data rate notwithstanding throughput indoor user highly degraded due additional wall indoor loss top inherently high path loss mmwave frequency reduce sinr indoor user therefore technique significantly enhance sinr highly import ant design consideration unleashing amazing prospect potential mmwave udns ,2
BD_463,g communication system attracting research attention throughout world providing seamless experience g network accommodate large number user internet thing iot environment gigabitpersecond gbps data rate mmwave communication consideration bigdata bd g environment several billion device connected seamlessly among mmwave communication secure connection g millimeter wave mmwave communication system proposes mmwave signal transmission low latency connection offer gigabitpersecond gbps speed discus g application service g vision challenge many challenge proposed mmwave communication system g mmwave communication system revolutionizing user ,2
BD_464,recent advance wireless networking big data technology g network medical big data analytics internet thing recent development wearable computing artificial intelligence enabling development implementation innovative diabetes monitoring system application due lifelong systematic harm suffered diabetes patient critical design effective method diagnosis treatment diabetes based comprehensive investigation article classifies method diabetes diabetes exhibit deficiency term networking intelligence thus goal design sustainable costeffective intelligent diabetes diagnosis solution personalized treatment article first propose gsmart diabetes system combine stateoftheart technology wearable machine learning big data generate comprehensive sensing analysis patient suffering diabetes data sharing mechanism personalized data analysis model gsmart diabetes finally build gsmart diabetes testbed includes smart clothing smartphone big data cloud experimental result show system effectively provide personalized diagnosis treatment suggestion patient ,2
BD_465,mobile access network experience significant challenge compared situation today traffic volume expected increase time number connected device time higher today networked society unconstrained access information sharing data available anywhere anytime anyone anything one big challenge provide fold capacity increase billion device affordable sustainable way low energy consumption key achieve take starting point situation today try pinpoint important focus area potential solution designing energy efficient g mobile network architecture include system architecture logical separation data control plane seen promising solution network deployment heterogeneous ultra dense layout positive effect radio transmission introduction massive antenna configuration identified important enabler finally backhauling solution need energy efficient today ,2
BD_466,big data contains image video text audio form data collected multiple datasets difficult process traditional database management tool application establish w model w data dimension big data analysis visualization w data dimension stand data content data occurred data came data occurred received data data transferred framework classifies big data attribute pattern also establishes density pattern provide analytical feature visual clustering display data sending receiving density demonstrate big data pattern model tested network security iscx dataset experiment show model clustered visualization efficiently used big data analysis visualization ,2
BD_467,summary form given complete presentation made available publication part conference proceeding cesi workshop summary cesi conducting empirical study industrial setting aim identifying debating mitigating barrier challenging design execution empirical study industrial setting past workshop also aimed improved understanding emergence industrialstrength empirical result critical characteristic research method needed yield result well aggregating inidual study result towards practical evidencebased guideline would like give special emphasis building managing big data system benefit empirical study context big data system bring type software engineering challenge test optimization planning requirement enhancement optimization code algorithm decentralization development task role software analytics etc today research finding empirical study isolated paper published specific research group however widely accepted replication study important build body knowledge empirical software engineering enable transfer novel approach finding different setting context also believe improved understanding challenge conducting empirical study industry ii considering challenge design experiment iii replicating empirical study different setting would lead actionable outcome thus proposed workshop also interested determining kind followon action recommendation taken upon result empirical study recommendation become even important era managing big datadataintensive system designing managing system require empirical analysis field ,2
BD_468,biggest unknown facing data science today society choose answer version old question regarding best balance freedom privacy iniduals minority security interest society context data science old question framed follows society view reasonable way gather data relating iniduals context erse fighting terrorism improving medicine supporting publicpolicy research fighting crime detecting fraud assessing credit risk providing insurance underwriting advertising targeted group ? ,2
BD_469,equipment become compact reliable essential power supply unit also compact reliable past high frequency switching one way miniaturize power supply equipment recent year mo fet developed enabling switching several megahertz requires optimum switching frequency determined since part become miniaturized densely packaged although reduces required packaging space increase temperature big factor determining reliability life equipment explains optimum switching frequency determined studying loss size part also explains design used highdensity package compare measured data computer simulation data khz compact power supply module ,2
BD_470,obvious trend modern society proliferation system sense react world smart phone smart home selfdriving car smart city proliferation smart device sensor present challenge privacy also driving growth big data development technology paradigm internet thing context data science growing impact across many area life however two area data science lead significant development coming decade personal medicine development smart city ,2
BD_471,big data analytics omnipresent today business environment whats technology internet thing everexpanding online social graph emergence data increase need deep analytical knowledge skill many company already invested big data analytics gain better understanding customer behavior fact due introduction various regulatory guideline mature analytical application found customerfocused area insurance risk management financial fraud detection ,2
BD_472,big data created number challenge relation management complexity variability mainly aggregation synthesis focus different aspect iniduality affected big data specifically proposes detail specific inidual right data subject might sufficiently protected relation big data number conclusion drawn show necessity eu legal framework adapt challenge posed big data ,2
BD_473,ternary contentaddressable memory tcam used search engine network bigdata processing nonvolatile tcam nvtcam developed reduce cell area search energy e standby power beyond achieved srambased tcam stcam particularly application long idle time frequentsearchfewwrite operation nvtcams previously designed diodetr dtr sttmtj tr phasechange memory tr tr reram however nv device suffer following issue high e requirement due celldccurrent idccell well large matchline ml parasitic load cml particularly wordlength wdl long large due two nvm r device incell control logic limited wdl caused small ml currentratio imlratio ≅ imlmisn*imlm mismatch current imlmis leakagecurrent imlm cell ml particularly nvm resistance rratio rhrs rlrs highr hr rhrs lowr lr rlrs state small due process variation long search delay tsd due large cml small imlratio proposes tr cell reduce cml e well increase imlratio regionsplitter r sense amplifier sa achieve robust sensing smaller mlvoltage vml swing vmls reduce tsd e ,2
BD_474,recent year global population people forcibly displaced conflict persecution reached level unprecedented since world war ii acute natural hazard also lead largescale movement people temporarily others permanently since number disasterdisplaced averaged million idmc many case humanmade natural factor precipitate largescale displacement witnessed recurrent famine somalia caused confluence drought conflict political instability impede access food relief chapter identifies novel big data source methodology challenge need addressed order develop robust timely reliable evidencebased system detecting forecasting forced migration context humanitarian crisis ,2
BD_475,engineering human health healthcare delivery one significant frontier progress computational scientist article focus opportunity challenge big data transforming healthcare delivery ,2
BD_476,evergrowing number cyberattacks last year put iniduals well largescale organisation stateofemergency situation dawn big data internetofthings era discovery personal information inidual profiling raise significant information privacy concern challenging regulator around globe hearing aid often effective therapeutic measure inidual hearing loss number active device could potentially cybercontrolled used malicious reason suggests threat taken lightly aim identify cybersecurity privacy concern arisen last year based advance communication protocol used hearing aid security identification potential hacking cyberattacking method aimed device need potential countermeasure action taken seriously order ensure patient privacy ,2
BD_477,recent increasing interest big data artificial intelligence emerging demand highperformance memory system large density high databandwidth however conventional dimmtype memory difficulty achieving gb due limited pin count signal integrity issue highbandwidth memory hbm dram tsv technology wide io prominent solution problem still many limitation including power consumption reliability present powerefficient structure tsvs reliability costeffective hbm dram core architecture ,2
BD_478,highthroughput matching memory mm datadriven microprocessor discussed mm constructed hashing memory however one biggest problem hashing memory necessity selective processing whenever hashed address conflict occur eliminate problem mm incorporated small amount associative memory words* b well hashing memory words* b matching operation subided three pipeline stage controlled elastic pipeline scheme structure mm high throughput megaaccesss mm realized & lt & ltetx & gt & gt ,2
BD_479,ghz w twta onboard part communication equipment conceived flexible element different experiment demonstration eg videoteleconference two earth station teleeducation data video transmission twta design travelingwave tube amplifier described herein designed selenia spazio spa current esa contract development olympus program biggest advanced european program telecommunication ,2
BD_480,emergence cloud computing big data analytics accompanied sustained growth batterypowered mobile device continues drive importance energy area efficient cpu soc design lowvoltage operation remains one primary approach active power reduction sram lsubminsub limit minimum operating voltage device size quantization continues challenge compact sram design finfet technology careful cooptimization technology assist circuit design required highdensity lowvoltage array implementation present two sram array design nm lowpower cmos technology featuring suprdsup generation finfet transistor highdensity mbmmsupsup array lowvoltage mbmmsupsup array ,2
BD_481,manual labeling difficult timeconsuming labeled sample used train supervised classifier generally limited become one biggest challenge hyperspectral imagery classification order tackle issue recent trend exploit structure information material reflects region homogeneity spatial domain offer invaluable complement spectral information respect gabor wavelet introduced extract joint spectralspatial feature hyperspectral image one one hand feature extracted gabor wavelet lead good performance classification hand drawback ie big number feature high computational cost limit applicability gaborwaveletbased phase coding hamming distancebased matching dgpchdm framework developed hyperspectral imagery classification proposed method instead taking account large volume gabor magnitude feature exploit gabor phase feature certain orientation ie direction parallel spectral axis encoded simple quadrant bit coding scheme normalized hamming distance matching hdm method adopted determine similarity two sample nearest neighbor classifier routinely utilized pixelwise recognition finally experiment three real hyperspectral data set show proposed dgpchdm lead good performance comparison stateoftheart method literature term classifier complexity generalization ability small training set also included ,2
BD_482,canopy radiation scattering signal contain abundant vegetation information many biophysical parameter quantitatively retrieved help canopy radiation scattering model joint simulation threedimensional model multiband combine advantage different spectral frequency domain could useful tool validation remote sensing manuscript present joint simulation platform dmultisim simulates spectral response visible microwave band validated platform corn field experimental data huailai testing site chinese academy science correlation coefficient validation data simulation result higher relative mean deviation % thermal infrared band correlation coefficient variation simulated directional bright temperature π space le °c reason may due model limitation high leaf area index lai microwave band simulation data validation data best consistency l band whereas trend bigger deviation x cband application platform performed sensitivity analysis radiation scattering response lai incidentobservation geometry multiband simulation result analyzed quantitatively application joint simulation platform proposed ,2
BD_483,describe design concept performance bit softdecision ic open vista terabitcapacity optical communication system dramatically improving capability forward error correction fec proposed softdecision ic composed five functional block ie softdecider error filter bit encoder demultiplexer clock recovery circuit biggest challenge softdecision block regenerating common data seven deciders separate threshold employed novel sige bicmos process custom bga package made lowtemperature cofired ceramic achieve high sensitivity mvpp wide phase margin spl deg gb nonreturntozero nrz data signal error filter bit encoder incorporated ic prevent degradation fec performance due signal noise fluctuation demultiplexer provides accessible interface fec encoderdecoder lsi clock recovery circuit based phaselockedloop technology fulfilled jitter tolerance requirement corresponding itut g even % duty cycle optical returntozero rz signal bit softdecision ic cooperation block turbo encoderdecoder achieved record net coding gain db % redundancy db away shannon limit code rate binary symmetric channel ,2
BD_484,high performance analog frontend intelligent tyre mem accelerometer sensor presented analog frontend part bigger systemonchip totally integrated inside car tyre aim interchange real time data car central unit system intrinsically selfbiased vibrationbased scavenger device used low power budget available analog frontend & ltμw constantcharge capacitancetovoltage conversion used readout input acceleration sensing allows reduce power circuital complexity time large signaltonoiseratio & gtdb hz÷khz bandwidth obtained simple inband noise filtering maintaining passband frequency response acceleration readout input signal prototype accelerometer analog frontend designed cmos μm technology node overall readout power consumption μw single v supply voltage ,2
BD_485,web gi experiencing development system system web gi based vrml popular form web gi analyzing existing web gi system based vrml point disadvantage introduces next generation standard webd xdextensible specification web gi model based xd also put forward advantage vrml incomparable good rehostability easy realization big scene graph integration heterogeneous database spatial data sharing mutual operation etc ,2
BD_486,multiplelevel cell mlc storage provides increased capacity hence reduced costperbit memory technology thereby rendering technology suitable big data application phasechange memory pcm however mlc storage seriously hampered phenomenon resistance drift readout circuit pcm specifically designed drift resilience mlc operation drift resilience achieved specific nonresistancebased cellstate metric contrast traditional cellstate metric ie lowfield electrical resistance builtin drift robustness circuit provides fast efficient implementation driftresilient metric enabling first time performance required non volatile memory application addition exploiting non linear subthreshold iv characteristic pcm cell readout architecture promise increase distinguishable signal range proposed read circuitry designed fabricated nm cmos technology experimental result integrated test resistor array readout circuit characterization presented demonstrating access time n bit raw bit effective resolution circuit lownoise characteristic exhibit sensitivity bitline parasitics readout circuit cointegrated mb xnm pcm cell array necessary programming electronics ,2
BD_487,datadriven machine learning processor dsupsupmlp mimd architecture designed big data analysis adopting configurable counting engine array layer dimension merging dsupsupmlp process maximal dimensional data parallel query learning stage implement nm cmos technology dsupsupmlp achieves x x faster processing time cpu gpgpu respectively application phase maximal k class classification performed learned density model operated v mhz dsupsupmlp demonstrates energyefficient solution learning classification mjgbquery μjclassification respectively ,2
BD_488,recent advance development semiconductor allow realization low cost ghz radar frontends suitable automotive application requirement angular resolution often force designer implement antenna array last decade trend move towards digital array processing instead analog beamforming availability cheap digital signal processor dsp case nelement receive array system must capable processing n receive channel parallel resulting big amount data field programmable gate array fpga deliver processing power flexibility handle collected data allow conjunction dsp implementation sophisticated signal processing algorithm deal implementation ghz frequency modulated continuous wave fmcw prototype radar system system designed array processing application maximum eight parallel receive channel functionality prototype system demonstrated imaging application help portal axis radar moved synthetic aperture order reconstruct reflectivity map imaging area ,2
BD_489,fast image reconstruction technique becoming important increasing number scientific case high resolution micro nano tomography processing large scale data demand mathematical tool tomographic reconstruction due high computational complexity current algorithm big data size demand powerful hardware sophisticated numerical technique several reconstruction algorithm dependent mathematical tool called backprojection transposition process conventional implementation backprojection operator cubic computational complexity manuscript propose fast backprojection operator processing tomographic data providing lowcost algorithm compare formula fast transposition technique real simulated large data set ,2
BD_490,contentbased image retrieval cbir received great attention medical community capable retrieving similar image known pathology however sheer volume data produced radiology center precluded cbir daily routine hospital volume medical image produced medical center increased fast annual data produced exam big radiology center greater terabyte therefore reached unprecedented age bigdata bagof approach speed image retrieval lung nodule stored large medical image database solution combine texture attribute registration algorithm together capable retrieving image benign lung nodule greaterthan % precision greaterthan % malignant case yet running minute grid making usable clinical routine ,2
BD_491,mapreduce emerged efficient platform coping big data achieves goal decoupling data distributing workload multiple reducer processing fully parallel manner zipfs law asserts many type data studied physical social science frequency event inversely proportional rank frequency table ie key distribution skewed however hash function mapreduce usually generates unbalanced workload multiple reducer skewed data unbalanced workload multiple reducer lead degrading performance mapreduce significantly overall running time mapreduce cycle determined longest running reducer thus important issue develop balanced partitioning algorithm partition workload evenly reducer proposes balanced partitioning mechanism collapsedcondensed trie mapreduce evenly distributes workload reducer collapsedcondensed trie introduced capturing data statistic authentically requires reasonable amount memory usage incurs small running overhead propose quasioptimal packing algorithm assign subpartitions reducer evenly resulting reducing total execution time experiment inverted indexing realworld datasets conducted evaluate performance proposed partitioning mechanism ,2
BD_492,substantial amount big data consumed via mobile device accessing content via wireless data connection mobile device set challenge among challenge speed data transfer usually first priority although many fast data connection available web surfing g lte etc actual connection speed could vary significantly among different region fast connection may available result experience viewing information varies different type data connection different location proposes utilising type data connection bandwidth determine whether dataset need cached prefetched reduce response time thereby providing better experience role mobile device owner form basis dataset construction criterion technique role mining mobile device confined particular space effort trace owner movement determines owner device heading towards help identify different connection speed pattern owner path different caching prefetching strategy deployed beforehand aim consistent quality service ,2
BD_493,allocation class seat flight airline industry closely connected multiple correlating factor including yield management airfare strategy airline policy regulation price modification travel agency booking reservation behavior customer different various machine learning method targeting direct fare price prediction constructed state predictor class seat applying naïve bayes algorithm based multinomial event model core flight reservation inventory big data tell probability class availability next several hour day four fundamental model one integrated model developed propose optimal decision airfare search engine layer make engine capable forecasting smart buyorwait suggestion customer experimental route sha tyo integrated model reach average % accuracy ,2
BD_494,among various natural calamity flood considered one catastrophic natural hazard significant impact socioeconomic lifeline country assessment flood risk facilitates taking appropriate measure reduce consequence flooding flood risk assessment requires big data coming different source sensor social medium organization however data source contain various type uncertainty presence incomplete inaccurate information present belief rulebased expert system brbes developed big data platform ass flood risk real time system process extremely large dataset integrating brbes apache spark webbased interface developed allowing visualization flood risk real time since integrated brbes employ knowledge driven learning mechanism compared datadriven learning mechanism determine reliability assessing flood risk integrated brbes produce reliable result comparison datadriven approach data expert system collected considering different case area bangladesh validate system ,2
BD_495,cyber security context big data known critical problem present great challenge research community machine learning algorithm suggested candidate handling big data security problem among algorithm support vector machine svms achieved remarkable success various classification problem however establish effective svm need define proper svm configuration advance challenging requires expert knowledge large amount manual effort trial error formulate svm configuration process biobjective optimization problem accuracy model complexity considered two conflicting objective propose novel hyperheuristic framework biobjective optimization independent problem domain first time hyperheuristic developed problem proposed hyperheuristic framework consists highlevel strategy lowlevel heuristic highlevel strategy us search performance control selection lowlevel heuristic used generate svm configuration lowlevel heuristic different rule effectively explore svm configuration search space address biobjective optimization proposed framework adaptively integrates strength decompositionand paretobased approach approximate pareto set svm configuration effectiveness proposed framework evaluated two cyber security problem microsoft malware big data classification anomaly intrusion detection obtained result demonstrate proposed framework effective superior compared counterpart algorithm ,2
BD_496,according domingospsila biasvariance decomposition framework biasvariance characteristic standard multiple criterion linear programming mclp classification method experimental result show domingospsila biasvariance decomposition framework bias much bigger variance boosting ensemble doesnpsilat behave better bagging ensemble increasing training example effectively reduce variance rather bias conclude mclp intrinsically stable classification method appropriate ensemble method mclp rest characteristic specific data set data easily linearly separated mclp low bias bagging employed lessen variance data complicated nolinear structure mclp high bias boosting ensemble considered reduce bias boosting used noise fitting considered ,2
BD_497,cloud computing involves multidisciplinary development integration result information technology related application web science core collection database used data source excel bibexcel vosviewer citespace software data mining quantitative analysis research paper cloud computing explore trend change distribution research force key area research hot spot international cooperation result show number document cloud computing growing many subject involved research cloud computing technology mainly computer science engineering telecommunication many research paper cloud computing china united state china prominent international cooperation strong cooperative relation major country chinese academy science active research cloud computing paper far ahead institution focus virtualization mobile cloud computing big data security etc hot spot research mobile cloud computing big data fog computing secure storage access control sever consolidation etc ,2
BD_498,bidirectional fiberwireless fiberinvisible laser light communication ivllc convergence system adopts dualpolarization modulation scheme machzehnder modulator mzmoptoelectronic oscillator oeobased broadband light source bls hybrid cable television catvmicrowave mwmillimeterwave mmwbaseband signal transmission proposed experimentally demonstrated mzm employed mzmoeo operated minimum transmission point result format optical carrier suppression yaxis component light dualpolarization modulation scheme optical carrier modulated catv signal xpolarization optical sidebands modulated mw mmw data signal ypolarization separated polarized orthogonally automatically indepth observation good carriertonoise ratio composite secondorder composite triplebeat bit error rate performance obtained km singlemode fiber rfm optical wireless transport bidirectional fiberwireless fiberivllc convergence system notable option would attractive providing broadband heterogeneous service catv internet big data service ,2
BD_499,taking advantage large scale corpus web effectively efficiently mine topic text essential problem era big data focus problem learning text topic embedding unsupervised manner enjoys property efficiency scalability text topic embedding represents word document semantic topic space word document similar topic embedded close compared conventional topic model implicitly capture documentlevel word cooccurrence pattern text topic embedding alleviates data sparsity problem capture semantic relevance different word document model text topic embedding propose bidirectional hierarchical skipgram model bhsg based skipgram model bhsg includes two component semantic generation module learn semantic relevance text topic enhance module produce text topic embedding based text embedding learned former module evaluated method two kind topicrelated task text classification information retrieval experimental result four datasets one dataset provide demonstrate proposed method achieve better performance ,2
BD_500,aurora geophysical phenomenon observed directly naked eye high latitude region systematic observation aurora play important role magnetosphere solarterrestrial electromagnetic activity observed aurora data growing quickly aurora morphology research becomes data intensive present big aurora data management framework toward aurora classification analysis considering scalability performance framework integrates aurora data acquisition management aurora data preprocessing data query explore aurora classification experiment management nosql database employed manage aurora data classification experiment data inmemory index constructed support insitu analysis ,2
BD_501,area ambientassisted living aal focus developing technology improve quality life care provided elderly disabled people propose novel system based rgbd vision sensor interval type fuzzylogicbased system itflss employing big bangbig crunch algorithm realtime automatic detection summarization important event human behavior largescale data several realworld experiment conducted aalrelated behavior various user shown proposed bbbc itflss outperform type fuzzy logic system counterpart well conventional nonfuzzy method performance improves number subject increase ,2
BD_502,spreading prevalence big data many advance recently made field framework apache hadoop apache spark gained lot traction past decade become massively popular especially industry becoming increasingly evident effective big data analysis key solving artificial intelligence problem thus multialgorithm library implemented spark framework called mllib library support multiple machine learning algorithm still scope spark setup efficiently highly timeintensive computationally expensive procedure like deep learning propose novel framework combine distributive computational ability apache spark advanced machine learning architecture deep multilayer perceptron mlp popular concept cascade learning conduct empirical analysis framework two real world datasets result encouraging corroborate proposed framework turn proving improvement traditional big data analysis method either spark deep learning inidual element ,2
BD_503,online education combined internet technology traditional education grows rapidly recently big data characteristic massiveness ersification low value rapidity deeply influencing reconstructing online education educational technology matching big data analysis exploration development trend law online education help successfully get dilemma facing online education realize inidualized development strategy promoted educational technology educational thinking based big data big data technology field ? give one method give one example illustrate discus ,2
BD_504,aircraft health management hot research hotspot field civil aviation inborn gene big data however big data application field still initial stage development big data technology airline could improve aircraft maintainability reliability economy fusing big data technology process health management provides design big data analysis application platform civil aircraft health management platform designed based data available u foreseeable furfure thus must imperfect meet current demand ,2
BD_505,mobile healthcare become important trend medical healthcare domain rapid development wearable sensing technology various healthrelated information recorded forming valuable big health data physical activity considered great impact heart rate analysis heart rate data widely used medicalhealthcare research analysis exercise record heart rate data used research exercise intensity many institute heart rate pattern refers symbol health status heart based current rate physiological parameter effective heart rate pattern discovering helpful healthcare cardiovascular prevention aim build big data analytics framework sport behavior mining personalized health service analyzed user exercise data including heart rate gps data collected practical sport social platform discover user periodic sport pattern trend heart rate change exercise since dataset huge also growing quickly adopt apache spark development framework address velocity issue big data analytical result serve important core personalized healthcare application moreover also group inidual result discover clustering result applied advanced healthcare application ,2
BD_506,datacells sample construction firm operated failed failure prediction model developed artificial neural network ann support vector machine multiple discriminant analysis mda logistic regression lr accuracy model test data surprisingly showed ann slightly better accuracy lr mda anns number unit hidden layer weight decay hyperparameters consequently tuned grid search tuning process led tedious machine computation aborted many hour without completion state art big data analytics bda technology first time failure prediction consequently employed tuning completed second mean accuracy cross validation used selection model best parameter value used develop ann model outperformed previously developed model test data subsequent selected variable develop model led reduced tuning computational cost improved performance since reallife effect misclassification cost greater tedious computation cost concluded bda best compromise ,2
BD_507,sk telecom company south korea recently introduced concept iost business model company deployed iost constantly generates data via lora wireless platform increase data rate generated iost escalating exponentially attempting analyze store massive volume iost data existing tool technology south korean company realized shortcoming immediately current article address issue present big data analytics architecture iost system developed proposed architecture able analyze store iost data efficiently enabling better decision proposed architecture composed four layer namely small thing layer infrastructure layer platform layer application layer finally detailed analysis big data implementation iost used track humidity temperature via hadoop presented proof concept ,2
BD_508,reliability availability serviceability ra log high performance computing hpc resource closely investigated spatial temporal dimension provide invaluable information regarding system status performance resource utilization data often generated multiple logging system sensor cover many component system analysis data finding persistent temporal spatial insight face two difficulty volume ra log make manual inspection difficult unstructured nature unique property log data produced subsystem add another dimension difficulty identifying implicit correlation among recorded event address issue recently developed multiuser big data analytics framework hpc log data oak ridge national laboratory ornl introduces three inprogress data analytics project leverage framework ass system status mine event pattern correlation application system event describe motivation project detail workflow three year log data collected ornls titan supercomputer ,2
BD_509,nowadays great deal attention devoted big data analytics complex healthcare environment fetal growth curve classical case big healthcare data used prenatal medicine early detect potential fetal growth problem estimate perinatal outcome promptly treat possible complication however currently adopted curve related diagnostic technique criticized poor precision technique based idea customized growth curve proposed literature perspective problem building customized personalized fetal growth curve mean big data technique discussed proposed framework introduces idea summarizing massive amount input big data via multidimensional view top wellknown data mining method like clustering classification applied overall defines multidimensional mining approach targeted complex healthcare environment preliminary analysis effectiveness framework also proposed ,2
BD_510,abundance data nowadays offer infinite opportunity possibility systematically explored exploration data achieved application big data analytics bda consequently number bda model seen developed number sector energy one sector potentially benefit bda initative consumer energy related data come source smart meter billing system good candidate data application bda consumer data useful information consumption pattern trend obtained study showed awareness energy consumption able contribute % saving furthermore bda model energy sector particularly electricity address consumer side sector still lacking therefore research bda model household electricity consumption tracking monitoring developed based common bda model layer descriptive predictive analytics analyse big data amassed consumer model provides required information prediction enables consumer view track compare plan electricity consumption home evaluation result showed model deemed applicable able attain objective proposed bda model consumer better guided managing electricity consumption ,2
BD_511,big data becoming common term among researcher looking tool broaden research improve result probable relation different scientific area although term big data recent application methodology changing well establish paradigm research area well several industry application big data methodology used rapid development big data also raising specific issue related core concept aim address impact issue novel nutritionbased vegetable production distribution system project sojo university active member ,2
BD_512,modelbased analysis tool built assumption simplification difficult handle smart grid data characterized volume velocity variety veracity ie v data random matrix theory rmt motivates datadriven tool perceive complex grid highdimension meanwhile architecture detailed procedure proposed algorithm perspective architecture performs highdimensional analysis compare finding rmt prediction conduct anomaly detection mean spectral radius msr statistical indicator defined reflect correlation system data different dimension management mode perspective groupwork mode discussed smart grid operation mode break regional limitation energy flow data flow make advanced big data analysis possible specific largescale zoneiding system multiple connected utility site operating groupwork mode able regional msr measuredsimulated data largescale interconnected system way naturally decoupled statistical parameter perspective rather engineering model perspective furthermore comparative analysis distributed msrs even imperceptible different raw data produce contour line detect event locate source demonstrates architecture compatible block calculation regional small database beyond architecture datadriven solution sensitive system situation awareness practical real largescale interconnected system five case study visualization validate designed architecture various field power system best knowledge first attempt apply big data technology smart grid ,2
BD_513,vehicle become moving sensor platform collecting huge volume data various embedded sensor data great value automotive manufacturer vehicle owner indeed connected vehicle data used large broad automotive service ranging safety service wellbeing service eg fatigue detection however vehicle fleet send big volume data traditional computing storage approach able manage efficiently experience psa group leveraging big data automotive context describe depth big data architecture deployed psa group underlaying technologiesproducts used component ,2
BD_514,network traffic rich source information security monitoring however increasing volume data treat raise issue rendering holistic analysis network traffic difficult propose solution cope tremendous amount data analyse security monitoring perspective introduce architecture dedicated security monitoring local enterprise network application domain system mainly network intrusion detection prevention used well forensic analysis architecture integrates two system one dedicated scalable distributed data storage management dedicated data exploitation dns data netflow record http traffic honeypot data mined correlated distributed system leverage state art big data solution data correlation scheme proposed performance evaluated several wellknown big data framework including hadoop spark ,2
BD_515,internet grows cybersecurity problem also arise different type malicious activity explored attacker however existent defense mechanism able completely end malicious threat perpetuating continuous arm race development application mitigate threat present complicating factor growth amount data variety data come different source architecture built top big data framework aim mitigate cybersecurity problem spam phishing show used spam phishing collected global honeynet ,2
BD_516,timely intelligent decision making increasingly important modern society availability big data advanced artificial intelligence decision making objective evidencebased quantitative smart decision made timely manner research proposed big data based intelligent decision support system bid sustainable business development system used government agency corporate business eg farm mining advanced planning collaboration management also address performance optimization bilevel decisionmaking problem one leader multiple follower extended kuhntucker approach introduced one algorithm adapted system ,2
BD_517,market competition intensifies customer churn management increasingly becoming important mean competitive advantage company however dealing big data industry existing churn prediction model well addition decision maker faced imprecise operation management response difficulty clustering algorithm called semanticdriven subtractive clustering method sdscm proposed experimental result indicate sdscm stronger clustering semantic strength subtractive clustering method scm fuzzy cmeans fcm parallel sdscm algorithm implemented hadoop mapreduce framework case proposed parallel sdscm algorithm enjoys fast running speed compared method furthermore provide marketing strategy accordance clustering result simplified marketing activity simulated ensure profit maximization ,2
BD_518,standardization process fifth generation g wireless communication recently accelerated first commercial g service would provided early increasing enormous smartphones complex scenario large frequency band massive antenna element dense small cell generate big datasets bring g communication era big data investigates various application big data analytics especially machine learning algorithm wireless communication channel modeling propose big data machine learning enabled wireless channel model framework proposed channel model based artificial neural network anns including feedforward neural network fnn radial basis function neural network rbfnn input parameter transmitter tx receiver rx coordinate txrx distance carrier frequency output parameter channel statistical property including received power root mean square rms delay spread d rms angle spread datasets used train test anns collected real channel measurement geometry based stochastic model gbsm simulation result show good performance indicate machine learning algorithm powerful analytical tool future measurementbased wireless channel modeling ,2
BD_519,global investment bank financial institution facing growing data processing demand originate increasing regulatory requirement expanding variety disparity data source also ongoing pressure cost reduction without compromising system scalability flexibility context ability apply promising stateoftheart big data technology extract maximum value vast amount data generated generating lot interest financial service industry big data architecture system design based distributed computing paradigm like hadoop mapreduce offering horizontal scalability nosql flexibility time meeting stringent quality resilience requirement banking software standard proposed architecture able consolidate validate enrich process different big data analytics technique data gathered different source system encountered banking practice time supporting different data integration transmission process orchestration requirement traditionally encountered global financial institution ,2
BD_520,elasticity key component modern cloud environment monitoring essential part process monitoring demonstrates several challenge including gathering metric variety layer infrastructure platform application need fast processing data enable efficient elasticity proper management data order facilitate analysis current past data future prediction classify monitoring big data problem propose appropriate solution layered pluggable extendable architecture monitoring component specifically propose nosql database backend bigqueue write buffer achieve high throughput evaluation show monitoring capable achieving response time hundred millisecond insertion hundred row regardless underlying nosql database ,2
BD_521,since lowquality data may influence effectiveness reliability application data quality required guaranteed data quality assessment considered foundation promotion data quality essential access data quality data related activity electric power industry electric power data continuously accumulated many electric power application developed based data china power grid many special characteristic traditional big data assessment framework directly applied therefore big data framework electric power data quality assessment proposed based big data technique framework accumulate realtime data history data provide integrated computation environment electric power big data assessment support storage different type data ,2
BD_522,healthcare system evolving simple medical device ubiquitous healthcare system working anytime anywhere particular acquisition transmission vital sign wearable device biosensors soon realized daily life interestingly vital sign electrocardiogram ecg respiration motion data collected accumulated become kind big data eventually crucial clue monitoring health everyday life preventing disease proposes big data framework uhealthcare system provide healthcare service based upon analysis big data vital sign framework includes method provision realtime service well transmission analysis data employ standard platform secure interoperability among data different device proposed framework implemented tested term motion data accelerometer ,2
BD_523,social medium many candidate post chosen satisfying functional criterion target post user require selection algorithm rank candidate post nonfunctional criterion therefore proposes novel algorithm named bdfgra big datafuzzy grey relational analysis handle post parallel spark platform selecting topn post satisfy userspecified selection criterion ranking criterion goal nonfunctional attribute experiment show bdfgra get convincing performance ,2
BD_524,escalating growth multimedia content internet thing iot application lead huge volume unstructured data generated unstructured big data particular format structure form text audio image video furthermore current iot system successfully realize notion ubiquitous connectivity everything capable include ‘ multimedia thing address two issue proposing architecture multimedia internet thing miot big multimodal computation layer first introduce miot novel paradigm smart heterogeneous multimedia thing interact cooperate one another thing connected internet facilitate multimediabased service application globally available user miot architecture consists six layer computation layer specially designed big multimodal analytics layer four important functional unit data centralized unit multimodal data aggregation unit multimodal data divide & amp conquer computation unit fusion & amp decision making unit novel highly scalable technique called divide & amp conquer principal component analysis dcpca feature extraction ide conquer mechanism proposed used together divide & amp conquer linear discriminant analysis dclda multimodal big data analytics experiment conducted confirm good performance technique functional unit divide & amp conquer computational mechanism final section give application camera sensing iot platform realworld data analytics multicore architecture implementation ,2
BD_525,hadoop deal big data source java framework two core component namely hdfs hadoop distributed file system ability system continue normal operation hardware software fault inexpensive hardware stock huge extent data another one mapreduce processing technique programming model done lateral scattered manner hadoop perform well short data huge amount short data could greater namenode hdfs inturn execution time prolonged mapreduce encountered dealing great amount short data particularly designed handle huge amount data hadoop experienced performance cost analysis permit indetail description hdfs actual way deal problem proposed approach handle short data file short data file problem proposed approach small file merged programming model hadoop known mapreduce approach hadoop performance handling small file larger block size improved also propose traffic analyzer combination hadoop mapreduce paradigm joint hadoop mapreduce programming tool make possible provide batch analysis minimum response time memory computing capacity order process log high available efficient stable way ,2
BD_526,information system becoming sophisticated mobile cloud computing social networking service popular people amount data rapidly increasing every big data data analyzed company organization tried analyzed could processed current technology introduce big data model recommender system social network data model incorporates factor related social network applied information recommendation respect various social behavior increase reliability recommended information big data model flexibility expanded incorporate sophisticated additional factor needed experimental result information recommendation mapreduce process show feasible model used information recommendation ,2
BD_527,apache cassandra leading distributed database choice come big data management zero downtime linear scalability seamless multiple data center deployment increasingly wider adoption cassandra online transaction processing hundred webscale company growing need rigorous practical data modeling approach ensures sound efficient schema design proposes first querydriven big data modeling methodology apache cassandra ii defines important data modeling principle mapping rule mapping pattern guide logical data modeling iii present visual diagram cassandra logical physical data model iv demonstrates data modeling tool automates entire data modeling process ,2
BD_528,effectively clean largescale mixed inaccurate monitoring collective data reduce cost data cache ensure consistent deviation detection timing data cycle big data online cleaning algorithm based dynamic outlier detection proposed data cleaning method improved local outliner detection upon density sampling cluster uniformly dilution euclidean distance matrix retaining correction next cycle cleaning avoids sampling causing overall cleaning deviation reduces amount calculation data cleaning stable time enhancing speed greatly finally distributed solution online cleaning algorithm based hadoop platform ,2
BD_529,introduce big data processing framework provides selfhealing capability internet thing domain discus highlevel architecture framework prototype implementation identify faulty condition utilize complexevent processing technique applying rulebased patterndetection algorithm event generated realtime event descriptor metadata measurement cpu usage memory usage bandwidth usage taken internet thing device understand usability effectiveness proposed architecture test prototype implementation performance scalability increasing incoming message rate result promising processing overhead negligible ,2
BD_530,construction global energy internet power system trend scale expansion network complexity equipment precision data massivication substation automation power grid equipment level continuously improved well traditional power grid dispatcher training simulation system dts unable adapt increasingly precise secondary electric equipment simulation requirement big data analysis based method power grid dispatch control training simulation first us etl tool extract standardization process data secondary equipment signal emit equipment type association rule mining equipment signal data preprocessing correlation matching accordance association rule last classified equipment data ided load according condition area substation bay voltage grade drive equipment detailed simulation logic method based actual operation monitoring data us semantic analysis association rule technology etl elasticsearch tool implement grid primary secondary equipment signal extraction parsing mining load operation monitoring equipment detailed simulation logic driven authenticity accuracy adaptability precision simulation improved ,2
BD_531,ever amount data consumer supplier product exploding today consumer world referred big data addition data available consumer world multiple source including social network platform order deal amount data emerging technology big data analytics explored employed analyzing consumer behavior searching information need specifically proposes big data application framework analyzing consumer behavior topological data structure cooccurrence methodology markov chain theory first consumer related data translated topological data structure second topological relationship cooccurrence matrix formed deduce markov chain model consumer behavior analysis finally simulation result shown confirm effectiveness proposed framework ,2
BD_532,serviceoriented architecture soa layered architecture used organize software resource service deployed discovered combined produce service interaction service affected situation destination becomes unavailable herein protocol introduced solution coordinate interaction service method extended consider automatic assignment access control policy generation called access control policy ac_policies linked protocol context protocol manages large amount data analysis data set may help improving protocol performance dealing large data set referred recently big data term related large set data complicated analyzed traditional application one successful implementation big data hadoop framework proposes extension automate integration hadoop platform aim break inidual problem multiple subtasks simple programming model mapreduce analysis computed result submitted score table linked protocol approach harness capability modeldriven architecture mda automate creation integration architecture proof concept approach implemented tool ,2
BD_533,need smart information retrieval system contrast difficulty deal huge amount data big data analytics architecture used implement semantic similarity search tool natural language text biomedical domain implemented methodology based word embeddings wes model obtained wordvec algorithm system assessed document extracted whole pubmed library also presented friendly web frontend able ass methodology real context ,2
BD_534,big data become major competitive advantage many organization analytical capability made possible big data analytics platform key stepping stone advancing business every organization illustrates development big data analytics system mobile telecommunication system author developed solution analyzing data produced mobile network node contain data relevant predictive maintenance troubleshooting purpose solution built around problem working small file hadoop environment log collected mobile network node small binary file mb size binary log file need decoded readable format analyzed extract useful information author provided benchmark various scenario collecting decoding binary log file hadoop cluster result scenario highest performance used implementation solution developed solution built tested hadoop cluster realworld data obtained several telecom operator around world ,2
BD_535,due rapid advance information technology big data recognized v characteristic volume variety veracity velocity bring significant benefit well many challenge major benefit big data provide timely information proactive service human primary current stateoftheart big data aspect organization representation cleaning reduction integration processing security privacy analytics application novel framework provide highquality called big dataasaservice framework consists three plane namely sensing plane cloud plane application plane systemically address challenge aspect also clearly demonstrate working process proposed framework tensorbased multiple clustering bicycle renting returning data illustrated provide several suggestion rebalancing bicyclesharing system finally challenge proposed framework discussed ,2
BD_536,big data analytics rapidly growing field academic industrial researcher giving attention towards building next generation data management system system able analyze dataset large volume short response time according focused source big data system benchmarking big data system big data benchmark playing important role evaluate performance big data system discussed issue related benchmarking term data generation technique workload ,2
BD_537,big earth data platform constructed based parallel distributed database management system scidb demonstrate visual analytics interactive animation erse datasets highperforming capability achieved exploiting transparent multimodal parallelization largely enabled unifying indexing scheme stare provides unparalleled variety scaling platform support effortless interactive data exploration analysis also potential systemize machine learning undertaking erse voluminous earth science data ,2
BD_538,current research development effort integrating everything heterogeneous object device people internet advanced network technology protocol develop internet everything ioe emergence smart system smart city smart traffic management system proposed gather data relevant source via ioe recently cloud computing introduced ioe paradigm provide multitude service necessary compose smart system utilizes big data propose bigdata centric framework smart system encompasses four phase data collection processing management interpretation proposed framework facilitates modular architecture smart system security cognition interactive module ,2
BD_539,flood big data cyberspace require immediate action ai intelligent system community address manage knowledge besides method system need total knowledgemanagement approach willl require perspective ai need merton system machine intelligence human intelligence tandem become normal mode operation next generation ai intelligent system ,2
BD_540,research based statistic database world bank dataworldbankorgon big data related monitoring foreign trade relevant statistic data china statistic database big data analysis applied change dependence foreign trade trade structure yunnan province china according research result yunnan degree dependence foreign trade increased % % however rate increase slower expectation based yunnan growth rate gdp total foreign trade volume data structure dependence import export trade see yunnan dependence export trade though keep fluctuating growing slowly general view fluctuant dependence import trade also growing trend though growth obvious term foreign trade pattern yunnan foreign trade mainly consists general trade small border trade general trade shared higher proportion made contribution yunnan foreign trade proportion general trade yunnan total value import export growing general proportion small border trade decreasing ,2
BD_541,present novel biomimetic radar sensor autonomous navigation accomplish drawn inspiration sensory mechanism echolocating mammal common bigeared bat micronycteris microtis demonstrate correspondence hardware system model signal processing validate performance sensor developed complementary control system based subsumption architecture allows system autonomously navigate unknown environment architecture consist separate behavior different level complexity combined produce overall functionality system describe behavior separately examine performance realworld navigation experiment system placed two distinct office environment goal achieving smooth stable trajectory observe noticeable improvement employing highlevel behavior furthermore utilize data collected navigation experiment perform simultaneous localization mapping algorithm developed earlier result show substantial improvement odometry attribute fact system traverse stable repetitive path facilitates place recognition ,2
BD_542,copyright protection multimedia nowadays big challenge due advancement information technology issue protecting copyright audio signal addressed designing audio watermarking algorithm dwtsvd domain proposes blind secure robust audio watermarking algorithm focused hiding data svd transformation audio signal dwt domain bit watermark hidden audio signal mean quantization bit hidden maintaining good audible quality signal proposed technique robust numerous audio attack efficiency proposed algorithm proved simulation result comparison proposed audio watermarking algorithm existing audio watermarking algorithm indication goo performance proposed algorithm term imperceptibility robustness large payload bps ,2
BD_543,computation maximum likelihood ml estimator heteroscedastic regression model considered traditional newton algorithm problem require matrix multiplication inversion bottleneck modern big data context big dataappropriate minorizationmaximization mm algorithm considered computation ml estimator mm algorithm proved generate monotonically increasing sequence likelihood value convergent stationary point loglikelihood function distributed parallel implementation mm algorithm presented mm algorithm shown differing time complexity newton algorithm simulation study demonstrate mm algorithm improves upon computation time newton algorithm practical scenario number observation large ,2
BD_544,nand flash memory major storage medium mobile storage card enterprise solidstate drive ssds logblockbased flash translation layer ftl scheme widely used manage nand flash memory storage system industry logblockbased ftls physical block called log block used hold page update large amount data block frequent page update log block introduce big overhead log block become system bottleneck address problem present blog blocklevel logblock management scheme mlc nand flash memory storage system blog blocklevel management update page data block collected together put log block much possible therefore effectively reduce associativities log block reduce garbage collection overhead also propose novel partial merge operation strategy called reducedorder merge effectively postpone garbage collection log block maximally utilize valid page reduce unnecessary erase operation log block based blog design ftl called blogftl multilevel cell mlc nand flash conduct set experiment real hardware platform representative ftl scheme proposed blogftl implemented hardware evaluation board experimental result show scheme effectively reduce garbage collection operation reduce system response time compared previous logblockbased ftls mlc nand flash ,2
BD_545,crowdintelligence try gather process infer ascertain massive useful information utilizing intelligence crowd distributed computer crowdintelligence ecosystem involves three stakeholder namely platform worker eg iniduals sensor processor publisher stakeholder mutual trust interest conflict mean bad cooperation due lack trust transferring raw data eg picture video clip publisher worker requires remote platform center serve relay node implies network congestion first rewardpenalty model align incentive stakeholder predefined rule implemented blockchain smart contract many edge server mobile edge computing network together function trustless hybrid humanmachine crowdintelligence platform edge server near worker publisher network congestion effectively improved proved existence one strong nash equilibrium maximize interest involved edge server make ecosystem bigger theoretical analysis experiment validate proposed method respectively ,2
BD_546,bluetooth scatternets integrating polling frequency hopping spreadsprectrum medium access control protocol provide contentionfree environment bluetooth device access medium communicate multihop link currently available scatternet formation protocol tend interconnect bluetooth device initial network startup stage maintain bluetooth link thereafter instead big scatternet approach propose scatternetroute structure combine scatternet formation ondemand routing thus eliminating unnecessary link route maintenance best knowledge first effort address ondemand scatternet formation every detail introduce extended id eid connectionless broadcast scheme compared original bluetooth broadcast mechanism achieves much shortened route discovery delay also propose synchronize piconets scatternet route remove piconet switch overhead obtain even better channel utilization furthermore routebased scatternet scheduling scheme enable fair efficient packet transmission scatternet route network performance analysis simulation show scatternet route provide multihop wireless channel high network utilization extremely stable throughput especially useful transmission large batch packet real time data wireless environment ,2
BD_547,biomedical sensor implanted networked human body health monitor diagnosis treatment prosthetic device life time heat generated implant due communication circuitry power consumption big concern present network architecture long range communication implanted sensor network measured onbody propagation around body surface inbody propagation tissue frequency range mhz ghz found inbody path loss onbody exploit path loss difference propose introduce body surface coordinator resource implanted sensor network instead routing data among implant coordinator body surface forward data one implant another long distance safely efficiently ,2
BD_548,wireless network specified layer l data link protocol recently iot big data processing promoted wireless sensor network connect send data data center application internet implementation ip stack wireless node gateway ip wireless l network proposed approach developed allow application ip network access l wireless network node however since wireless sensor network require network protocol ip essential collecting data therefore propose novel bridging vpn connecting wireless network application wireless end node required acknowledge ip address network protocol way ip network merely serf transport data link frame wireless network believe another style iot recommend small iot business institution vpn test bed start implement ip stack system ,2
BD_549,world population growing conjunction preference city make city management challenging issue traditional city common feature able handle human need result smart city beneficial outcome attract lot attention recently fact smart citycommunity field collecting processing data many different area making proper decision feeding part system future style city word smart community complex big data problem combine different field research make unit environment brief survey deal aspect smart community also explained different category smart community addition future challenge try introduce aspect smart transportation detail ,2
BD_550,enforcement smart city operation requires manageable infrastructure operating system o installed computer control every computer carry manages system resource similarly istack smart city o architecture designed inesa deems support citybigdataoriented cloudbased application governs interacts relevant city information infrastructure terminal like smart lighting infrastructure serf platform connection communication cooperation smart city application feasible optimal scalable computationstorage resource scheme operated demonstrates architecture function feature istack particular proposed business solution architecture bsa smart city o sustainable smart city solution could created efficiently conveniently ,2
BD_551,network topology routing two important factor determining communication cost big data application large scale given cluster cloud grid system network topology fixed static dynamic routing protocol preinstalled direct network traffic user change system deployed hence hard application developer identify optimal network topology routing algorithm application distinct communication pattern design ccg virtual system ccgvs first us containerbased virtualization allow user create farm lightweight virtual machine single host us softwaredefined networking sdn technique control network traffic among virtual machine user change network topology control network traffic programmingly thereby enabling application developer evaluate application system different network topology routing algorithm preliminary experimental result synthetic big data program npb benchmark shown ccgvs represent application performance variation caused network topology routing algorithm ,2
BD_552,development active distribution network scale power system becomes larger larger number electrical equipment distribution network increase sharply becomes precise electrical equipment operation monitoring controlling signal data character massive ersity complication show trend big data massive random operation monitoring controlling signal data cause various application active distribution network unable extract useful information quickly efficiently difficult form decision support complex event processing cep intelligent data processing technology rise era big data implement rapid analysis processing continuous data based rule engine article us cep engine operation monitoring controlling signal processing core us etl extracttransformload framework integrate clean load distributed disordered standard unified signal data active distribution network data warehouse problem data format unified independent storage data extraction solved adapter mode daemon process way based cep engine determines core processing architecture operation monitoring controlling signal big data architecture signal cleaning rule library algorithm library pluggable mode make easy maintain expand rule library determined nested query combined operation pattern matching algorithm library packaged memory partitioning multithread processing wordfrequency statistic keyword recognition elimination algorithm us buffer queue cache processing result format output needed cep engine based big data etl solution implement fast accurate effective standardization processing operation monitoring controlling signal provides accurate data preparation fast simulation fault analysis state estimation important application active distribution network ,2
BD_553,shortterm load forecasting smart grid key electricity dispatch scheduling reliability analysis maintenance planning generator convolutional neural network cnn based bagging model forecasting hourly load employ cnn train forecasting model big load data set segment real industry load data set many subset finetune forecasting model subset learn weak forecasting model assemble weak forecasting model conduct bagging forecasting model learning assembling procedure implemented spark specifically load sample data set reorganized image respect similarity relation pixel image feature load sample experimental result indicate effectiveness proposed method ,2
BD_554,efficient scheduling bottleneck area semiconductor manufactory get important due high complexity manufacturing area currently possible optimize whole even big part factory mostly center specific optimization approach investigated typically scheduling problem deal two dimension – job equipment area semiconductor manufactory also third dimension considered – limited secondary resource constraint programming model limited secondary resource problem presented thereby scheduling model also deal setup matrix first also secondary resource modeling cp model shown detail result compared discrete event simulation dispatching rule test data first test orientated real production data ,2
BD_555,order solve series problem management enterprise lower efficiency quality complexed business process communication pattern huge static management data dynamic control data etc intelligenceawareness management platform based cyber physical system cps constructing smart industry proposed optimize management process resource whole resource enterprise mainly include software hardware employee resource aware integrate kind resource intelligence method together analyzing providing better big challenge especially physical stateawareness hardware network facility business processawareness management software business data knowledgeawareness among employee enterprise based critical resource smart itsm platform designed programed cps metamodel build stateawareness smart environment also integrate itil information technology infrastructure library metamodel standard management process aware change process knowledge library application result show cpsawareness itsm platform promotes efficiency qualify provides earlyalarm management process whole life cycle resource enterprise ,2
BD_556,present detail cuda implementation pagerank pipeline benchmark proposed benchmark aimed compare measure capability big data system reference implementation serial moment cuda implementation parallel result indicate gpu accelerated system considerable potential big data workload ,2
BD_557,hadoop mapreduce based distributed processing framework frequently used industry today area big data analysis particularly text analysis graphic processing unit gpus hand massively parallel platform attractive performance price power ratio used extensively recent year acceleration data parallel computation cuda compute unified device architecture cbased programming model proposed nvidia leveraging parallel computing capability gpu general computation attempt integrate cuda acceleration hadoop distributed processing framework create heterogeneous high performance image processing system hadoop primarily used text analysis involves facilitating efficient image processing hadoop experimental evaluation adaboost based face detection algorithm indicate cudaenabling hadoop cluster even lowend gpus result % improvement data processing throughput indicating integration two technology help build scalable high throughput power costefficient computing platform ,2
BD_558,carpooling taxicab service hold promise providing additional transportation supply especially extreme weather rush hour regular taxicab service insufficient although many recommendation system regular taxicab service proposed recently little research done assist passenger find successful taxicab ride carpooling first systematic design unified recommendation system regular carpooling service called callcab based datadriven approach response passenger realtime request callcab aim recommend either vacant taxicab regular detour occupied taxicab heading similar direction carpooling minimum detour yet without assuming knowledge destination passenger already taxicab analyze unknown destination occupied taxicab callcab generates refines taxicab trip distribution based gps data set context information collected existing taxicab infrastructure improve callcabs efficiency process big data set augment efficient mapreduce model measure phase tailored callcab finally design reciprocal price mechanism facilitate taxicab carpooling implementation real world evaluate callcab realworld data set taxicab result show compared ground truth callcab reduces % total mileage deliver passenger % passenger waiting time price mechanism reduces % passenger fare increase % driver profit simultaneously ,2
BD_559,due drastic growth mobile customer recent day mobile business brought paradigm shift expanded application area mass production various mobile business field consequently erse attempt made order analyze mobile business successful performance propose performance metric measure performance mobile business suggest enhanced performance measurement model analyzing mobile business proposed performance metric performance metric categorized two type customer retention product engagement according characteristic mobile business automatically collected raw data mobile application crawling data mobile market order measure performance metric mobile business statistically analyzed two performance metric big data processing system based cloud environment suggest enhanced performance measurement model mobile business environment result analyzed proposed model case proposed model support efficient decision making mobile business field mobile marketing mobile commerce ,2
BD_560,maryland state archive msa digital curation innovation center dcic university maryland ischool collaborating digital project utilizes digital strategy technology create indepth understanding africanamerican experience maryland era slavery utilizing crowdsourcing transcription data cleaning transformation technique data visualization strategy joint project team creating avenue understanding complex web relationship undergirded institution slavery ischool student full participant project team learning digital curation technical skill gaining insight multiple us cultural big data penetrate past illuminate ,2
BD_561,apache spark efficient distributed computing framework big data processing support inmemory computation rdds resilient distributed dataset provides provision reusability fault tolerance realtime stream processing however task spark framework performed cpu low degree parallelism power inefficiency cpu may restrict performance scalability cluster order improve performance power dissipation data center heterogeneous accelerator fpga gpu mic many integrated core exhibit efficient performance generalpurpose processor big data processing propose framework integrate fpga accelerator spark cluster fpga accelerate spark task developed python way computing load performed fpga instead cpu illustrate performance fpga based spark framework case dfft algorithm acceleration result showed fpga based spark implementation acquires x speedup cpu implementation ,2
BD_562,manytask computing mtc computing paradigm address challenging application effectively supported existing htc hpc system mtc application often require large number task relatively short per execution time dataintensive task mtc application may require relatively small amount data processing especially compared existing big data application typically based larger data block size however mtc application consist much larger number task communicates file therefore mtc another type dataintensive workload large number data processing task efficiently processed order address mtc type data processing workflow developed moha manytask computing hadoop aim effectively combine mtc technology hadoop platform moha framework leverage hadoop yarn popular powerful resource management system achieve massive scalability reliability effective implementation behavior revised moha framework support real mtc application hadoop cluster exploiting highthroughput distributed message queue system apache kafka experimental result show approach effective handling real mtc application help robust resource management system provided hadoop addition discus potential load imbalance problem caused kafka practical consideration moha framework achieve high performance dispatching good load balancing ,2
BD_563,current major big data analytical stack often consist general multistaged computation framework eg hadoop sql query system eg hive top key factor query performance efficiency data shuffling two execution stage eg mapreduce current data shuffling various useful information shuffled data query data simply wasted make strong case crosslayer optimization hivehadoop stack designed implemented novel data shuffling mechanism hadoop called structured data shuffling sshuffle carefully leverage rich information data query optimize overall query processing experimental result industrystandard tpch benchmark show sshuffle performance sql query processing hadoop improved x ,2
BD_564,current major big data analytical stack often consist generalpurpose multistaged cluster computation framework eg hadoop sql query execution system eg hive top stack key factor query execution performance efficiency data shuffling two execution stage eg mapreduce however current stack often execute data shuffling dataoblivious way mean structured data processing various useful information shuffled data query data simply wasted specifically problem make two optimization opportunity lost unnecessary record filtered advance ii columnoriented compression algorithm applied solve problem designed implemented novel data shuffling mechanism hadoop called structured data shuffling sshuffle avoids low efficiency traditional data shuffling carefully leveraging rich information data query provided hive experimental result industrystandard tpch benchmark show sshuffle performance sql query processing hadoop improved x ,2
BD_565,recent year many big data system invented improve different issue related process large amount data nevertheless system solve particular problem especially domain sensitive safety privacy accuracy still limited due unfriendly interface design complicated configuration poor security management mechanism thus propose webbased analytic workflow system allow endusers easily desired analytic function solve specific problem different domain moreover system enable safe sharing guarantee security well process automation also conduct case verify validation practice system ,2
BD_566,coming age big data recent focus company government even world economic forum wef rapid exponential growth global data outpaces moore law improvement computing storage efficiency creating growing energy wall coping global data observe problem significantly exacerbated needed security mechanism propose systematically designed energyaware security mechanism ,2
BD_567,restoring customer top priority alabama power company year although method technology brought bear changed improved dramatically technology helped company improve response system disturbance automation technology deployed distribution control room distribution substation discrete site distribution feeder provides system intelligence regarding state condition electric distribution system automation technology also facilitates presentation supervisory control data acquisition scada telemetry distribution operator meanwhile advance desktop computing workstation permit geographical display distribution circuit widearea view improves visibility distribution system operator bigpicture widearea view displayed map board presented control room desktop workstation today application integration providing next round technology improvement distribution control room advanced application integrated platform providing technique improve efficiency reliability distribution system together advanced application improve restoration article describes past future restoration technology alabama power ,2
BD_568,urban traffic data analysis platform important infrastructure modern city spatialtemporal data produced traffic transportation system explosively growth operator traffic field trying adopt emerging big data solution born internet area however hard find high costperformance solution build platform erse combination hardware software configuration currently operator selecting solution depend simple evaluation result based internet benchmark terasort two issue including appropriate evaluating solution spatialtemporal application internet benchmark characteristic spatialtemporal application potential optimization measurement never fully explored address issue novel workload characterization tool called extensible metric importance analysis emia big data application key idea performance model based ensemble learning take program metric input output performance metric execution time rank metric corresponding importance based emia apply principal component analysis pca program behavior five representative spatialtemporal application nine popular internet big data benchmark experimental result show spatialtemporary application unique characteristic unreasonable evaluate solution spatialtemporary application internet benchmark moreover optimize spatialtemporary application via applying measurement key factor identified emia achieving obviously performance improvement ,2
BD_569,numerous classification algorithm developed variety data type however nearly impossible one classifier perform best kind datasets therefore ensemble learning model aim take advantage different classifier received lot attention recently scalable classifier ensemble framework assisted set judgers proposed integrate output multiple classifier multimedia big data classification specifically based confusion matrix different classifier set judgers organized hierarchically structured decision model testing instance first input different classifier classification result passed proposed hierarchical structured decision model derive final result ensemble system run spark designed big data processing experimental result multimedia data containing different action demonstrate proposed classifier ensemble framework outperforms several stateoftheart model fusion approach ,2
BD_570,rapid pace technological advancement smart device sensor actuator technology internet thing iot domain received significant attention advance brought u closer ubiquitous computing vision however order fully realize vision device application rapidly adapt change environment nearby device existing application store collected data data store allow user query stored data notice react change many application utilize cloud big data technology scalability nevertheless responsiveness iot application largely limited due polling based query therefore propose centrally managed distributed infrastructure based state art big data technology focus primarily problem process multiple continuous query real time notify user timely contribution specifying generic scalable architecture process multitude real time query provide prototype implementation demonstrate applicability approach scalability architecture evaluated conducting several experiment prototype implementation ,2
BD_571,high frequency physiological data great potential provide insight many condition patient develop critical care utilized big data analytics based clinical decision support system artemis artemis deployed nicu sickkids hospital toronto august employ potentiality big data original data together newly generated analytics stored data persistence component artemis realtime analytics performed online analytics component knowledge extraction component system take care data mining enabled support clinical research various condition artemis date utilized three different implementation however artemis still hold many challenge lower resource setting research demonstrates challenge opportunity artemis cloud cloud computing based health analyticsasaservice approach provision remote realtime patient monitoring low resource setting case research demonstrate implication opportunity challenge utilizing artemis low resource setting small remote pediatric critical care unit viz nicupicu india utilizing potentiality big data pediatric intensive care unit great potential improve healthcare low resource setting ,2
BD_572,remote sensing data grown explosively past decade however remote sensing application system evolve slowly due challenge big imagery data storage processing cost accessing current remote sensing image still high learning curve remote sensing image image processing tool still steep response emergency fast enough development big data cloud computing technology recent year brought opportunity challenge remote sensing application remote sensing business model based web cloud computing environment clear trend give brief overview challenge faced building big imagery analytics system remote sensing proposes cloud computing solution big imagery data analytics experimental result cloud computing space traditional film uav image also presented full stack solution based arcgis platform remote sensing imagery storage management processing application ideal platform next generation remote sensing application business model ,2
BD_573,transport system already encounter vast amount data per day ranging gps information vehicle sensor check realtime location newer technology social medium sensor network passenger counting system name opportunity well challenge accommodate even larger data volume essentially leading big data problem context realtime distributed transport system argue contemporary model system inadequate le adequate meeting challenge cloudbased model integrated distributed transport system enable greater flexibility portability interoperability different controller sensor model called movie acronym model operation view intelligence event proposed movie model describes event controlled system incorporates cloud various messaging protocol order provide safe secure way communication user sensor multimodal transportation network describe model detail simulation passenger counting system deliver minute information passenger enable make informed choice travel option emergence social medium transport patron may connect transport system city receive provide update status traffic time ,2
BD_574,traditional flowbased network monitoring analyzing tool challenged largescale network traffic big size data proposes cloud platform largescale network analysis exploit hdfs datax deal storage heterogeneous big data mapreduce model applied concurrently compute analyzing correlating large amount network flow data flowbased technique employed collecting network data make possible application level analysis network usage experimental result show performance platform greatly improved compared traditional rdbms application ,2
BD_575,emerging big data application increasingly require resource beyond available single server may expressed complex workflow many component dependency relationshipseach component potentially requiring specific perhaps specialized resource execution efficiently supporting type big data application challenging resource management problem existing cloud environment response propose twostage protocol solving resource management problem exploit spatial locality first stage dynamically forming racklevel coalition server execute workflow component coalition exist duration execution assigned component subsequently disbanded allowing resource take part future coalition second stage creates package coalition designed support component complete workflow minimize communication housekeeping overhead needed form package coalition technique combinatorial auction adapted marketbased resource allocation technique considerably lower overhead resource aggregation traditional hierarchically organized model analyze two strategy coalition formation first historybased us information past auction preform coalition anticipation predicted demand second one justintimethat build coalition support specific workflow component requested ,2
BD_576,scalability io efficiency two biggest challenge building cloud storage system especially dataintensive application run cloud cloud computing constructing suitable architecture every kind cloud key succeed little done create valid standard cloud storage architecture fourlayer cloud storage architecture proposed meet requirement dataintensive application efficient scalable node organization model introduced cloud storage system ,2
BD_577,computing machine learning model cloud remains central problem big data analytics introduce cloud analytic system exploiting parallel array dbms based classical sharednothing architecture approach combine indbms data summarization mathematical processing external program summarize data set parallel assuming large number processing node accelerate gpus contrast big data analytic system java hdfs mapreduce spark system programmed c++ c top traditional unix system system model efficiently computed suite innovative parallel matrix operator compute comprehensive statistical summary large input data set matrix one pas leaving remaining mathematically complex computation matrix fit ram r order competitive hadoop ecosystem ie hdfs spark rdds also introduce parallel load operator large matrix automated yet flexible cluster configuration cloud experiment compare system spark showing order magnitude time improvement gpu many core widens gap summary system competitive solution ,2
BD_578,dramatic increase data rate wireless network caused radio spectrum usage essential critical issue spectrum sharing widely recognized affordable nearterm method address issue first characterizes feature spectrum sharing future wireless network including heterogeneity sharing band ersity sharing pattern crowd intelligence sharing device hyperdensification sharing network harness benefit unique feature promote vision spectrum without bound network without border introduces concept internet spectrum device iosds develops cloudbased architecture iosd future wireless network prime aim building bridging network among various spectrum monitoring device massive spectrum utilization device enabling highly efficient spectrum sharing management paradigm future wireless network furthermore present systematic tutorial key enabling technique iosd including big spectrum data analytics hierarchal spectrum resource optimization quality experienceoriented spectrum evaluation addition unresolved research issue also presented ,2
BD_579,inspired emerging big data challenge provide description olap* cloud based framework supporting effective efficient olap big data environment olap* combine data warehouse partitioning technique cloud computing paradigm provides suitable implementation top wellknown rolap server mondrian consists applying meaningful transformation multidimensional database schema complement analytical contribution mean case showing effectiveness framework practical setting ,2
BD_580,recent year due development pervasiveness information communication technology ict data generated tremendously increasing rate various type data source massive amount data widely referred big data contains large amount hidden rich information uncovering valuable information big data service envisioned bring huge potential commerce business research fact series sophisticated process involved big data service however exists structural gap holding back development big data service fourlayer cloudbased network architecture proposed support big data service proposed network architecture provides systematic efficient approach big data access storage retrieval specifically process supporting big data service categorized data transfer data collection data processing data retrieval furthermore cloudbased architecture presented followed closer look network architecture big data collection device level ,2
BD_581,network continues evolve completely analyzing traffic requires immeasurable resource situation processing enormous streaming data significant k item topk interesting streaming algorithm deployed due relatively limited memory also limited processing time per item spacesaving one popular algorithm computation frequent topk element data stream algorithm implemented cloud analyzing big networking data empirical formula counter number derived efficiently maintaining topk item meanwhile easily understandable proof manner presented prove merging ability spacesaving algorithm experiment conducted affirm effectiveness algorithm ,2
BD_582,nowadays growing global economy demand customized product bringing manufacturing industry seller market toward buyer market context smart manufacturing enabled industry changing whole production cycle company specialized different kind product one hand advent cloud computing social medium make customer experience inclusive whereas hand cyberphysical system technology help industry change real time cycle production according customer need context retentionmarketing strategy aimed acquisition customer also profitability existing one allow industry apply specific production strategy maximize revenue possible mean analysis various kind information coming customer product purchase focus customer loyalty program particular propose cloudbased software architecture store analysis big data related purchase product rank order provide customer list recommended product experiment focus prototype human machine workflow preselection customer deployed private hybrid cloud scenario ,2
BD_583,information communication technology ict shown impact medical research last year big data analysis adopted many medical research application including rehabilitation surgery facial paralysis rehabilitation training progress traditional training process require huge effort patient doctor increasing number patient limited resource offered hospital assistance ict urgently needed cloudbased training analysis system facial paralysis patient physician provides rehabilitation training automatic progress result evaluation training client developed provide rehabilitation training well data collection addition training result analyzed cloud platform machine learning methodology cloud platform provides automatic evaluation rehabilitation progress based feedback training data set input physician ,2
BD_584,local histogram key feature intensity probability pixel neighbour pixel must visited construction local histogram big image data timeconsuming propose local histogram construction algorithm based cloudcomputing realtime communication network computation cost easily shared construct several local histogram time proposed algorithm fastest solution field also applicable various data processing related probability distribution experimental result show proposed algorithm best performance compared related algorithm ,2
BD_585,cloudbased physical body data sensing architecture playing child rationale designing sensing architecture twofold analyzing physical body data identify relation body activity health playing child another reason foster awareness connection traditional culture modern culture providing various kind play seven country korea japan china mongolia kazakhstan uzbekistan iran silk road based database proposed sensing architecture based cloud computing sensing data securely stored aggregated cloud computing system design sensing architecture enables identify similarity difference body activity respect user addition big data analysis capability proposed architecture able detect potential health problem aggregated sensor data stored stable cloud storage volume cloud storage architecture designed support stateful stateless application compatible traditional infrastructure ,2
BD_586,smart revolution already begun toward future characterized internet everything noninvasive wireless smart sensor allow dynamically share information eg alert signal big data cloud thing scenario providing secure userfriendly service harmonious interaction man environment management complex scenario characterized high mobility dynamic heterogeneous data access requires different access level local remote time would require ability gather data several typology event functional structural eg regarding mobility transportation energy consumption correlate data caused natural industrial phenomenon eg air pollution guarantee safety city propose advanced solution meet challenge achieve advanced multipurpose management based cloudenabled virtual environment clever projected realized university messina easily federated cloud context sensor web enablement standard specification show case regulate user access certain area specific room provide useful data business intelligence oriented multipurpose management particular solution aim gather data regarding people access electricity consumption provide web information service private governance ,2
BD_587,workflow scheduling algorithm cloud environment extensively studied workflow management system simulator common criterion covered algorithm addressed simulator makespan monetary cost reliability energy consumption beyond criterion security also criterion investigated recently scientific business workflow typically handle sensitive big data influence makespan cost significantly scheduling algorithm applies security service data however simulator workflow execution address overhead produced applying security service sensitive data propose extension workflow simulator support security service considered seven step measuring security overhead workflow execution extension validated executing realworld workflow applying three type security service namely authentication integrity verification encryption extension proved useful simulating workflow execution applying security service sensitive data analyzing effect security makespan cost security criterion ,2
BD_588,development latest technology change market demand wireless multisensor system widely used multisensors integrated way produce overwhelming amount data termed big data multisensor system creates several challenge include getting actual information big data high accuracy increasing processing efficiency reducing power consumption providing reliable route toward destination minimum bandwidth shortcoming overcome exploiting novel technique clustering data fusion coding scheme moreover data fusion clustering technique proven architecture used efficient data processing resultant data le uncertainty providing energyaware routing protocol limited resource multisensor system challenging reduce energy consumption survive network longer period keeping challenge view present novel technique hybrid algorithm clustering cluster member selection wireless multisensor system selection cluster head member node proposed data fusion technique used partitioning processing data proposed scheme efficiently reduces blind broadcast message also decrease signal overhead result cluster formation afterward routing technique provided based layered architecture proposed layered architecture efficiently minimizes routing path toward base station comprehensive analysis performed proposed scheme stateoftheart centralized clustering distributed clustering technique result shown proposed scheme outperforms competitive algorithm term energy consumption packet loss cluster formation ,2
BD_589,era big data data analysis data mining important decision support tool critical step accuracy comprehensiveness patent retrieval directly affect result patent analysis mining almost mainstream patent retrieval system based retrieval word miss lot similar patent order improve recall rate chinese patent retrieval implement semantic retrieval utilizing wordbuilding part speech combination characteristic four character medicine effect phrase put forward method calculate similarity four character medicine effect phrase give kcentroid clustering algorithm experimental result show effectiveness method ,2
BD_590,efficient execution distributed database operator joining aggregating critical performance big data analytics increase compute speedup modern cpu reducing network communication time operator large system becoming increasingly important also challenging current technique significant performance improvement achieved stateoftheart method reducing network traffic designed data management domain data flow scheduling data communication domain however proposed technique field view black box performance gain cooptimization perspective yet explored based current research coflow scheduling propose novel coflowbased cooptimization framework ccf cooptimize applicationlevel data movement networklevel data communication distributed operator consequently contribute performance large distributed environment detailed design implementation ccf conduct experimental evaluation ccf largescale simulation large data join result demonstrate ccf perform faster current approach network communication largescale distributed scenario ,2
BD_591,internetofthings iot environment continuously inspires timeplacethings connectivity smart object around universe day day rapid growth enormous iot object digital storage technology lead large heterogeneous data depository iot bigdata stored dissimilar database framework consequence heterogeneous data source due large heterogeneous data source incompatibility like name scale structure level abstraction framework iot bigdata create threat data management knowledge discovery need propose cognitive oriented iot bigdata framework coibframework implementation architecture iot bigdata layering architecture data organization framework effective data management knowledge discovery copup large scale industrial automation application discussion analysis show proposed framework architecture creates feasible solution implementing iot bigdata based smart industrial application ,2
BD_592,last year deep learning gained great popularity health medical science analyzing personal health data privacy patient data one biggest concern traditional method possibility leaking data transferring raw data storing data centralized houseware therefore proposed collaborative privacypreserving learning system based deep neural network share local raw data system implemented xmpp server several mobile device experiment reconstructed rate proposed evaluate performance distributed system compared centralized training rate % different scenario furthermore network traffic collaborative learning also measured ,2
BD_593,recent year development system processing analyzing large amount data socalled big data become important subdiscipline software engineering however date exit comprehensive summary specific idiosyncrasy challenge development big data system imposes software engineer aim provide first step towards filling gap based collective experience industry academic project well consulting initial literature review contribution concise summary challenge engineering big data system collected consolidated mean systematic identification process aim make practitioner aware common challenge offer researcher solid baseline identifying novel software engineering research direction ,2
BD_594,landscape distributed computing rapidly evolving computer exhibiting increasing processing capability manycore architecture almost every field science data driven requires analysis massive datasets algorithm analytics machine learning used discover property given dataset make prediction based however still lack simple unified programming framework data intensive application many existing effort designed specialized mean speed inidual algorithm thesis research distributed programming model mapcollective defined easily applied many machine learning algorithm specifically algorithm fit iterative computation model easily parallelized unique collective communication layer efficient synchronization contrast traditional parallelization strategy focus handling high volume input data lesser known challenge shared model data parallel worker equally high volume multidimensions required communicated continually entire execution extends understanding data aspect computation inmemory caching input data eg iterative mapreduce model finegrained synchronization model data eg mapcollective model library called harp developed hadoop plugin demonstrate sophisticated machine learning algorithm simply abstracted mapcollective model conveniently developed top mapreduce framework kmeans multidimensional scaling md tested thread iu big red ii supercomputer result show linear speedup increasing number parallel unit ,2
BD_595,standard multidimensional scaling md one concerned finding lowdimensional representation set n object pairwise dissimilarity among original object realized distance embedded space minimum error propose md algorithm addition minimizing usual stress function accommodate additional optimization criterion well side constraint associated underlying visualization application attempt minimize secondary objective funcion cluster membership discrepancy given cluster structure original data resulting cluster structure lowdimensional embedding preliminary computational experiment show algorithm able find md embeddings preserve original cluster structure incurring relatively small increase stress compared standard md finally discus property algorithm make interesting choice big data visualization ,2
BD_596,big data epoch one major challenge large volume mixed structured unstructured data come heterogeneous source different form structured unstructured data often considered apart however may speak entity world query involve structured data unstructured counterpart inefficient execute separately present novel index structure tailored towards combination structured unstructured data combined index joint index structured database unstructured document based entity cooccurrences also semantic index describes semantic relationship entity multiple resource store index rdf graph query sparqllike experiment show associated index provide apposite information also execute query efficiently ,2
BD_597,describes combined ground penetrating radar gpr data historical archive performed siloyard valencia spain identify map various pavement construction period valencian silo constructed house underground grain storage valencia city architectural complex composed three building big square siloyard silo placed construction siloyard pavement extended two century th century following different construction system historical archive confirmed seven pavement construction period however archive data provided scant information pavement layer construction period gpr survey carried pinpointing seven pavement construction period gssi sir equipment mhz frequency antenna used collecting $ { } \times { } \\text { } $ grid $ { } $ profile across square $ { } \ { \text { } ^ { } } $ reaching depth addition gps survey performed specifically surface mapping siloyard detail combined gpr data reflection profile spectrum amplitude slice map historical archive allowed identifying delineating different pavement construction period siloyard map term material thickness result demonstrate gpr noninvasive nondestructive technique mapping soil near surface horizon additionally combined gpr data historical documentation make technique even efficient comprehension shallow ground layer especially cultural heritage study ,2
BD_598,matter fact cause big challenge protocol design consider coexistence sensor actuator wireless sensoractuator network wsans especially automated architecture proposes routing protocol vertex matrix routing vmr design extensive simulation explore performance vmr automated architecture aa semiautomated architecture saa preliminary result presented demonstrate difficulty data collection distributed multiactuators advantage aa ,2
BD_599,currently active learning widely used several application build initial classification system trivial amount data set problem modern active learning system assumption training set perfect dont take consideration data issue derived realworld scenario research challenge existing model could cause several concern realtime application including redundancy incoherence big size data among others research compared six active learning method based nine standard datasets derived uci database term convergence rate experimental result observed method dont achieve high performance learning due convergence rate information loss comparative analysis based nine test reveals decisiontree based active learning method produce seven time optimal convergence rate imbalanced data notable sample attribute difference ,2
BD_600,last year increasing wsns application security surveillance monitoring structural health building habitant monitoring health care disaster management observed biggest constraint wsns limited energy participating sensor node time near impossible change replenish battery node sensor node maybe potentially deployed harsh environmental condition unmanageable sustaining long life major challenge wsns hierarchical routing protocol provide amicable solution term energy efficient routing data type protocol sensor node may gathered possibly non overlapping cluster cluster cluster head used data agglomeration route data desired sink provide taxonomy hierarchical routing protocol look envision hybrid hierarchical routing protocol may embeds characteristic intelligent routing protocol ,2
BD_601,summary form given conventional magnetic recording challenge physical limit motivated consider dimensional data storage technique motivation provided fact data recording may arranged bigger sector error correcting code ecc low density parity check code ldpcc get arbitrarily close capacity large enough block length consider ldpcc ecc conjunction equalization method iterative otherwise recording medium isi equalization method recording discussed iterative detection ,2
BD_602,digital communication proliferated big way previous year advantage digital communication improved efficiency better transmission accuracy better noise immunity requirement lesser bandwidth secrecy standardisation transmissionreception equipment digital communication shipboard application used transmission voice data picture ship operational environment accuracy secrecy immunity noiseinterference essential advent latest equipment capable advanced signal processing technique result prolific digital communication shipboard application aim bringing various aspect digital communication vi & ampvis dense electromagnetic environment exists naval platform compatibility applicability source coding digital modulation technique error control coding data security mitigating electromagnetic interference ship borne environment discussed various problem cochanneladjacent channel interference effect randomburst noise digital communication system also brought achieving immunity digital communication interference various spread spectrum technique also discussed ,2
BD_603,bootstrap resampling method precorrected pet data proposed applied measured data order simulate repeated experiment elliptical phantom two hot sphere cm cm diameter warm background scanned ge advance pet system sphere background ratio randoms scatter attenuation dead time correction applied sinogram data method validated student fstatistical test validation test indicate applying bootstrap method precorrected pet data preserved statistical characteristic image quality image reconstruction measured data resampled data tested channelized hotelling observer cho two reconstruction method filtered backprojection fbp penalized maximum likelihood spacealternating generalized em pmlsage compared initial detectabilities fbp higher one pmlsage small sphere detection detectabilities pmlsage higher one fbp big sphere detection detectabilities resampled data appears higher experiment data number tested resampled data experiment data ,2
BD_604,ct dynamic volume imaging system moving organ image quality comparable conventional ct dynamic conebeam ct realize several breakthrough largearea dimensional detector highspeed data transfer system reconstruction algorithm ultrahighspeed reconstruction computer highspeed continuous rotating gantry among development detector one biggest task wide dynamic range high data acquisition speed view rate ct detector developing ctscanner together keycomponents take one volume sec matrix spl time spl time describes concept design well preliminary development detector ,2
BD_605,telecommunication operating company asked provide service short mediumterm therefore system infrastructure must evolve order support service several technological option already available choose best among big challenge network planner proposes mixedinteger linear programming model devoted help planning socalled access network link client core telecommunication system model driven maxrevenue criterion focus network evolution assumption imprecise estimate concerning service penetration rate order perform technoeconomical risk analysis fuzzy set concept adopted application us actual data reported ,2
BD_606,due collimator aperture spatial resolution spect data varies sourcetodetector distance since radius detector rotation bigger scanning larger patient spatial resolution degraded case emitted gamma ray travel central axis collimator hole also offaxis due collimator aperture however offaxis ray one angle would centralaxis ray another angle therefore raw projection data one angle thought ensemble centralaxis ray collected small arc equal collimator aperture thus fine angular sampling compensate collimator blurring sampling pitch le half collimator aperture angle compensation performed subtracting weighted sum projection data raw projection data collimator geometry detector rotation radius determined weighting function cylindrical phantom four differentsized rod torso phantom tl cardiac spect simulation used evaluation aperture angle collimator degree projection sampling pitch degree phantom study proposed method showed improvement contrast reduction partial volume effect thereby indicating proposed method compensate adequately image blurring caused collimator aperture ,2
BD_607,image diagnosis area biggest medical field telemedicine obligate direct contact patient responsible radiologist building persistent lack specialist place distant urban center make telemedicine important tool improvement healthcare service framework called cyclopsdistmeddb cyclops distributed medical database integration distributed dicom medical record database wide area system central module responsible receiving client request patient data image waveform performing querying retrieval image patient record etc specific dicom database containing data requested delivering client data communication protocol adopted dicom retrieval object directly dicom data server corba common object request broker architecture delivery dicom data client application ,2
BD_608,big science requires large research team huge amount data internet project provides pipe next generation bucket feed network ? national lab require storage infrastructure readily expandable tightly integrated network highly secure costeffective discus storage architecture would meet stringent requirement ,2
BD_609,alarm correlation play important role improving reliability modern telecommunication network previous research alarm correlation consider effect noise data database focus method discovering alarm correlation rule database containing noise data firstly define two parameter winfreq winadd measure noise data robust search algorithm solve problem different size winfreq winadd experiment alarm database containing noise data show robust search algorithm discover rule bigger size winadd also compare experiment two different interestingness measure confidence correlation ,2
BD_610,discus problem finding profile location scattering electromagnetic wave fixed frequency consider optimization method particular dual space method dsm known efficient advantage reducing number unknown disadvantage data measured many angle since mainly motivated medical application disadvantage problem scattering data measured many angle goal try see much information need frequency order get reasonable reconstruction dsm extend dsm general formulation temode consider also tmmode moreover consider reconstruction refractive index well boundary scatterer result suggest small wave number lead satisfactory reconstruction finding index tmmode boundary temode tmmode big wave number lead poor reconstruction regardless mode try reconstruct case temode wave number neither small big may able obtain satisfactory result ,2
BD_611,summary form given follows consideration given effect grouping data packet transmission error detectretransmit system chinese teletex system since error condition transmission line remain whole process transmission possible achieve high throughput fixed packet size error condition line bigger packet size bigger packet error probability therefore packet retransmitted method dynamically allocating optimum packet size obtain high throughput presented different approach used r lynn kirlin wesley w chu ,2
BD_612,believed areal density approaching one terabit per square inch ultimately achieved conventional magnetic recording technology density require sharp transition written welldefined extremely narrow track finely grained thermally stable recording medium requirement drive key characteristic geometry read write head recording medium reexamines several aspect proposed terabit per square inch recording system discus critical technology required support extreme areal density include necessity low magnetic spacing ability fabricate narrowtrack writeread head need exquisite trackfollowing capability one biggest challenge extreme areal density develop recording system also deliver high data rate ,2
BD_613,designed system provides support physician regardless specialization objective system ensure accurate diagnosis local unclassified patient computerized support system take input clinical data collected stored electronic patient record generates output recommendation therapeutic intervention laboratory testing based fourlevel diagnosis process process start diagnosis made local physician subject double verification local remote expert system finally approved appropriate remote specialist constructed telemedicine based system called so specialist sos achieve objective sos provide quality care rural area also big city hospital government organization still suffering lack specialist specific domain attractive characteristic sos capability promote adding diagnosis appropriate specialist case local patient database furthermore help physician update knowledge outside specialization ,2
BD_614,recently concept medlan system dedicated application scenario wireless local area network wlan hospital & ampe department presented essential element acceptance system reassuring stakeholder system data transmitted system secure order stakeholder reassured technical managerial issue addressed technical issue addressed include selection suitable encryption algorithm bit key encrypting wireless link identification suitable cryptoboard fitted system laptop computer many respect managerial issue pose bigger challenge technical issue medlan system introduced member emed system research group liaise hospital manager establish hospital data securitypolicy expanded accommodate emed system cost implication expansion determined cost insuring security data handled medlan system determined ,2
BD_615,creation device digital signal processing fibreoptical sensor mechanical value featured device allows spend measurement produce adjustment sensor remotely big degree accuracy device connects pc threewire line link usage standard transfer protocol data rsc scheme implemented usage chip corporation atmel at analog device ad texas instrument tlvi intersil hincp ,2
BD_616,complex extensible metric data enquiry function needed predict system performance create effective cost management policy register electronic commerce environment may significant undertaking article proposes advanced complexity metric data enquiry function advantage proposed method standard method used pricing count typical output applied complex query resulting big data set aim proposed method also calculate effort required create disseminate required data output complex distributed system ,2
BD_617,technological advance avenue communication commerce also market fraud combat fraud vulnerable business subject database customer transaction several data mining technique search pattern indicative fraud difficulty reallife fraud take many different form constantly evolving thus one big challenge fraud detection coming algorithm learn recognize great variety fraud scenario adapt identify predict scenario another challenge creating system quickly enough detect fraudulent activity occur ,2
BD_618,popular content frequently replicated multiple server cache internet offload origin server improve enduser experience however choosing best server nontrivial bad choice may provide poor end experience contrast retrieving file single server propose parallelaccess scheme end user access multiple server time fetching different portion file different server reassembling locally amount data retrieved particular server depends resource available server path server faster server deliver bigger portion file slower server deliver smaller portion available resource server path change download file dynamic parallel access automatically shift load congested location le loaded part server link internet end result user experience significant speedup consistent response time moreover need complicated server selection algorithm load dynamically shared among server dynamic parallelaccess scheme presented require modification server content easily included browser peertopeer application content distribution network speed delivery popular content ,2
BD_619,describes newly developed botany database named seed plant china spch application spch first biggest botany database china includes spherical coordinate data attribute data total plant specie family genus contains information seed plant taxon general designation biotaxonomy unit grouped county elevation habitat province including taiwan china designer database author first provides technical description database structure type geographic attribute data data layer comparison spch common gi database function capability serving botanical user example application spch area botany given lastly future development improvement spch proposed ,2
BD_620,farmland le recognized global farmland resource problem little known wide scale relationship farmland altitude analyzes dynamic distribution chinese farmland mids different altitude farmland dynamic coverage obtained visual interpreting mids tm image mge environment data data changed m*m grid format overlay dem data scale arcinfo grid module last year people think farmland china reduced drastically increasing population pressure agricultural activity announces district farmland reduced yet district farmland enhanced paddy field area meter reduced meter area increased great speed meter area becoming bigger although range small meter meter area almost unchanged dry land area meter reduced paddy field meter area increased meter meter range increased area great except change obvious ,2
BD_621,author investigated applicability interferometric sar insar monitoring forest fire damage attempted coherence information obtained interferometric sar insar detect monitor damaged area forest fire test site forest around tamano city okayama prefecture relatively big forest fire occurred august total area ha burnt used several interferometric data pair jers sar acquired forest fire multilook intensity image coherence image created test site intensity coherence change due fire damaged forest area extracted compared nondamaged forest area result indicated intensity decreased slightly fire however change big enough interpret extract damaged forest area clearly hand coherence increased significantly damaged area fire much easier interpret extract damaged area compared intensity experimental result support insar effective detecting monitoring land cover change forest fire well deforestation insar already verified effectively ,2
BD_622,propose adaptive filter enhance ground penetrating radar gpr image well known gpr image usually dominated specular ground reflection specular reflection make object scattered signal difficult observe first must removed refined detection classification processing employed remove specular reflection biggest challenge due ground roughness reflection satisfactorily subtracted simple method movingaverage filter contrast stretch enhance object reflect signal standard background removal method eliminate specular reflection contrast stretch gpr image may streaky artifact background removal overcome sideeffect apply adaptive filter remove streaky artifact field data show image higher quality obtained method ,2
BD_623,many effort successfully made recent year increase storage capacity optical disc cddvd hddvd blue laser diode time many consumer product became smaller consequently small optical magnetooptical disc brought market search material optical data storage found tesafilm conventional adhesive tape suitable conjunction geometry concept offer big advantage development geometrically small writeonce memory capacity gbyte tesafilm used multilayer recording material forming cheap cylindrically shaped optical data storage medium ,2
BD_624,terrorist attack exposed troubling shortfall u intelligence agency many fundamental problem technologyrelated inability national security agency nsa process promptly immense flood communication intercept every day woefully antiquated computer system federal bureau investigation fbi inadequacy fbi computer linked another basic weakness little cooperation data sharing among intelligence agency fbi central intelligence agency cia nsa one biggest initiative proposed federal budget almost $ billion nsa extend improve powerful computerbased system analyze transcript intercept look certain word phrase automatically route hit prespecified intelligence agency fbi midst $ million upgrade information technology system scheduled finished end project called trilogy encompasses bureau computer software also network trilogy aim shift bureau hodgepodge proprietary mainframebased system webbased one provide secure connection fbi facility worldwide ,2
BD_625,power industry changing rapidly utility deregulated market forced focus increased customer competitive market order become successful utility utilize resource one resource huge amount information different computer system information refined combined show pattern support conclusion could used provide better customer gain market share increase profit key store information data warehouse flexible enough provide powerful datamining capability powerful enough handle big information pressure caused constant inflow measured data power network data warehousing power industry need special consideration used reliable historian process data high requirement performance availability redundancy time must flexibility openness required let perform eg ad hoc query data mining discus consideration possible realization ,2
BD_626,adaptive antenna array isi cancellation nonlinear hard limiter receiver well known key technology high data rate lowcost receiver however combination technology big challenge since nonlinear receiver provide phase frequency sample amplitude information required adaptation antenna array accessible therefore adaptive antenna array often applied combination linear receiver low cost receiver combine adaptive antenna array hard limiter receiver training adaptive antenna array performed basis complex channel impulse response cir estimated phase sample performance approach shown mean simulation simple hard decision device maximum likelihood equalization three decoding structure compared optimum combining hard decision optimum combining reduced state viterbi equalizer single antenna receiver full state viterbi equalizer ,2
BD_627,spatial reuse protocol srp medium access control maclayer protocol operates double counterrotating ring network topology srp designed enhance sonet network handle data traffic efficiently allterminal reliability srp ring implementing intelligent protection switch ip enhanced intelligent protection switch eips calculate reliability scenario allterminal connectivity maintained summing result arising inidual mutually exclusive event allterminal reliability ip eips obtained assuming constant timedependent component failure rate mean time failure mttf mean time failure improvement factor mtif measure calculated result show mttfmtif vary function network size component reliability coverage factor advantage eips ip obvious network size big concentrator failure rate small analysis could helpful network designer wish determine whether additional costcomplexity added eips scheme justified ,2
BD_628,power deregulation power company releasing transmission grid form isosrtos maintaining state estimator area recent trend isosrtos combine enlarge become bigger megarto grid better market efficiency determination state whole system becomes challenging due size instead totally estimator whole grid author propose distributed textured algorithm determine whole state algorithm existing state estimator local companiesisosrtos fully utilized estimator longer required need extra communication instrumentation estimated data exchange addition algorithm following advantage distributed textured algorithm nonrecursive asynchronous avoids central controlling node therefore fast practical based exchanging data neighboring companiesisosrtos textured overlapped area become part process developed textured decomposition method bad data detection identification ability better existing distributed state estimation algorithm especially bad data occur around boundary inidual estimator discrepancy boundary bus different estimator decrease result whole grid become consistent moreover updating local estimation estimated data exchange matrix modification technique utilize sparse technique developed accelerate computation speed detailed numerical test given verify efficiency validity approach ,2
BD_629,growing concern throughout higher education gap university central service traditionally provide academic currently need widening member administrative staff academic community staff student finding performance routine task becoming increasingly difficult due nature institution information system system evolved ad hoc basis usually comprised multiple unconnected data repository user often prevented carrying inappropriate access control mechanism lack appropriate client software broadly two approach addressing problem one big bang existing system replaced simultaneously single centralised system approach taken necessary fully understand dynamic institution information system order specify encompassing system major alternative attractive approach integrate existing system usercentric portal objective inside project piloting valueadded service based distributed information base order development delivery joined system institution ,2
BD_630,simple practical method synthesizing load dynamic characterization proposed data measured guangdong grid dynamic load model obtained model bpa static load model respectively used simulating generator phase swing busground fault simulation shuibei substation simulation result show shortcircuit current simulated dynamic load model closer real current measured grid simulated static load model calculating transient stability limit limit power simulated dynamic load model slightly bigger obtained static load model ,2
BD_631,complex nature corona phenomenon combined number factor influencing effect make experimental study indispensable evaluating corona performance power transmission line different method ranging test laboratory cage measurement operational transmission line may used obtaining necessary data give introduction design small corona cage well presenting test result obtained cage test involved changing surface condition conductor coating silicon order determine corona performance effect wind concluded wind corona cage play big part corona loss clean conductor recommended test carried stronger wind source ,2
BD_632,medical information management system sigim aim integrating many already existing technology applied health care allowing big improvement quality service provision health caring area project involves several area term knowledge expertise ided among four group author article responsible creating electronic patient record epr achieve result adopted technology threetier architecture separate presentation rationale database xml extensible markup language standardises transmission medical data patient among system first stage construction erp focused study particularity oncology area ,2
BD_633,improving performance extending utility information processing requires access ever larger volume data thus impact progress storage technology overall growth information processing industry immense advance continually reduce cost storage becomes feasible develop place application computer system permitting larger system data base sophisticated control application program unfortunately term mass storage precise technical meaning frequently used describe online peripheral storage size bigger currently belief justify user system upgraded level however technical advance time allow capacity increased fixed cost amount storage barely considered adequate much le mass discussing hardware term commonly associated mechanical storage device solidstate memory continually provides bit per chip rate storage capacity absorbed grows even faster thus seems electronic memory never eliminate auxiliary storage device storage cost decrease application expand market grows product volume increase resulting cost reduction turn reinforce cycle addition becomes feasible increase investment technology result improvement costperformance thus important understand storage technology trend one anticipate future ,2
BD_634,huge superconducting magnet used toroidal field tf coil next generation tokamak like intor therefore development large superconducting tf coil urgently needed around world auspex international energy agency iea big project going called large coil lct project carried ieaimplementing agreement signed euratom usa switzerland japan usdoe act operating agent produce three coil facility testing six coil toroidal array constructed ornl euratom switzerland japan produce one coil testing u coil test coil designed × bore dshaped winding generate peak field pair solenoid mounted bore selected coil generate pulsed field simulation effect poloidal field tf coil besides parameter test coil significant difference among six coil design superconductors nbti nbinfinfsn structural material cooling mode pool boiling helium forced flow cooling supercritical helium gas test facility provide test stand vacuum vessel cryogenics power supply data acquisition system first testing three pool boiling coil scheduled start july full testing six coil late half ,2
BD_635,modeling becomes necessary analysis special electromagnetic system also testing consistency two dimensional model variational formulation magnetostatic scalar vector potential reviewed original energy functional non linear anisotropic vector potential proof uniqueness solution proposed biggest problem remain data input result reduction two problem analysed solution given illustrated example ,2
BD_636,automatic procedure presented implementing finite element magnetic field analysis technique design electric machine transformer related device mean boundary element method mesh obtained studying magnetic field given region finite element method way input data reduced accurate final data acquired region considered ensuring big decrease program runtime fe iterative procedure used advantage procedure illustrated application transformer comparison magnetic field value obtained proposed procedure classical finite element method reveals better agreement measured value case former % reduction program runtime ,2
BD_637,year telecommunication industry working bring art transmission switching point could provide top quality everybody big reliable basic network well basic goal largely achieved never complete customer sight keep rising communication increasingly important national economy industry must continue grow order stay healthy vigorous mean constantly improving basic instrument communication providing great variety option staying abreast consumer changing taste purchasing habit data communication electronic switching touchtone calling communication satellite etc helping achieve end continued success depends upon industry creative ability degree freedom accorded governmental agency regulate activity ,2
BD_638,maximumlikelihood estimation theory provides general framework developing nearoptimum respect cramerrao bound synchronization scheme digital communication system technique jointly estimating symbol timing carrier phase digital receiver linear digital modulation nonsynchronized sampling established dataaided nondataaided system blockbased feedforward architecture technique practical fully digitally implemented synchronization concept based loworder polynomial approximation likelihood function farrowbased interpolator shown low oversampling like two sample per symbol used timing recovery without compromising system performance result efficient overall receiver implementation also demonstrated quality interpolator design big effect performance synchronization scheme frequencydomain optimized polynomial interpolator design provide significantly better performance wellknown lagrange interpolators ,2
BD_639,dual camera stereo photogrammetry used quantify deformation central region anterior leaflet mitral valve operating flow loop physiological pathological condition stretch strain measured analyzed principal stretch demonstrated rapid rise early leaflet closure followed plateau suggesting collagen fiber locked place big difference major principal stretch minor principal stretch similar invitro tissue mechanic study transmitral pressureareal strain relationship loading unloading clearly demonstrated hysteresis relationship demonstrated dramatic stiffening attributed collagen fiber locking data papillary muscle position compared leaflet slack papillary position showed highest areal strain rate valve exhibited strongly anisotropic behavior papillary muscle position small effect strain measured region ,2
BD_640,article optimization method parallelized execution irregular fine grain computation presented method implemented pseudovector processing pvp sliding window register swr mechanism provided hitachi sr supercomputer general idea pvp swr relies optimizing access big continuous part memory parallel execution three kind operation placed loop loading storing data arithmetic operation disadvantage abovementioned mechanism gain obtained long loop regular expression inside method focused attention irregular computation devoid predictable dependency ided given code part manually optimized relation loading storing operation taking consideration memory latency delay accessing needed data implementation obtained speedup simple reordering sequence access operation register memory ,2
BD_641,reconfigurable computer generated holography sometimes known electroholography technique capable computer held data generate interactive high quality image containing depth cue used human visual system practical application electroholography require computer generated hologram cgh pattern sup sup pixel calculated displayed interactive rate pixel count necessary order generate image big enough upwards mm width posse large enough field view fov permit simultaneous multiuser viewing advance several key area may make high performance electroholographic system practical near future describe cgh design algorithm computer architecture cgh display engine including active tilingspl trade system ,2
BD_642,october greymagic israeli web application company warned security flaw could make internet explorer vulnerable malicious hacking warning interest even fascinating software giant response microsoft publicly chided firm ulging bug existence microsoft could fix part greymagic told medium past effort notify microsoft disclosure yielded meaningful result recent incident microsoft tussled issue disclosure last finnish firm oy online solution spotted internet explorer bug talked microsoft problem oy online agreed give software giant time fix big eventually went anyway saying microsoft endangering user data failing produce timely patch incident spotlight issue long simmered software world software bug made ? software maker get chance fix problem general informed ? much time ? standard needed govern arena ? ,2
BD_643,deep sea power cable linking geothermal field big island hawaii population center honolulu island oahu designed km long deployed depth requirement demand significant extension current power cable technology potential premature failure le year due combined action erosion corrosion assessed abrasive erosive process become potential problem much ocean bottom proposed cable route covered abrasive volcanic rock geologically recent origin tidal current deepest channel route exert significant force cable laboratory data abrasion armor wire polymeric serving material pillow basalt combined test data corrosion steel deep ocean seawater arrive series worstcase estimate potential life reduction due erosioncorrosion shown failure mechanism distinct possibility unless proper precaution taken ,2
BD_644,course titled process design improvement computer based tool developed offered author fall parttime graduate student manufacturing system engineering technology management program university st thomas minnesota & ltwwwstthomasedutechnologyfallmmse fhtm & gt objective course introduce student current software method used organize data model manufacturing industrial system virtual representation business operation choosing problem workplace course created make complex process tool computer modeling accessible nonspecialists better understanding operation unusual people know small part overall system give way see big picture case illustrates application tool ,2
BD_645,medical imaging shell rendering considered one efficient effective method volume visualization requires compact data structure voxels us voxel splatting technique surface volume rendering order avoid hole rendition size voxels usually made bigger size pixel voxel splatting case identified conceptual problem shell rendering affect correctness quality rendition discus problem propose solution improves image quality without affecting speed method approach called eshell rendering extendedshell rendering requires extension shell data structure variant original algorithm illustrate discus result example created surface volume rendering ,2
BD_646,aim design pattern classifier fuzzy relational calculus frc initially proposed pedrycz course first consider particular interpretation multidimensional fuzzy implication mfi represent knowledge training data set subsequently introduce notion fuzzy pattern vector represent population training pattern pattern space denote antecedent part said particular interpretation mfi introduce approach computation derivative fuzzy maxfunction minfunction concept generalized function construction classifier based frc fuzzy linguistic statement fuzzy membership function represent linguistic statement represent value feature eg feature fsub small fsub big population pattern note construction classifier essentially depends estimate fuzzy relation spl rfr input fuzzy set output fuzzy set classifier classifier constructed nonfuzzy feature pattern classified time classification nonfuzzy feature testpatterns concept fuzzy masking fuzzify nonfuzzy feature value testpatterns performance proposed scheme tested synthetic data finally proposed scheme vowel classification problem indian language ,2
BD_647,present adaptive stateprediction facsimile coding technique based thirdorder markovian state prediction coding chinese character & lttex & gtast & lttex & gtpattern detecting particular statepair right left inclined stroke predictor state changed adaptively get accurate prediction bigger data compression ratio ,2
BD_648,early effort regarding research area interest nature exploratory theoretical model built meaningful empirical research performed careful process identifying appropriate research question problem must undertaken current state research regarding relatively area continuous audit ca though concept ca around almost decade recent advance made technology widely available affordable firm yet make significant step toward implementation thus need exploratory survey key audit personnel charge providing assurance service major client bring light issue regarding technology people process auditor audit client wrestling discus result survey u assurance partner big accounting firm objective survey get partner perception thought viability continuous auditing current state ca audit environment impact ca implementation might various roadblock ca implementation addition various demographic data collected openended question survey instrument could systematically categorized analyzed minimize interpretation bias qsr nudistspl copy nonumerical unstructured dataindexing searching theorizing version software used code response capture emergent theme result survey revealing current state ca hurdle overcome implementation ,2
BD_649,improvement quality old house critical problem earthquake risk management past model analysis shown incentive renew house becomes smaller age owner becomes bigger history house however clear actual owner make decision renewal house based recognition degradation risk even owner know house dangerous may implement measure also necessary expand analysis incorporate decision repairing improves safety house cost lower renewal tried specify critical factor affect owner decision repairing renewal especially focus two temporal property age owner history house first model analysis renewal expanded apply general situation second survey carried examine appropriateness model yamaguchi city japan based collected data parameter binary logit model estimated proved owner age affect decision effect history house clear ,2
BD_650,bluetooth scatternets integrating polling frequency hopping spreadsprectrum medium access control protocol provide contentionfree environment bluetooth device access medium communicate multihop link currently available scatternet formation protocol tend interconnect bluetooth device initial network startup stage maintain bluetooth link thereafter instead big scatternet approach propose scatternetroute structure combine scatternet formation ondemand routing thus eliminating unnecessary link route maintenance best knowledge first effort address ondemand scatternet formation every detail introduce extended id eid connectionless broadcast scheme compared original bluetooth broadcast mechanism achieves much shortened route discovery delay also propose synchronize piconets scatternet route remove piconet switch overhead obtain even better channel utilization furthermore routebased scatternet scheduling scheme enable fair efficient packet transmission scatternet route network performance analysis simulation show scatternet route provide multihop wireless channel high network utilization extremely stable throughput especially useful transmission large batch packet real time data wireless environment ,2
BD_651,summary form given optical proximity correction essential modern semiconductor production question followed presentation much imperfection exposure tool affect opc ultimately whether different opc needed different highend exposure tool focus modern arf exposure tool investigate particular effect lens aberration illuminators effective annularity assessment lens aberration effect lens data taken pmi well litel used illuminator modeled standard rectangular profile sophisticated realistic illuminator aerial image simulation solely focusing line space pattern simulated data good agreement compared exposure test data bulk simulation focused cog mask though halftone mask taken account result find lens aberration modern exposure tool force tool specific opc lens fulfill certain quality criterion nevertheless taken special care spherical aberration astigmatism aberration affect opc strongly biggest role opc play illuminator effective annularity illuminator uniformity effective sigma assessed experimentally decide tool specific opc ,2
BD_652,cellular industry successful providing voice service consumer business next big opportunity wireless network differentiation based data multimedia service wireless provider face everincreasing pressure offer innovative service capability make efficient spectrum order meet need existing wireless network evolved technology air interface core network specifically wireless mobile data communication technology evolved circuit switched secondgeneration g network g third generation g network beyond describes revolution wireless communication wireless mobile data industry evolution wireless mobile data communication technology wireless mobile data market failing barrier wireless data proliferation ,2
BD_653,rise world wide web market growth mobile device advanced data capability make mobile internet inevitable next big wave technology due form factor limitation mobile device never used web browsing tool like desktop counterpart people access personal information communicate people messaging facility find local information navigate wellorganized information directory propose simple information access method called pixel navigator utilizes image hotspot data interaction compare popular wireless data service performance issue pixel navigator discussed illustrate tradeoff imageonly system ,2
BD_654,making good decision area petroleum production becoming big problem timely gather sufficient correct information may stored database data file world wide web gaia methodology agent architecture employed contribute framework solve problem framework consists three level namely role mode agent type agent instance model five role analyzed four agent type designed six agent instance developed constructing system petroleum information service experimental result show agent system cooperatively organize retrieve relevant petroleum information successful implementation framework show agentbased technology significantly facilitate construction complex system distributed heterogeneous data resource environment ,2
BD_655,perhaps biggest technical problem facing telephone company world growing mismatch network capability customer demand nowhere mismatch glaringly apparent company struggle keep pace steady growth internet traffic pure data exceeds voice traffic nearly everywhere legacy phone system designed decade ago optimized entirely different purposethe handling digitized voice signal author discus introduction sonet together boosting speed virtual concatenation concludes considering cut sonet cost ,2
BD_656,one biggest issue facing computer technology today data security problem gotten worse user working sensitive information often number threat growing hacker developing type attack many technology expert advocate development trusted computing tc system integrate data security core operation rather implementing via addon application discus cryptographic trusted computing trusted computing initiative ,2
BD_657,digital watermarking emerging technique protect data security intellectual property right identification verification watermarking pattern achieved detecting watermark received signal however one biggest challenge watermarking detection strength watermark signal change distorted attacker watermarking channel meanwhile embedding strength may adapted original signal unknown receiver end original signal often highly nongaussian although done optimum detection watermark uncertainty watermark signal strength real statistical behavior multimedia content taken account simultaneously much needed enhance performance watermarking system since multiplicative watermark robust well suited copyright protection present investigation robust optimum detection multiplicative watermark subband transformed domain discrete cosine transform dct discrete wavelet transform dwt pyramid transform class generalized correlators constructed based generalized gaussian distribution thresholding method achieve given false alarm rate performance analysis provided squareroot detector designed demonstrated near optimal performance large set natural image employed universally optimal detector decoder image video locally powerful detection method extended dft domain multiplicative watermarking magnitude coefficient modeled weibull distribution another class detector built based statistical modeling robust optimum detection multiplicative watermark applied copyright notification enforcement broadcast monitoring applied robust optimum watermarking detection combined audio video watermarking ,2
BD_658,electronic manufacturer worldwide currently facing big challenge reduce conversion cost order competitive market rising labor cost surface mount technology smt machine capital cost cost scrap poor quality smt manufacturer need focus efficiently utilizing fixed asset controlling cost quality scrap utilizing outofthebox technique reduce conversion cost discus six sigma methodology tool used achieve business result reducing scrap cost much % increase utilization fixed asset smt machine much % also give detail enterprise resource planning erpmaterial resource planning mrp integration factory data helped engineer think outofthebox helped deploy six sigma technique control scrap cost real time motorolas manufacturing pulsespl trade equipment monitor software used sigma tool achieve business result reduce conversion cost short time period different smt manufacturing site worldwide discus detail statistical process control spc chart methodology used realtime process control several example realworld data included ,2
BD_659,testbed characterization dynamic behavior cylindrical robot motion deformable soil described mobile robot consists cylindrical rigid shell roll rough terrain thanks internal device testbench designed optimized experimentally test interaction external shell soil different mechanical characteristic labview based software lead acquire necessary data experiment developed pcbased board general purpose ad io port used rotative linear encoders internal device dc motor goal build big sensor estimate force system arising interaction rigid cylindrical shell rough terrain experimental result show testbed give good measure travelling resistance minivehicle meet rough terrain ,2
BD_660,summary form given modern image compression standard jpeg defined operate integer data thus pose problem data need compressing typical way handle floating point data initial quantization approach allows standard technique used quantized data may acceptable researcher due irreversible data loss another compression approach strictly lossless method lzw based technique disadvantage approach include low compression ratio capability lossy compression low flexibility compressed data stream extension jpeg standard proposed allow efficient floating point data coding extension advantage maintaining desirable property jpeg including flexible embedded bit stream lossy lossless compression image scalability bit plane coding needed overall floating point algorithm applied acceptable wavelet color transforms derived derivation floating point bit plane coding algorithm considers narrow problem jpeg proposed approach bit plane coding represents floating point value big integer code integer directly jpeg separate eligibility pas every several bit plane introduced lower number coefficient coded coding pas resulting improved efficiency ,2
BD_661,capacity planning critical network management identifies much capacity needed match future traffic demand directly affect customer satisfaction revenue network usage analysis tool called dynamic netvalue analyzer dna help alleviate big problem network engineer marketing executive face making optimal resource investment decision marketing executive project customer growth network engineer project traffic volume based entire customer population dna help prediction process presenting actual network usage data business perspective form useful network engineer marketing executive projection decision upgrade resource made show information dna used quantify revenue earned link quantify returnoninvestment performing link upgrade quantify loss due customer dissatisfaction link upgraded also illustrate formulation based business information used improve capacity planning decision ,2
BD_662,author discus question whether zigbee wireless standard promoted alliance firm big threat bluetooth ? zigbee developed ghz band look rather like bluetooth simpler lower data rate spends time snoozing characteristic mean node zigbee network able run six month two year two aa battery claim backer however question zigbees viability target building automation application make technical sense field notoriously slow adopting technology proposed application zigbee seems tread bluetooths toe technical price advantage marginal unsubstantiated finished zigbee chip low price necessitate high volume ,2
BD_663,basis compression redundancy removal digital image compression discrete wavelet transform dwt applied remove interpixel redundancy although dwt powerful removing linear redundancy still various correlation left dwt coefficient correlation modeled withinsubband clusteringintra crosssubband similarityinter success recent wavelet image coder mainly attributed innovative strategy data organization representation exploit inter intra correlation one way try quantify performance loss correlation removed experiment performed two best zerotree coder set partitioning hierarchical tree spiht set partitioned embedded block coder speck recapitulate data organization adopted spiht speck general tree formation framework block coefficient based pseudorandomization applied remove inter intra correlation experimental result indicate performance loss due removal intra correlation much bigger performance loss due removal inter correlation therefore excellent psnr performance wellknown spiht algorithm much credited data structure exploit intra correlation although inter correlation widely mentioned previous literature ,2
BD_664,earthorbit international space station i grows need power generated solar panel period planet earth occult sunlight energy stored biggest set battery ever flown space reliability power important space station failure requires costly launch replacement component even greater importance result astronaut station power failure cause astronaut perish would serious event first batterycontaining integrated equipment module launched november installed port international space station two module launched united state launched european space agency attached columbus apm laboratory power system unexpected batteryrelated event occurred integrated equipment module first yearandahalf orbit problem solution described paper presented sup th intersociety energy conversion engineering conference since international space station carry battery cell spacecraft inflight performance data battery assembly useful engineer design power supply spacecraft therefore summarize battery development process adopted design unexpected inflight battery degradation correction ,2
BD_665,result growing interest telemedicine last decade seen development deployment several video conferencing telemedicine application recent year deployment application isdn line dedicated circuit since bandwidth security privacy biggest concern telemedicine session initiation protocol sip signaling standard attracts telemedicine application developer since sip designed multimedia communication ipbased network inherent native mode security mechanism built developed sipbased video conferencing application run internet provide authentication md digest hashing mechanism client designed provide voice video service sip currently standardized ietf client also integrated directory designed commobject architecture video conferencing client performance interoperability successfully tested working deploying telemedicine environment telemedicine setting gather data user order evaluate satisfaction physician patient additional feature identified enhance patient physician communication obtained easily client future ,2
BD_666,big ear robust design able produce calibrated ultrawideband scattering signature data isar image used offset feed compact range also served platform important measurement fopen scattering signature fopen foliage propagation performance year system produced data significance radar sensing community uhf vhf frequency ,2
BD_667,unceasing emergence technology wireless mobile telecommunication network combined simultaneous rapid advance information technology leading many solution field telemedicine thus offering opportunity improving existing supporting advanced service healthcare objective carry practical evaluation performance gsm gprs system transmissionreception xray image video emergency orthopedics case expected performance gprs superior gsm data transfer rate achieved gprs range kbps download time typical xray image file size kbytes mobile device region second similar performance also recorded case moving station simulating ambulance biggest part journey conclusion although medical imaging downloading timing range minute physician pleased benefit offered system freedom access anywhere anytime even motion ,2
BD_668,china biggest developing country unreasonable distribution research resource properly recognizing typical characteristic technological development region important improve effectiveness efficiency regional technological resource allocation china base investigating analyzing distribution research resource city province endeavor construct analyzing index system draw seven type regional technological characteristic china basis chinese r & ampd statistic relative data publicized national statistic office ,2
BD_669,space geodetic technology gps vlbi long baseline interferometry slr satellite laser ranging sar synthetic aperture radar revolutionized geodesy land however technology based electric wave directly applied seafloor geodesy electric wave inclusive light hardly propagate seawater adapt sound wave ocean bottom cable underwater communication positioning power supply data recovery importance crustal movement seafloor pointed long time last dream coming true promising report gpsacoustic seafloor positioning repeated acoustic ranging seafloor ocean bottom pressure monitoring tilt measurement deepsea boreholes longterm continuous regional observation crucial geodetic monitoring geodynamics time u examine plan scientific ocean bottom cable system although global coverage difficult transocean monitoring system regional system seismogenic zone feasible latter maintain real time observation seafloor crucial big earthquake prepared ,2
BD_670,analysis shfband radiowave propagation principle conducted urban area high density building site analysis based statistical data collected novosibirsk city one biggest city russia adjusted model interference cellular communication considered result experiment incorporation correction coefficient dealing peculiarity surrounding urban area known expression suggested ,2
BD_671,existing synthesis system influence area delay controller sufficiently taken account controller big influence especially certain datapath realization requires huge number state andor control signal present approach controller estimation highlevel synthesis fpgabased target architecture estimator presented invoked every synthesisstep ie allocation scheduling binding respectively considering controller influence overall area design design space exploration made accurate le error prone approach estimating area controller based information easily accessible step highlevel synthesis explicit description controller usually generated binding necessary particularly valuable allocation phase intensive design space exploration done based fast accurate estimate ,2
BD_672,propose intermediate mtf interval source coding scheme make explicit alphabetical ordering well symbol frequency proposed scheme encodes number symbol appeared since last previous occurrence current symbol count symbol alphabetically bigger current symbol proposed method capable removing data redundancy due symbol occurrence order ,2
BD_673,temperature arc discharge air measured spectrometer radiant power dc horizontal free arc tungsten electrode measured spectroscope power meter arc current mpa pressure result calculated w bigger nitrogen spectral line n temperature le k total radiant power density estimated sup wmsup sr k nm wavelength region radiant power density emitted w higher n n ii ii radiant power spl phiw nm spl mum case point light source radiant power emitted dc horizontal short free arc discharge mixtured tungsten vapor function current w w w increase proportion th power current value le wallstabilized arc radiant energy spl phisub ekj nm spl mum case point light source radiant power emitted dc horizontal short free arc discharge mixtured tungsten vapor function current input energy kj kj kj kj kj kj increase proportion th power input power radiant efficiency extremely high level % white light value considered champion data double gas temperature free arc mixtured tungsten estimated k k line pair method temperature almost value even current change current increase effect arc expanse radius direction stronger increment temperature case free arc considered energy arc becomes increment radius influence wall gas radius radiant power increase proportion th power current value half wallstabilized arc free arc doesnt restriction radius radius increase expand radius direction arc radius increase proportion square root current case constant current density ,2
BD_674,distributed parallel system face recognition face database system huge thousand face matching recognition process carried one computer cluster system must used improve matching speed many current cluster existing problem fit system special distributed parallel system developed complete face query recognition concept parallel virtual machine kind linked table structure adopted system decreased lot moving overhead adding deleting node array structure also truly realized infinite extensibility furthermore key technique distributed database buffer synchronization technique communication multithreading control flow adopted guarantee normal running practical result proved parallel system could improve matching speed time moreover greatest advantage system increasing matching speed also breaking upper limit face data capacity consequently face data capability system extended arbitrary figure bigger possible ,2
BD_675,association rule mining one important research area data mining yet exist two big problem process acquiring rule traditional mining algorithm ie quantity quality rule presently many method focus resolving two problem although method reduce amount rule derived extent total number big ever first propose notation upper closed itemset generalized association rule base obtain generalized association rule base database contains whole information association rule also conform structure convenient practical application also propose mining algorithm generalized association rule base proposition example algorithm shown valid efficiently solve problem quantity rule ,2
BD_676,development toward ubiquitous pervasive computing lead application scenario large number sensor computing device connected network device might constantly send status information via multicast number application user one big challenge environment amount data traffic generated sensor depends size data transmission frequency number sender receiver however certain application sufficient receive le accurate aggregated data group source lead possibility programmable router perform data aggregation inside network basic algorithm data merging described literature address large number source organized hierarchical structure allow multiple user get view sensor different level aggregation control information provided aggregating node traverse aggregation tree joining different multicast session transmit different level detail provides novel communication paradigm reduces network overhead continuously transmitting source organizes data way useful receiver provide two detailed example scenario battlefield information system aggregate geographic location data unit conferencing application aggregate audio data describe aggregation algorithm used analyze effect delay jitter periodic transmission source describe hierarchical control structure provides multiple level aggregation realtime transport protocol rtp used implement performance proposed scheme evaluated measurement done implementation audio aggregation application ,2
BD_677,epcollider hera desy germany high energy physic experiment hi zeus upgraded year expected specified luminosity five time higher one upgrade project build set multi wire proportional chamber cipk providing information distinguish event induced beam background epinteractions early stage trigger first level trigger system provides trigger decision total channel chamber speed mhz system realized large field programmable gate array fpga order comply timing requirement necessary dead time free trigger decision spl mu achieved simultaneous event pipelining readout preparing trigger decision total data throughput rate gb system developed hardware description language verilog special attention drawn integrated error correction system fpga realized hard wired electronics system necessary ensure maximum pattern recognition efficiency even high occupancy cipk trigger system installed parallel hera startup commissioned order reach best performance flexible programmable hardware clearly big advantage ,2
BD_678,describes design strategy algorithm developed visualization registration volume interest voi definition measurement multimodality single subject head neck ct mr pet surgical tumor specimen image part project measured usefulness mr pet image threedimensional radiotherapy treatment planning originally based ct image vois could defined registered volume exported ct image treatment planning system dicom major problem handling large datasets big difference fov voxel size used objectoriented design c++ programming language develop object class method efficient data management used extensible markup language xmel standard save registration transformer vois registered volume resliced fly visualization voi statistical information computing therefore avoided creation large resliced dataset file used class extend two existing application interactive registration roi drawing describes data handling problem ii developed object relationship method iii two application ,2
BD_679,grid computing computational concept based infrastructure integrates collaborates high end computer network database scientific instrument owned managed several organisation involves large amount data computing require secure reliable resource sharing across organisational domain despite high computing performance orientation communication delay grid computing node big hurdle due geographical separation realistic grid computing environment communication scheme broadcasting multicasting routing therefore take communication delay consideration communication scheme grid computing environment pose great challenge due arbitrary nature topology context heuristic algorithm multicast communication proposed grid computing network finite capacity bursty background traffic scheme facilitates internode communication grid computing network applicable singleport mode message passing communication scheme utilises queuebyqueue decomposition algorithm arbitrary queueing network model based principle maximum entropy conjunction information theoretic decomposition criterion graph theoretic concept evidence based empirical study indicates suitability scheme achieving optimal multicast communication cost subject system decomposition constraint ,2
BD_680,like oral communication gesture natural way carry human machine interface early day robotic system human gesture used control robot movement mean masterslave structure spite robot programming language manual control reliable way carry complex task unstructured environment situation noncontact passive remote system helpful control teleoperated robot mean human gesture vision system able detect locate track head hand human body presented system us several calibrated camera placed around operator scenario locate body part person system combine different computer vision technique increase reliability body part detection image movement detection skin colour segmentation stereo data provided module focused looking coherence according human body dimension scheme proposed possible obtain lowcost realtime system human computer interfacing based natural way communication gesture civil area big robot shipyard mine work crane possible application ,2
BD_681,show propose inexpensive flexible carrier system agv automated guided vehicle practical manufacturing process making idc intelligent data career big capacity data twoway communication characteristic system simple easy change agv route number easily coexistence person order verify possibility system realization developed algorithm agv traffic rule concept confirmed effect proposal system computer simulation ,2
BD_682,difficulty research supervised learning fuzzy rulebased system difficulty selecting effective input variable difficulty selecting proper rule structure solve difficulty proposed gasup genetic algorithm degeneration performs structural learning thought information criterion system optimized obtained system become general explain unlearned data better gasup optimizes information criterion directly case many parameter lost earlier generation idea multiobjective optimization estimation error information criterion optimized introduced avoid problem weight error bigger earlier generation weight information criterion becomes bigger later generation shown idea effective structural learning rbf fuzzy rulebased system ,2
BD_683,world small company vsc characterized great ersity term quality behavior consequently principle economic evaluation used today medium big sized company directly used vsc must grouped company similar behavior conducted french ministry finance find original technique group company cluster economic theory background selforganizing map som used create subset company original database method implemented java software web frontend perform computer evaluation technique method validated data set company collected french student clustering software found four subset correspond economic theory world production interpersonal industrial immaterial merchant world ,2
BD_684,design assistant expert tool used highlevel whatif consideration early stage design point design capture complete work highlevel structural representation design used logic captured support real topdown design approach refinement mechanism goal answer question big circuit ? power dissipation ? fit gatearray ? package ? design one two chip ? tool collection designer expertise built top prolog expert system containing technical data estimation rule providing powerful flexible environment & lt & ltetx & gt & gt ,2
BD_685,usb universal serial bus interface commonly used computer hardware assures asynchronous serial data transmission speed much bigger r interface essay usb implementation unit intended sound vibration measurement analysis presented aim usb interface implementation assure fast data transmission unit pc usbn chip national semiconductor used interface controller software developed measurement unit pc testing application different mode data transmission tested achieved result test performed different operating system presented conclusion concerning required modification implementation order achieve faster transmission drawn ,2
BD_686,recent research modeling timing jitter raised requirement predictable high magnitude uniform wide bandwidth hfield novel hfield generator design methodology proposed consists single layer air core solenoid digital power switch driver take advantage low power wide bandwidth big currentdriven capability input overdrive voltage digital switch drive railtorail voltage output current power bandwidth mhz demonstrates novel solenoid driver circuit generate accurate hfield comparing digital analog approach comparing experimental data theoretical data ,2
BD_687,harddrive technology critical point history vendor hitting limit amount data current technology read write square inch disk space hard drive capacity continue increase rate arealdensity growth likely slow hurt company maxtor make much revenue selling bigger hard drive ongoing basis moreover hard drive price per gigabyte storage capacity fallen industry advance thereby reducing many vendor profit margin reason researcher developing approach could increase storage density capacity important force driving future hard drive demand home entertainment device although product camcorder camera pda also play important role ,2
BD_688,visual medium data image raw data representation many important application biggest challenge visual medium data come extremely high dimensionality comparative spatial interest pixel sip including eightway novel sip miner harris lucaskanade whose extraction considered important step reducing dimensionality visual medium data extensive case study shown usefulness sip lowlevel feature visual medium data classpreserving dimension reduction algorithm gsvd applied reduce dimension feature vector based sip experiment showed superiority pca ,2
BD_689,development intelligent transportation system traffic data management system becomes important imperative necessary tool people future organize data efficiently agentbased approach provides useful method manage vast quantity various type traffic data method also involves integration data resource various type data physical storage medium various computer server analysis algorithm carry fundamental topic traffic data management multiagent system ma architecture traffic data management based ma designed design principle component agent workflow ma also introduced finally research provided architecture discussed adopted practical project urban traffic control center construction big city china ,2
BD_690,learning spillover production tftlcd investigated quarterly market data tftlcd panel price plantlevel data panel output glass input learning curve tftlcd estimated multioutput model developed modified traditional single output model turn spillover significant external learning rival company production experience much bigger internal learning company production experience mean newcomer easily enter tftlcd industry acquire manufacturing technical skill knowhow difference internal external learning smaller rd generation process nd generation process korean enterprise went market full scale moreover korean firm experience dram production enables lower learning curve tftlcd easily another factor success explains industrial dynamic tftlcd entry barrier leadership change etc learning curve also delivers implication persistence leadership ,2
BD_691,investigates three different way transfer function method detecting mechanical winding displacement power transformer reliable approach timebased comparison requires finger print data previous measurement information however usually available multilegged transformer without zigzagconnected winding result separately tested leg used mutual reference constructionbased comparison third approach compare transfer function obtained identically constructed transformer typebased comparison however transformer given nominal specification data winding design may time undergo change cause change transfer function proposed solve problem calculating tolerance band transfer function big group sametype transformer novel statistical algorithm presented approach demonstrated set specified identically mva power transformer ,2
BD_692,size complexity vlsi circuit increase need faster floorplanning algorithm also grows introduce traffic method creating wire areaoptimized floorplans connectivity grouping simple geometry efficient data structure traffic achieves higher result quality simulated annealing sa fraction time speed allows designer explore large circuit design space reasonable amount time rapidly evaluate small change big circuit quickly produce initial solution floorplanning algorithm ,2
BD_693,contrast broadcasting data packet wired network broadcasting data packet mobile ad hoc network manet big challenge due high bit error rate high collision probability even though broadcasting manet intrinsically unreliable ad hoc routing protocol aodv dsr application protocol sdp ip autoconfiguration must distribute important information make matter worse broadcast used several protocol node manet one node broadcast data packet time simultaneous broadcasting multisources make packet delivery rate drop severely broadcasting single source overlapped data path multisources solve broadcasting problem manet propose high reliable broadcast mechanism considering network resource value wireless network proposed mechanism minimizes network overhead improve reliability neighbor knowledge obtained periodically exchanging hello message result simulation n show mechanism achieves high reliability packet delivery whole node minimizing network resource consumption efficiently ,2
BD_694,digital tv system necessary video audio also data processing especially case bidirectional broadcasting manage return channel created internet pstn many functionality multitasking job need operating system embedded linux source program increase cost effectiveness market many advantagesreusable device driver application program convenient development environment shell file system easy resolution problem source community modified embedded linux kernel cross development environment bigendian system redesigned device driver kernel execution configured system memory map order load linux kernel also developed device driver entire system control ,2
BD_695,optical local area network architecture based multimode optical fiber component short wavelength laser detector widely used fast ethernet protocol presented optically transparent network represent novel approach fibertothedesk application made minimize cost associated passive optical lan implementation biggest issue realization network synchronization bursty traffic collision detection detail solution synchronization problem introducing analog sinusoidal carrier addition data signal sent data packet duration extraction data synchronization signal made simple filtering facilitating receiver realization ,2
BD_696,clustering analysis play important role scientific research commercial application kmeans algorithm widely used partition method clustering datasets scale increase rapidly difficult kmeans deal massive data improved kmeans algorithm presented avoid getting locally optimal solution degree reduce probability iding one big cluster two one owing adoption squarederror criterion experiment demonstrate improved kmeans stable accurate ,2
BD_697,despite great popularity big bang framework cosmology face growing contradiction observation big bang theory requires three hypothetical entitiesthe inflation field nonbaryonic dark matter dark energy fieldto overcome gross contradiction theory observation yet evidence ever confirmed existence three hypothetical entity prediction theory abundance sup sup li spl sigma data assumed density baryon probability theory fitting data le sup observation void distribution galaxy excess mpc diameter combined observed low streaming velocity galaxy imply age structure least triple likely six time hypothesized time since big bang big bang prediction anisotropy microwave background involve seven free parameter still excluded data spl sigma level observed preferred direction background anisotropy completely contradicts big bang assumption contrast prediction plasma cosmology strengthened observation including evidence stellar origin light element plasma origin largescale structure origin cosmic microwave background radio fog dense plasma filament evidence show time come indeed long since come abandon big bang primary model cosmology ,2
BD_698,limitation ipv becomes big problem resolve problem ipv proposed growing various project wide project tao making big effort promote ipv tottori university environmental study tues met problem ipv though ipv good solution problem problem used ipv jgn tried transfer data archaeological photograph tokyo tottori amount data gb application find activity web page ipv internet describe detail short problem met similar problem experienced ipv network fifteen year ago ,2
BD_699,modern vlsi process crosscoupling capacitance adjacent neighboring wire metal layer large fraction total wire capacitance lead problem delay variation due crosstalk reduced noise immunity arguably one biggest obstacle design ic recent time problem particularly severe long onchip bus since bus signal routed minimum pitch long distance propose solve problem crosstalk canceling codecs utilize memoryless codecs reduce logical complexity enhance robustness technique bus data pattern classified spl middotc spl middotc spl middotc spl middotc spl middotc pattern based maximum amount crosstalk exhibit crosstalk avoidance codecs eliminate spl middotc spl middotc pattern reported describe crosstalk avoidance technique eliminate spl middotc spl middotc pattern describe analytical methodology accurately characterize bus area overhead spl middotc pattern codecs result characterize area overhead versus crosstalk immunity achieved similar exercise performed spl middotc pattern experimental result show spl middotc crosstalk canceling technique bus sped factor area overhead % spl middotc technique robust ,2
BD_700,amount data stored enterprise increasing rapidly volume data stored database approaching terabyte size response time directly proportional amount data database requirement fast response time circumstance motivated research parallel database system pd last decade despite distribution data pd various processing element pe concurrency control algorithm us centralized scheduling approach approach inherent weakness heavy load condition big lock table number message system central overloaded scheduler distribute scheduling responsibility node data actually located also propose serializability criterion parallel database quasiserializability meet requirement ,2
BD_701,next generation internet protocol ipv us bit internet address replace current ipv protocol gradually ipv ocean internet network completely transition ipv ipv ipv coexist network device must support ipv ipv time especially general user want internet application without big change even network changed ipv describes alg application layer gateway ipv translates application layer data natpt transition mechanism design implementation dnsalg ftpalg research application layer gateway examine relationship ip layer translation application layer translation ipv deployed ip layer translation also application layer translation necessity ,2
BD_702,one biggest opportunity provider today provide ip based internetworking service meet exponential growth demand business residential customer ip designed transparent topology underlying transport protocol opportunity come number issue must resolved order meet capacity requirement deliver service cost effective revenue generating manner internet traditionally provides commonly characterized best effort architecture tremendously successful supporting data application like www email ftp http many application run well model interactive application telephony video conferencing impose stringent demand network project computer software package opnet modeler used examine dynamic ip traffic sonet ppp point point protocol ip atm real time application nonreal time application ,2
BD_703,due biglagged biginertial character load control object thermal power unit difficult conventional feedback signal guarantee rapidness precision simultaneously low frequency disturbance filter designed based data fusion theory filtering measured radiant energy signal boiler furnace low frequency disturbance signal gotten rid without phase lag general observer configuration frequency domain crosscomplementary knowledge observer additional degree freedom design crosscomplementary knowledge measured different source radiant energy heat signal application measurement radiation signal boiler furnace show method remove low frequency disturbance effectively robust model perturbation ,2
BD_704,big organisation realising wireless network used data traffic business long recognised benefit able keep touch employee move face arrival wifi provides straightforward costeffective solution capable building voip wireless local area network wlan technology provide worker sort communication mobility take granted everywhere else daily life network allow staff roam office phone across whole organisation enticing prospect quality security still important issue ,2
BD_705,data replication used extensively widearea distributed system achieve low dataaccess latency large number heuristic proposed perform replica placement practical experience indicates choice heuristic make big difference term cost required infrastructure eg storage capacity network bandwidth depending system topology workload performance goal describe method assist system designer choose placement heuristic meet performance goal lowest possible infrastructure cost existing heuristic classified according number property inherent cost lower bound class heuristic obtained given system workload performance goal system designer compare different class heuristic basis lower bound experimental result show choosing heuristic proposed methodology result time lower cost compared obvious heuristic caching ,2
BD_706,noaa next generation geostationary operational environmental satellite go beginning go r followon go np series go r developed launch time frame meet requirement validated rigorous screening verification process present opportunity explore instrument satellite design system architecture noaa national environmental satellite data information nesdis explore alternative distributed architecture might costeffective continuing current philosophy combining instrument onto one big spacecraft go r improvement environmental sensing instrument include advanced baseline imager abi hyperspectral environmental suite he capable providing sounding imagery enhanced solar xray imager esxi space environment monitor sem lightning mapper lm noaa also investigating possible operational instrument coronagraph solar imager microwave sounder noaa analyze different architecture distributed v consolidated instrument abi he sem sxi lm orbit geo v meo determine optimal constellation coverage communication configuration abi he sensor support conus coastal water cw estuary timely imaging sounding cw zone defined ocean water mile adjacent conus well estuary he support coastal water ocean color ocean optical property resolution meter abi support long wave ir measurement sea surface temperature sst currently abi formulation study underway three contractor overall system concept following request information rfi contract source meeting industry regarding overall approach summer procurement activity concept study he initiated several contractor similar activity inaugurated instrument ground system spacecraft concept provides latest status activity well update concept operation conors ,2
BD_707,deal broadband constant beamwidth beamforming problem circular array response vector circular array expanded form sum infinite series whose core function first kind bessel function high order term series truncated array response vector different frequency component transformed approximately equal reference frequency constant beamwidth beamforming vector constructed transforming procedure beam different frequency reference beam effectiveness method firstly verified computer simulation investigate performance proposed method lakeexperiment carried element uniform circular array radius based data collected experiment constant beamwidth beam successfully formed eight different frequency covering oneoctave frequency band although big amplitude difference among hydrophones observed experiment constant beamwidth beam still correctly formed except distortion sidelobe region beampattern experiment result conclude constant beamwidth beamforming approach proposed circular array applicable practical system good error tolerance ,2
BD_708,summary form given increasingly recognized navigation communication system play everexpanding role proliferation application autonomous underwater vehicle auvs objective quantify impact high accuracy navigation requirement performance system mcm scenario assessment quantified uuv navigation requirement based time complete mission ie search area specific probability detection classification pdpc assessment also examined communication capability required term defining required data message size content transmission storage time etc investigated four different navigation conceptstactics used search yard region varies depth foot lawnmower search uniform track spacing yard used case result showed tactic big driver case high accuracy in unit uuv detrimental overall mission performance assessment conducted autonomous littoral warfare system evaluatormonte carlo alwsemc simulation developed coastal system station cs ,2
BD_709,wave monitoring system developed meet need measuring wave accurately continuously long period ocean describes newly developed wave monitoring system able monitor frequency spectrum also directional spectrum result model experiment shown carried order confirm validity system demonstrated accuracy wave measurement fairly good one measured wave data obtained big typhoon hit okinawa september presented ,2
BD_710,era semantic web enabled user extract semantically relevant data web backbone semantic web shared uniform structure defines web information split regardless implementation language syntax used represent data structure known ontology information web increase significantly size web ontology also tend grow bigger extent become large used entirety single application stimulated area subontology extraction may extract optimized subontologies existing base ontology subontologies valid independent ontology known materialized ontology specifically extracted meet certain need size original ontology process repeatedly iterating million node relationship form optimized subontology extensive therefore identified need distributed approach extraction process ontology currently widely used proposed approach distributed ontology extraction play important role improving efficiency information retrieval ,2
BD_711,pointtomultipoint broadband wireless access bwa attractive solution provide advanced data service user easy access wireline data service however bwa need support delay sensitive service user application becoming increasingly sophisticated wireless packet scheduling important part qualityofservice qos provisioning bwa biggest difficulty wireless packet scheduling locationdependent channel error channel condition independent fair scheme cif t eugene et al march us explicit leadinglagging approach compensate erroneous channel state able satisfy rapid convergent guaranteed throughput fairness propose token bank fair queuing tbfq scheduling algorithm qos provisioning mechanism asymmetric broadband pointtomultipoint wireless lan consider throughput fairness performance tbfq locationdependent channel error condition variable packet length extension previous applying tbfq next generation cellular network ,2
BD_712,present possibility reliability knowledge maintenance employee used order receive reliability data used simulation calculation presented methodology open big source information employee knowledge entail processing imprecise data knowledge given form failure time plot form verbal expression specific information deal data format precision expertbased information methodology presented enables transformation certain employee called expert information reliability data apart also show influence imprecision expert information handle imprecision order get applicable result finishing subject also provides possibility deviation expert information reality estimated dependent expert statement approach one tax trustability expert information ,2
BD_713,apply dempstershafers theory evidence combination mining medical data consider classification two domain breast tumor skin lesion classifier output used basis computing belief dynamic uncertainty assessment based class differentiation combine belief three classifier knearest neighbor knn naive bayesian decision tree dempsters rule combination combine three belief arrive one final decision experiment kfold cross validation show nature data set bigger impact classifier others classification based combined belief show better overall accuracy inidual classifier compare performance dempsters combination differentiationbased uncertainty assignment performancebased linear majority vote combination model circumstance evidence combination approach improves classification ,2
BD_714,due overall popularity internet elearning become hot method learning recent year internet learner freely absorb knowledge without restriction time place many company adopted elearning train employee elearning system make enterprise competitive increasing knowledge employee know elearning become one potential ecommerce business elearning environment architecture consideration single computer server erecting foundation soon workload increase software hardware need updated renewed big burden company insufficient budget thus research employ kind grid computing technology called access grid integrate idle computer resource enterprise elearning platform substituting purchase costly highlevel server equipment access grid support grouptogroup communication via highspeed networking internet provides high quality audio realtime video interactive interface elearning user hardware cost reasonable company academy easily set access grid node access grid technology enterprise integrate training material knowledge repository data grid elearning vod platform knowledge shared published flexibly widely ,2
BD_715,summary form given talk build around three challenge fusing heterogeneous uncertain source information extracting tracking geometry dealing computational complexity first briefly describe done group led dr john fisher machine learninginformationtheoretic method illustration audiovideo fusion association signal subject propagation distortion second topic focus socalled curve evolution method probabilistic interpretation method developed group incorporate informationtheoretic method blind segmentation prior modeling shape segmentation complex imagery illustration would given two problem profound societal importance automatic segmentation prostate prostate brachytherapy automatic segmentation photo zebra idea zebra third topic deal research group largescale problem statistical inference specified term socalled graphical model briefly describe significant theoretical success developing method exploit embedded tractable graphical structure solve largescale estimation problem large integer programming problem arise data association finally two really big challengesvery largescale data assimilation geophysical field fusion large number distributed inidually limited sensor briefly commented addressing challenge requires much union topic addressed talk asking question suggest research area might evolve contribute large interesting challenge ,2
BD_716,remote access control monitor various device industrial environment important big challenge engineer automation institute internet technology providing accessibility great benefit industry one demand access alienbradley slc family programmable logic controller plc internet available standard web browser remote access capability provides realtime data acquisition monitor control device connected inputsoutputs module plc present novel scheme provide realtime accessibility alien bradley plc control equipment without dedicated licensed software run tool web server microsoft net programming technology used implement novel scheme involves two step first step read write data plc slc visual basic net vbnet programming language second step slc data displayed web page monitoring controlling html page active server page net aspnet web service web server utilized project internet information service u microsoft window server ,2
BD_717,distributed transaction one important service jee application server efficiency big impact latter overall performance distributed transaction design extensible portable jee application server strategy optimize performance experimental data indicate much improved performance transaction without sacrifice transaction integrity ,2
BD_718,collection organization data clinical trial requires sophisticated information management system ideal system easily accessible webtechnology provide high security data deciding solution meanwhile even mid bigsized company also evaluate opensource platform pure commercial solution opensource product seems get feasible early opensource disadvantage like limited support limited userfriendliness seem disappear author intended discus basic scheme software strategy choose objective develop scorecard decision support parameter trial userneeds scaledimension trial financial budget itresources long term objective company itstrategy scorecard obtained free author ,2
BD_719,nowadays activity performed internet people involved transaction circle security authorization control becomes one biggest concern hence motivated need manage enforce strong authorization mechanism largescale webenvironment role based access control rbac provides flexibility security management key infrastructure pki provide strong authentication privilege management infrastructure pmi technology provide strong authorization order satisfy mentioned security requirement established role based access control infrastructure developed prototype us x key certificate pkcs attribute certificate ac access control performed access control policy written xml policy role stored ac pkcs ao stored ldap server solution policy management described component prototype administration tool access control engine access control engine provides mediates data user resource also responsible authentication authorization administration tool create key pair pkcs ac manage user information ,2
BD_720,one biggest change network evolution network converges voice data mgcmedia gateway controller mgmedia gateway play core roll converged network mg providing medium translation connection mgc responsible call processing provide erse service converged network mgc interoperate legacy s network respect signaling sgsignaling gateway provides signaling interworking legacy scn network packet network sigtran defines suite protocol adaptation layer transporting information ip based network sctp used common signaling transport sigtran providing reliable service converged network connectivity mgc sg great significance suggest autorecovery method sctp association mgc sg make network reliable and¿fault tolerant ,2
BD_721,analyzes land dynamic change latest year huabei region based r gi huabei region includes four province hebei shanxi shandong henan two city beijing tianjing one municipality inner mongolia region chinese center politics economy culture also important food supply base huabei region significant tm image primary data source processing atmosphere geometric correction get two dynamic coverage visual interpreting mge environment select huabei region dynamic coverage arcinfo grid coverage changed m* grid format past year farmland increasing especially dry land forest grassland decreasing urban increase rapidly farmland shifting urban land change secondly grassland shifting farmland bigger proportion according land zone huabei locates two zone one huanghuaihai farmland shifting urban show dry land changing county ecotone agriculture animal husbandry focus grassland shifting farmland inner mongolia past year ided two period time comparing two period time huanghuaihai farmland shifting urban decrease farmland increase urban faster ecotone agriculture animal husbandry velocity farmland increase evidently greater ecotone agriculture animal husbandry obvious change ,2
BD_722,oilgas exploration much information collected concerning geophysical exploration geochemical exploration remotesensing geology exploration depending traditional exploration method difficult make progress deep step oil exploration theory method urgently needed geoanomaly theory first put forward zhao pengda chinese math geologist widely applied solid mineral exploration research promoted oil gas exploration mine valuable oil gas geoanomaly information knowledge collected data big problem point view taking oil gas exploration one basin east china example research done mining oil gas geoanomaly information data mining technology research mining method block convulsion filtering bp neural network grey prediction applied besides entropy complex method research show block convulsion filtering method beneficial removing noise data grey prediction method better way extract geoanomaly information drilling seismic data bp network method used well predicting reserve cover layer parameter high accuracy complex entropy method make great effect predicting oil gas preferable area research oil gas geoanomaly information mining good result achieved quantity method oil gas geoanomaly information extraction research contributes lot get effective exploration knowledge predict preferable object oil gas exploration ,2
BD_723,statistical inversion method first presented support application kernelbased brdf bidirectional reflectance distribution function model calculation surface albedo operational procedure inversion kerneldriven brdf model albedo retrieval applicable sevirimsg reflectance measurement processing step applied spaceborne polder sensor data follows quality control accumulation priori information model coefficient directional hemispherical reflectance implementation brdf model inversion method based biased estimation instead usual nonbiased least solution big variance case data control procedure consists filtering input reflectance data output model coefficient based analysis criterion determined fisher statistic multicriteria procedure follows considering particular shape reflectance angular signature tstatistics bowl shape index dome shape index white sky albedo bihemispherical reflectance black sky albedo variance directional hemispherical reflectance procedure applied polder data corresponding class igbp land cover classification statistical result include mean value covariance matrix spectral brdf model coefficient ,2
BD_724,described method producing precise global dmspols nighttime mosaic data plural ols scene short duration integration noaaavhrr data analysis result integrated data latter half clearly showed spreading light distribution pattern several big city change geographical distribution light forest fire field fire ,2
BD_725,describes sar processor implementation able process data acquired stripmap scansar spotlight airborne space borne platform together radar imaging technique processing software developed able dynamically adapt performance memory cpu resource computer running automatically calculates optimum number block used process big image maximum portability also one major task interface enhanced capability extended markup language xml standard adopted parameter setup file simplify software toolkit manual time improve experience aim flexible core help design processor future system example transmitter receiver platform thus follow different path processing kernel specific module operating mode platform validated raw data er radarsat esar order validate spotlight mode simulated data used air space borne platform ,2
BD_726,image processing discrete system assumes application digital filtration method spectral analysis discrete fast fourier transformation many applied problem error brought processing method computing system comparable error final result getting matter extent error data discretization therefore topical problem definition relative error discretization fourier transformation solved offered shown considered type real signal discretization error decrease inverse proportion squared number discrete point simple type function exact expression discrete spectrum approached expression discretization error corresponding received big number point ,2
BD_727,microarray technology essential part modern biomedical research moment widely utilized microarray platform academic biomedical research dna microarray due flexibility low cost one biggest drawback dna microarray technology high variation data quality thus order obtain reliable result sophisticated image analysis extensive preprocessing step applied actual microarray data analysis take place highlight essential microarray preprocessing step ,2
BD_728,fraudulence case happened time business environment responsibility auditor prevent swindling case ensure every operation conforms regulation recent year adopted business environment traditional approach operation paper audit trail changed edp auditing typically since auditor come nonit background difficult involve area edp auditing furthermore enterprise resource planning erp adopted competing opponent around world erp make enterprise system complicate hence auditor face even big problem audit erp environment propose mechanism structure rule auditing information mapping business process data flow data model mechanism auditor directly obtain auditing information based business process containing data changing process ,2
BD_729,world ebusiness businesstobusiness bb plethora concept standard one must knowledge understand beginning transformation path traditional manual based business process automated semiautomated electronic based one variety complexity standard concept significant barrier entry ebusiness many small company approximately % european company buy sell internet big company buying selling challenge facing eeurope action plan enable small medium sized enterprise smes participate ebusiness without extending resource aspiring ebusiness professional small company time resource needed invest understanding concept standard need understand concept standard quickly deciding invest time area discus development ebusiness skillset enhancement tool eset bb integration scenario development working model ebusiness environment assist smes advanced rd level student introducing world bb enables experience bb environment professional see enterprise ebusiness bb see data electronic environment experience transfer data electronically internet view process modeled simulated see ebusiness bb environment processing data business process enables make informed decision investment area existing problem easily accessible environment available either student feed smes professional experiment interact ,2
BD_730,cluster system dynamic load sharing support submission migration workstation determined availability cpu memory resource workstation time l xiao et al system small number running job unexpectedly large memory allocation requirement may significantly increase queuing delay time rest job normal memory requirement slowing execution inidual decreasing system throughput call phenomenon blocking problem big job block execution pace majority job cluster since memory demand job may known advance may change dynamically possibility unsuitable submissionsmigrations cause blocking problem high existing load sharing scheme unable effectively handle problem propose two scheme address problem first scheme network ram supported load sharing combine migration network ram us remote execution initially allocate lightly loaded workstation necessary network ram provide global memory space larger would available otherwise scheme merit migration network ram experiment show effectiveness scalability however scheme requires network ram facility cluster may cause additional overhead increase cluster network traffic order address limit propose second scheme memory reservation incorporated dynamic load sharing adaptively reserve small set workstation provide special service job demanding large memory allocation soon blocking problem resolved memory reservation scheme system adaptively switch back normal load sharing state scheme target handling large dataintensive job cluster mutually complementary network ram supported load sharing scheme fully utilize cluster global memory space memory reservation scheme advantage simple implementation low overhead thus effective alternative practically deployed cluster computing different system condition ,2
BD_731,analyzes wavelet transform application data compression power system transient study influence compression efficiency quality different mother wavelet scale level thresholdings present relation compression efficiency compression accuracy show get optimal solution show wavelet transform lead data compression approach high compression efficiency high compression accuracy high compression quality good denoising effect wavelet transform bring remarkable advantage field big amount data processed like fault recording scadaemsdms system ,2
BD_732,address problem taking account data imprecision clustering binned data mixture model binned em algorithm framework defect detection problem acoustic emission control brought treat set point em algorithm applied diagonal gaussian mixture model one provides satisfactory solution real time constraint imposed problem make application impossible number point becomes big data set become larger data processing becomes increasingly complex result data analysis expensive computation time solution propose group data available data thus take form histogram data also called binned data fit binning data procedure imprecise data model imprecise data multivariate uncertainty zone propose assign uncertainty zone several bin percentage proportional overlapping surface bin experimental result compare binning procedure classical one applied imprecise point interval em algorithm considered reference simulated data ,2
BD_733,cost convenience security converge world sensor bigger database much le privacy technology us data added seemingly every day potential greater abuse growing meanwhile legal protection lagging far behind ,2
BD_734,accumulation protein related data internet many domain based computational technique predict protein interaction developed however technique still many limitation used real field usually suffer low accuracy problem prediction provide interaction possibility ranking method multiple protein pair reevaluate domain combination based protein interaction prediction method develop interaction possibility ranking method multiple protein pair ranking method one discern protein pair probable interact protein pair multiple protein pair reevaluation found accuracy prediction improved size noninteracting set protein pair increased size noninteracting set protein pair increased time bigger interacting set protein pair learning set % sensitivity % specificity achieved yeast organism validation ranking method revealed exist correlation interacting probability accuracy prediction case protein pair group matching pip value interacting noninteracting pip distribution ,2
BD_735,rock drilling many industry today drive towards unmanned equipment full automation big issue challenge automation process rock drilling retraction drill steel drilling completed today drilling performed automatically extend human ear required final part splice drill steel opened enough allow retraction discus fast fourier transform fft method search audio data order detect locate specific sound appearing retraction drill steel possible investigate achieving full automation drilling process possible wavelet also evaluated far author know system today automatic retraction drill steel recording analysing sound rock drill rig comparison system implemented electronic ear human ear evaluated fft applied preprocessing method examines feature power spectrum detection sound splice opened sound contains higher power spectrum sound rest drilling procedure feature classification program designed experimental result show good possibility make commercialized product automatically detect drill steel ready retracted ,2
BD_736,international collaboration astronomer computer scientist piecing together mean connect stored data collected last several decade hundred groundbased orbiting observatory thousand archive effort create world biggest best telescope known virtual observatory vo allow astronomer well student general easily locate download research data internet vo also serve grid computing network giving researcher regardless location resource equivalent supercomputer desktop comparing billionrecord archive running largescale simulation vo encompasses patchwork project organized international virtual observatory alliance alliance includes astronomer computer scientist least country vos various working group scientist hammering standard make archive interoperable outlining necessary infrastructure defining vos scientific goal ,2
BD_737,big potential ultra wideband radio particular low power consumption low power spectral density high immunity interference affords many benefit consumer electronics also medical device cochlea implant electronic hearing apparatus wireless link human tissue required propose uwb link data rate mbps propagation distance mm transmitter antenna receiver described proposal semiconductor integration made ,2
BD_738,internet corporate data warehouse full type digital information simple text document complex application one type information gaining prominence threedimensional object computeraided design cad drawing complex engineering part digital representation protein complex molecule increasing amount information making way onto web corporate database advance computing power combined interactive modeling software let user create image query search made dsearch technology possible searching several important element voxel query formulation search process search engine help big company quickly find whether certain part inventory ,2
BD_739,independent component analysis ica multivariate data analysis tool basic principle ica assumption independency source data separation data source ica algorithm search demixing matrix maximize independency searching process mostly done iterative way involving high order statistic process time consuming certain application speech source signal power lower frequency reduce data length removing high frequency component wavelet decomposition popular method propose data reduction wavelet preprocessing ica speed ica computation investigate haar daubechies daubechies daubechies wavelet wavelet analysis investigate computation time function level decomposition wavelet found haar wavelet third level decomposition gave biggest advantage computation speed % ,2
BD_740,spoken dialog system becoming increasingly common deployed service system perfect often deployed openloop lacking systematic procedure diagnosing problem making improvement order target improvement biggest impact two thing needed first method tool detailed analysis data feed call log customer audio second interactive tool presenting intuitive view result responsible application discus paradigm implementation able close loop system execution system evolution providing empirical dialog trajectory analysis represented via stochastic finite state machine novel graph analysis algorithm introduced change detection compression pruning display based userinterface objective ,2
BD_741,impulsive acoustical event impact compose big family everyday sound detection separation sound important current computational auditory scene analysis propose method online architecture detecting separating acoustical impact able find every impulsive acoustical event continuous data flow energy density function timefrequency span given result separating impact background overlapping impact onset used finding event predictionbased method introduced separating event overlap time frequency method rely spectral peak track harmonic property thus applicable broad class sound ,2
BD_742,mp audio compression increase demand insertion additive data copyright information information music content continues grow related research also progressed actively additive data inserted mp bitstream cause distortion music quality change file size due modification mp bitstream structure satisfy condition additive data inserted bitstream modifying linbits among quantized integer coefficient big value characteristic linbits distribution also considered result subjective sound quality evaluation mean opinion score mo test quality value mo confirmed achievable data insertion rate bytessec proposed method possible insert additive data effectively encoded bitstream retrieve easily thus realizing various application audio database management ,2
BD_743,dealing multiobjective optimization tyresuspension system racing car large number objective taken account two different model used validated data coming instrumented car differential equation based physical model neural network purely numerical method objective function defined least showing strict clash equivalent scalar function based formulation intentionally avoided due well known limitation fuzzy definition optimum generalization paretooptimality applied problem result approach subset paretooptimal solution problem big portion entire search space properly selected consequence input designer obtained optimal solution compared reference vehicle optimum previously obtained design experiment technique different mo optimization strategy ,2
BD_744,many machine defined thing mechanical electrical electronic property world people growing number machine networked harbor research technology consultancy analysis firm estimate least billion device internetconnected worldwide increasingly popular machinetomachine technology plan take advantage development mm would leverage connectivity enable machine including manufacturing telecommunication equipment data center storage tank propertysecurity product industryspecific asset publicutility system even vending machine communicate directly one another mm based idea machine value networked network becomes valuable machine connected sensor gather information mm system transmit becoming widely used thus driving demand technology biggest trend vendor expanding mm wireless technology radio chip module attach almost device machine thus mm gearing exponential growth ,2
BD_745,propose system read text encountered natural scene aim provide assistance visually impaired person describes system design evaluates several character extraction method automatic text recognition natural image receives growing attention potential application image retrieval robotics intelligent transport system camerabased document analysis becomes real possibility increasing resolution availability digital camera however case blind person finding text region first important problem must addressed assumed acquired image contains character first system try find image area small character zoom found area retake higher resolution image necessary character recognition propose four characterextraction method based connected component tested effectiveness method icdar robust reading competition data performance different method depends character size data bigger character prevalent effective extraction method prof sequence sobel edge detection otsu binarization connected component extraction rulebased connected component filtering ,2
BD_746,categorize data reduces access time nowadays internet one biggest data resource however data internet written natural language internet efficiently need categorized amount data increment rate high process done hand hence necessity automatic text categorization system increasing contrast language much turkish text system developed automatic text categorization news article article classified different class % success ratio achieved ,2
BD_747,quality electricity gaining emphasis among utility sector consumer maintain quality strategic measure coping sort disturbance generated intrinsically modern power electronic equipment large commercial building power environment mean improving electric power quality start systematic identification power system disturbance posed big challenge conventional approach based fourier transform principle drawback losing timedomain feature transformation whist technique wavelet transform appears promising strength handling signal short time interval high frequency component long time interval low frequency component integrated approach fourier wavelet transforms proposed used integrate advantage transforms wavelet transform used extract required timedomain information high frequency component fourier transform used provide accurate measurement low frequency component automatic power quality recognition system based integrated approach developed neural network classifier rulebased classifier selected implement proposed approach validation performed via simulated data set ,2
BD_748,summary form given conventional microwave source utilize strong axial magnetic field guide electron beam interaction region plasmaassisted slowwave microwave oscillator pasotron operate without external magnetic field presence ion neutralizes beam space charge allows radial motion electron action transverse field wave inherent efficiency conventional microwave source based interaction backward wave electron flow typically limited % current thrust take advantage electron motion pasotron order demonstrate high efficiency operation megawatt power level indeed efficiency excess % demonstrated experimentally power level mw beam voltage spl sim kv current range biggest challenge associated efficient high power operation pasotron beam dynamic power extraction mode competition theoretical study pic simulation experimental data indicate steady state transient beamdynamics selfpinching beam pasotron well understood recent theoretical experimental activity reviewed emphasis stationary nonstationary beam dynamic beam wave interaction efficient power extraction ,2
BD_749,traffic prediction play important role network layout traffic management etc two week network traffic cernet northwest center investigated seasonal arima model traffic prediction model proposed model parameter educed improved linear modeling traffic prediction data different step computed according model experiment result show prediction data match real data approximately prediction step le least mean square error prediction independent time depends step mean square error becomes bigger prediction effect becomes worse step becomes ,2
BD_750,standard generalized eigen value decomposition gevd popular ellipse detection technique whose statistical analysis given prove disadvantage big estimation bias mse also proved effective measurement improve performance ellipse detection whitening data noise regularizing data observation theoretic analysis strongly supported hartley regularization method improvedgevd algorithm developed theoretical analysis computer simulation experiment demonstrated proposed technique advantage intrinsically able whiten data noise regularize data observation output nonbiased estimation ellipse parameter small mse furthermore computation complex largely simplified ,2
BD_751,analysis hard realtime system traditionally performed rmapcp simulation nowadays also studied scheduler synthesis problem one automatically construct scheduler guarantee avoidance deadlock deadlinemiss system state even though approach potential finer control hard realtime system fewer resource easily adapting quality aspect memoryenergy consumption jitter minimisation etc synthesised scheduler usually extremely large difficult understand big size consequence inherent precision since attempt describe exactly frontier among safe unsafe system state nevertheless hinders application practise since extremely difficult validate better understanding behaviour system show one adapt datamining technique decrease size synthesised scheduler force inherent structure appear thus giving system designer wealth additional information understanding optimising scheduler underlying system particular used obtaining hint good distribution different processing unit optimising scheduler sometimes even removing altogether safe manner obtaining pertask persystem view schedulability system ,2
BD_752,biggest problem automatic target recognition accurate efficient extraction feature synthetic aperture radar sar image sar image formation algorithm recognition oriented developed algorithm based tomographic projection model sar observation vectorentropy optimization approach reconstruct sar image projection provides image higher resolution scatter better separate ability different region traditional algorithm applied synthetic sar scene data mit lincoln laboratory adts dataset show validity algorithm ,2
BD_753,effort reduce crime improve urban safety frequently falter deterministic thinking environmental determinist example assure u design crime defensible space lot foot traffic ignoring contributory socioeconomic factor social determinist call fairer policy doubt better technology urban design really make difference technological determinist instead assure u innovation networked video surveillance imminent inevitable regardless desirability yet often gloss unresolved analytical data sharing privacy issue would delay implementation year advocate disparate solution talk past one another present reason avoiding trap deterministic thinking urban safety discussion way brief simplified explanation specialized effort necessary implementing improvement balanced view big picture integrated coordinated approach crime prevention help bring big picture view additionally need focus constructive attention limit solution tempering enthusiasm without inducing paralysis author present wellestablished literature determinism social study science technology urban planning decision science additional useful insight ,2
BD_754,modelling methodology including dynamic stress evolution proposed characterize relative stressinduced voiding siv probability inside via various culow k interconnects seven pattern representative versatile ic design unit selected demonstrated modelling approach serve good method identifying troublesome layout unit insidevia siv result aligned well experimental data study two kind layout style designed together found detrimental layout unit vias subjected significant uppermetal edge confinement one via close big vacancy source ,2
BD_755,development information technology big change world economy form constant global market full much competition design lay inidual capacity also closely suit requirement developing market cscwd computer supported cooperative design provides supporting environment participant different background knowledge together reduce producing cycle increase product quality accelerate product proceeding cooperation key assure success product design capacity competition market challenge method traditional software development develop cooperative design environment based special area describes method componentbased design building intended facilitate cooperation assure requirement building design difference common software system fully think property design building support cooperation comprises communication component interface organize software building design database store component building design mechanism data changing visual environment satisfies requirement cooperative design building ,2
BD_756,gas identification represents big challenge pattern recognition system due several particular problem aim compare accuracy range advanced classical pattern recognition algorithm gas identification sensor array signal density estimation applied construction classifier bayes rule experiment real sensor data proved effectiveness approach excellent classification performance compare classification accuracy different density model several neural network architecture gas sensor data best performance achieved gaussian mixture model % accuracy ,2
BD_757,next generation cellular system increasingly similar data communication system transfer voice multimedia data also integrated wlan access internet whenever possible thus cellular system need highly integrated multistandard receiver design ad converter receiver big challenge reconfigurable spl sigmaspl delta modulator suitable gsmwcdmawlan standard introduced according different signal bandwidth dynamic range dr specification spl sigmaspl delta modulator reconfigured achieve required dynamic range le power consumption prototype implemented tsmc spl mum cmos process v power supply ,2
BD_758,third generation g wireless network high data rate get widely deployed optimizing tcp performance network would broad significant impact data application performance one biggest challenge optimizing tcp performance g wireless network adapting significant delay rate variation wireless channel make two contribution first window regulator algorithm us receiver window field acknowledgment packet convey instantaneous wireless channel condition tcp source ack buffer absorb channel variation thereby maximizing longlived tcp performance improves performance tcp sack % simple droptail algorithm small buffer size congested router second wireless channel tcpaware scheduling buffer sharing algorithm reduces latency short tcp flow % still exploiting ersity thus allowing wireless channel utilized efficiently ,2
BD_759,summary form given past year popularity internet growing leap bound however come time life technology matures question future need answered internet exception case often called next big thing global internet technology grid computing viewed one top candidate shape future internet grid computing take collective advantage vast improvement microprocessor speed optical communication raw storage capacity world wide web internet occurred last five year grid technology leverage existing resource delay need purchase infrastructure demand computer power industry like life science health informatics almost unlimited grid ability deliver greater power le cost give technology tremendous potential ultimately grid must evaluated term application business value scientific result delivers architecture biology provides important well complex scientific challenge time problem include understanding human genome discovering structure function protein gene encode information efficiently drug design problem extremely intensive computational perspective one principal design goal grid framework effective logical separation complexity programming massively parallel machine complexity bioinformatics computation definition appropriate interface encapsulation semantics bioinformatics computation methodology mean application track evolution machine architecture exploration various parallel decomposition scheme take place minimal intervention domain expert end user example understanding physical basis protein function central objective molecular biology protein function internal motion interaction environment understanding protein motion atomic level pursued since earliest simulation dynamic simulation connect experimental result microscopic examination different process via simulation acquire credibility simulation result help interpret experimental data improvement computational power simulation method facilitated grid framework could lead important progress study protein structure thermodynamics kinetics talk overview state play show grid change competitive landscape thus become potential disruptive technology ,2
BD_760,program slicing technique identify statement may influence computation statement despite ongoing research almost year program slicing still problem prevent widespread sometimes slice big understand expensive complicated computed reallife program presented thesis show solution problem contains various approach help understand slice easily making focused user problem approach implemented valsoft system thorough evaluation proposed algorithm presented underlying data structure used slicing program dependence graph also used different purpose approach clone detection based identifying similar subgraphs program dependence graph presented able detect modified clone better tool theoretical part thesis present highprecision approach slice concurrent procedural program despite fact optimal slicing known undecidable first approach slice concurrent program rely inlining called procedure ,2
BD_761,finding survey conducted finland software product company matured evolved year addition introducing key term characterizing software product business provide overall data sector discus specific issue related software r & ampd process subcontracting survey one largest survey covering software product company revealed several interesting finding software product company notably software company shown dynamic resilient challenging business environment biggest challenge growth technical management marketing related furthermore also discovered important improvement area improving degree productization level competence personnel ability network company critical younger company survey also revealed programming planning two common type subcontracting difficulty modularity specification biggest hurdle prevent wider subcontracting ,2
BD_762,internet undoubtedly changed prerequisite global music distribution year skepticism clinging old business model pirate hunt pp network record industry reluctantly begun embrace channel marketing distribution cultural content know music consumption pp network ? coincide variety cultural content traditional medium channel ? describes difference cultural content pp network concert traditional broadcasted medium based comprehensive data theoretic rage choice air play requested music pp service also describes change business model already taken place concludes among legal download service might reduce dominance big five major record company long run ,2
BD_763,part adopting industrial process go learning curve measure rate average unit cost production decrease cumulative amount produced increase argued organization buy integrated case tool leave shelf misinterpret learning curve effect productivity shown learningcurve model quantitatively document productivity effect integrated case tool factoring learning cost manager model result estimate future project greater accuracy without depth understanding manager likely make lessthanoptimal decision integrated case may abandon technology soon influence learning curve case tool adaptation learningcurve model integrate case discussed three biggest task implementation learningcurves integrated case setting locating suitable data site collecting data validating result also discussed & lt & ltetx & gt & gt ,2
BD_764,spatialtemporal traffic data analysis based global data management newly developed crucial approach help traffic manager global view urban traffic status level road network clearly useful traffic control route guidance multiagent system used traffic data management full consideration characteristic traffic data cooperation workflow among software implementation data management agentbased common object request broker architecture adopted taking distributed urban traffic data large area network environment account based global traffic data approach visualized spatialtemporal analysis induced similarity traffic data analyzed first link profile achieved undertake primary processing urban traffic data furthermore analysis result shown basis geographic information system transportation two type visualization pseudocolor contour map adopted demonstration display traffic status graphically changing frame among application big city china case urban traffic analysis beijing studied demonstrate implementation approach ,2
BD_765,due spectrum limitation lower frequency nasa deep space network currently implementing kaband ghz tracking capability deep space communication complex dsccs since weather effect increase atmospheric noise temperature associated biggest uncontrollable factor performance kaband deep space telecommunication link algorithm forecast atmospheric noise temperature pas desirable analytical method comparing performance ideal forecasting algorithm best statistical method term average data return derived methodology applied two different case first case spacecraft change data rate pas second case spacecraft continuously vary data rate methodology applied four different elevation profile whose maximum elevation varies le degree greater degree goldstone madrid canberra dsccs analysis show fixed data rate case forecasting significantly increase average data return link db db depending dscc elevation profile improve reliability link significantly ideal case % continuously variable data rate case forecasting improves average data return db db depending elevation profile dscc reliability link ideal case % ,2
BD_766,general approach isar imaging rangedoppler rd imaging approach approach translational motion compensation tmc firstly obtained envelope alignment autofocus target treated rotating target next processing method scatterers migration resolution cell mtrc caused rotational motion neglected however practice mtrc exists improvement resolution big target mtrc compensation keystone transformation sar used keystone transformation demanded raw data coherent fact isar raw data usually coherent processing raw data proposed coherent processing raw data firstly done next step correct mtrc finally parameter estimation method multicomponent amplitude modulation linear frequency modulation amlfm signal proposed estimate scatterers instantaneous amplitude frequency rangeinstantaneous doppler rid isar image obtained effective algorithm testified processing simulation data ,2
BD_767,economy booming china number town grows rapidly rapid urbanization brought many problem abuse land development chaos construction market etc informationization based gi r gps dedicated aid build geographical information system planning construction town however biggest obstacle informationization cost building spatial database town afford problem linking highresolution remote sensing data supermap gi gps proposes workable solution quick bird imagea kind highresolution serf data source spatial database based cad data map planning design town translated predefined layer stored spatial database supermap gi software exists blank digitize image vector screen last case prof technological plan cost saving fast one ,2
BD_768,remote sensing inversion assume observed data error distribution normal distribution simplifying calculation assumption observed data big error inversion result become unstable try expectationmaximization em algorithm get precise robust inversion result based another statistical distribution linear kerneldriven model tdistribution error solved em algorithm used prove idea inversion method include traditional ml estimate without prior distribution information inversion parameter bayesian inversion based prior normal distribution test robustness showed assumption tdistribution error half observed data big error cause instability inversion result ,2
BD_769,middle yangtze plain located central china well known world one region mostly suffering flooding disaster china recently increasing flooding result nature process also result land usecover change research land usecover change helpful trace flooding damage series land usecover coverage first generated visually interpreting landsattm etm image data mge arcinfo software based netchange analysis conversion matrix dynamic degree model characteristic spatialtemporal change transfer land usecover analyzed area result showed area farmland woodland decreased builtup area water area grassland nonused land increased past year significant shifting farmland water body builtup area cultivated land decreased hm % changed water area especially fishpond % builtup land interval pace landuse change much faster dynamic degree model found greatest change land usecover occurred big city ie wuhan city nanchang city slowest change mainly county near dongting lake poyang lake largescale land reclamation lake ever history curbed effectively flooding plain since author deduced worsened flooding risk area attributed overreclamation since although return cultivated land lake sufficiently alleviated flooding disaster due limited restore water body ,2
BD_770,north china special rim zone characterized mixture crop farming herd grazing due intensive land cropping grazing natural ecosystem semiarid zone seriously destroyed past decade several strong sandstorm recent year swept zone invade beijing capital china big city north china commonly agreed sandstorm direct result landscape ecological destroy northwest china inner mongolia mongolia plateau ecological degradation desertification core issue concerned inside outside china especially japan korea order monitor ecosystem development dynamic zone northwest china plateau possible program environmental improvement many academic effort way toward zone current lab part effort china objective monitor land change last twenty year rim zone arclnfo gi used tool establish spatial database socialeconomic natural condition zone remote sensing r data especially modis land tm image used land mapping integrating gi r technique analyze land dynamic zone county spreading qinghai gansu shaanxi shanxi hebei inner mongolia liaoning jilin heilongjiang province zone ided three subregions detailed examination east middle west result indicates farmland zone expands % rangeland contrast reduces % period hand occupied area settlement village town increase % imply intensive anthropogenic activity force driving landscape ecosystem zone change dramatically recent decade urgent administrate crop farming herd grazing sustainable development zone ecosystem fragile ,2
BD_771,investigation carried wetland biebrza basin biggest area marsh swamp central europe aimed finding best biophysical property wetland vegetation characterise marshland habitat various soilvegetation index basis considered spectral band satellite landsat +etm spot er noaa envisat calculated gemi evi index calculated spot vegetation best distinguishing vegetation class significant correlation lai measured ground index gemi evi index soil moisture value calculated er envisat microwave data well characterise marshland humidity class retrieval biophysical parameter lai leaf area index vegetation moisture vm soil moisture sm erssar envisat asar data acquired vv hv vh hh polarisation two different viewing angle applied evapotranspiration assessed noaa avhrr meteorological data er envisat image obtained esa aoid project ,2
BD_772,oasis specific landscape play important economic role arid northwestern china yet peripheral ecological system around oasis equally important oasis economic system term protecting oasis desertification ensuring sustainable development oasis however rapid increase population steady progress society technology since greatly expanded irrigated agricultural production oasis resulting dramatic decrease stream flow associated increase groundwater withdrawal arid northwestern china overexploitation groundwater formed groundwater table depletion cone eventually lowered groundwater table oasis also periphery oasis resulting overall decrease soil water content response soil moisture decrease periphery plant specie relying groundwater resource dying mesic specie replaced xerosere specie groundwater flowing process watertable fluctuating process past year simulated obtain spatial temporal distribution groundwater table mean gisassisted feflow modeling based hydrogeologic data obtained minqin basin several conclusion drawn simulated result firstly discharge recharge groundwater retained balanced groundwater table depth periphery area oasis maintained deep secondly utilization groundwater dropped groundwater table oasis leading formation big groundwater depletion cone started influence groundwater table periphery area thirdly overexploitation groundwater oasis dropped groundwater table oasis periphery since middle ,2
BD_773,huge amount available textual data need find convenient way process data get invaluable information appears factorial correspondence analysis allows get information included data besides even data processing still big amount material need visualization tool display show correspondence analysis sensible way give application analysis internal scientific production important research center france inria french national institute research computer science control ,2
BD_774,explore domain american football tv broadcasting respect interesting event detection existing method achieve goal event detection sport video type shot scene based approach many problem arise come shot scene level american football domain big amount camera movement tilting zooming panning large number different angle used different broadcasting network make difficult shotscene level show two level segmentation almost inevitable also propose novel concept answer problem domain concept unit unit defined good workable data necessary accurate unit detection process locate potentially interesting segment video separate rest redundant data ,2
BD_775,one biggest obstacle faced command based anomaly detection technique paucity data gathering command data slow process often spanning month year propose approach data generation based customizable template template represents particular profile template either userdefined created known data set developed automated tool called racoon rapidly generates large amount command data given template demonstrate technique produce realistic data showing pass several statistical similarity test real data approach offer significant advantage passive data collection term nonintrusive enabling rapid generation sitespecific data finally benchmark result wellknown algorithm original data set generated data set ,2
BD_776,evolution automation system reached point increasing complexity requires mechanism keep control design operation automation system model designed capable perceive react based global situation perception requires scenario recognition based continuous input many different type sensor future control system cope massive data quantity collected environment stable system reliably perceives situation relies ersity amount sensor input approach discussed simulation big amount sensor actuator order verify scalability evaluate verify model based scenario perception recognition ,2
BD_777,effect upstream u downstream d rate cap docsis medium access endtoend performance broadband ip service share typical homeaccess cable internet link experimental measure performance actual docsis equipment typical network configuration observe modestly long lived data transfer d direction create substantial latency spike m shared docsis segment even d rate cap one two megabit per second spike big impact delaysensitive application voice ip voip online game interactive streaming video may sharing docsis link also experimentally characterize impact u d bandwidth asymmetry mtu size tcp window size achieving maximum performance docsis link ,2
BD_778,world biggest generating plant construction boom drawing close natural gas fired combined cycle plant constituted large majority addition developer initially proposed plant commonly expected enter baseloaded electricity supplier capacity factor near % projection however failed account many dramatic change taken place ensuing year installed base power generation increased gw % increase four year period peak load demand rose % resulting excess capacity forced combined cycle power plant compete intermediate operation many part country time natural gas price risen dramatically exhibited increased volatility challenging profitability combined cycle plant factor combination difficult environment predict future plant operating level examines historical operating pattern combined cycle power plant also pattern changed recent year fundamental power system simulation model used predict future operation fundamental model predict maintenance part need entire fleet unit without needing expressly consider uncertainty inherent inidual unit forecast operation explored discussed finally impact change combined cycle operating pattern discussed equipment owner standpoint original equipment manufacturer oem part service supplier advantage sharing operating data illustrated product introduced improved operating knowledge ,2
BD_779,wireless sensor network wireless personal area network power consumption one important design criterion small device one biggest power consumer device rf transceiver normally kept powered possible incoming packet power inefficient preamble sampling scheme proposed enable receiver sample channel periodically low duty cycle sending long wakeuppreamble data frame dramatically reduces power consumption receiver proposes wakeupframe instead wakeuppreamble optimize preamble sampling scheme achieving additional battery lifetime gain order ten hundred percent different topology traffic load ,2
BD_780,traditionally mediumvolt mv power cable producer two choice insulation broad category crosslinked polyethylene xlpe ethylenepropylene rubber ep include variation treeresistant xlpe trxlpe ethylenepropylene rubber epr ethylenepropylenediene epdm etc last several year technology developed allowed polymer producer offer category material electrical insulation eam ethylenealkene copolymer material include component traditional ethylene propylene building block offer advantage processability flexibility performance broad range melt flow rate density molecular weight distribution available allows compound producer find right property balance optimal distributive mixing extrusion performance biggest challenge facing eam resin insulating material acceptance fairly conservative industry cable producer must able take advantage material improved processing well physical electrical property cost conscious deregulated utility industry examine suitability filled eam insulation category discus specific type material fall category provide cable test data comparison traditional xlpe epdm formulation available today test data include association edison illuminating company aeic qualification data accelerated cable life test aclt result icea testing among others ,2
BD_781,paradigm web service transforms internet repository data repository service gathering significant momentum academia industry recent year however web service published internet choose appropriate web component sea everchanging unpredictable largely uncontrollable web service pose big challenge propose mobile agentbased approach selects reliable web component costeffective manner ,2
BD_782,support vector machine regression svr big spl epsiv value give rough system model little support vector small spl epsiv value give accurate system model many support vector selection support vector effected small change training data obtain accurate model little support vector method includes two step proposed step one big spl epsiv value used select small number support vector step two giving selected support vector small value others big one accurate system model obtained experimental result demonstrate efficiency proposed method ,2
BD_783,discriminant analysis da big influence many scientific discipline unfortunately da algorithm need make assumption type data available therefore applicable everywhere example data class represented single gaussian share common covariance matrix linear discriminant analysis lda good option case da approach may preferred unfortunately still exist application da algorithm correctly represent reality therefore unsupervised technique principal component analysis pca may perform better first present theoretical define importantly da technique fail section used create da algorithm adapt training data available section first component solution design method automatically discover optimal set subclass class show achieved optimal result obtained second component algorithm given theoretical defines way rapidly select optimal number subclass experimental result two application object categorization face recognition show method comparable superior lda direct lda dlda nonparametric da nda pca ,2
BD_784,smart item technology like rfid sensor network considered next big step business process automation automatic realtime data acquisition technology benefit great variety industry improving efficiency operation sap autoid infrastructure enables integration rfid sensor technology existing business process give overview existing infrastructure discus lesson learned successful customer pilot point research issue ,2
BD_785,summary form given development wide software system activity consumes great quantity time resource even increase automation software development activity resource stay scarce consequence big interest metric software due potential better efficient resource tool help assist planning estimation complexity application develop different stage process describe technique define metric omg object management group standard specification semantic metric specified formally ocl object constraint language based omg metamodels concrete specification establish series step allows define uniformly metric different rup model furthermore show metric defined technique relation data obtained application metric thirteen object oriented system encompass project capture requirement implementation showing metric applied different stage deployment ,2
BD_786,trend toward bigger systemsonachip mean increase die size alone add significant dpm making goal doubledigit dpm current method infeasible keep quality control nanometer process test must target delay defect noise process variation functional testing highperformance part continues screen significant unique dpm top high coverage scan content atspeed test result heavy yield loss applied nonnative mode could target functionally unsensitizable path addition dft support reliable atspeed test application method proliferation subtle defect type nanometer process targeting defect directly essential contain test data volume target defect stochastic process ndefect bist used ,2
BD_787,importance shortterm load forecasting increasing lately deregulation competition energy price forecasting become big business busload forecasting essential feed analytical method utilized determining energy price variability nonstationarity load becoming worse due dynamic energy price besides number nodal load predicted allow frequent interaction load forecasting expert autonomous load predictor needed competitive scenario describes two strategy embedding discrete wavelet transform neural networkbased shortterm load forecasting goal develop robust load forecaster hourly load temperature data north american slovakian electric utility used test proposed methodology ,2
BD_788,digital data experienced explosive growth past year evidence suggests trend continues world becomes digitized data storage becomes increasingly relevant inidual community economy data storage undoubtedly continues big issue near future five year expect continued demand capacity proliferation form factor size shape storage device governmental regulation look like ? expect continued emphasis management technology heterogeneous environment lessexpensive storage medium tool content management short see cheaper better faster technology creating managing storing digital data ,2
BD_789,technological advance lowpower digital signal processor radio frequency rf circuit micromechanical system mem led emergence wirelessly interconnected sensor node technological possibility emerge large number tiny intelligent wireless sensor node combined sensor node typically battery operated therefore energy constrained hence energy conservation one foremost priority design wireless sensor network wsns protocol limited power resource bursty nature wireless channel biggest challenge wsns link adaptation technique improve link quality adjusting medium access control mac parameter frame size data rate sleep time thereby improving energy efficiency emphasizes optimizing wsns building reliable adaptive mac without compromising fairness performance link adaptation technique mac layer enhance energy efficiency sensor node proposed mac us variable frame size instead fixed frame size transmitting data order get accurate estimation well reducing computation complexity utilize extended kalman filter predict optimal frame size improving energy efficiency goodput minimizing sensor memory requirement next designed verified different network model evaluate analyze proposed link adaptation scheme correctness proposed theoretical model verified conducting extensive simulation also prototype proposed scheme mac protocol berkeley mote prototype simulation result show proposed algorithm improve energy efficiency % ,2
BD_790,wireless sensor network efficiently disseminating data dynamic source multiple mobile sink important application mobile target detection tracking treebased multicasting scheme used however due short communication range sensor node frequent movement source sink sink may fail receive data due broken path tree frequently reconfigured reconnect source sink address problem propose dynamic proxy treebased framework big challenge implementing framework reconfigure proxy tree efficiently source sink change model problem online construction minimum steiner tree euclidean plane propose centralized scheme solve considering strict energy constraint wireless sensor network propose two distributed online scheme shortest pathbased sp scheme spanning rangebased sr scheme extensive simulation conducted evaluate scheme result show distributed scheme similar performance centralized one among distributed scheme sr outperforms sp ,2
BD_791,conventional rate control scheme focus problem finding optimal quantization value p bframes rate control available encoding iframes could pose big problem due large number bit iframe could generate due fact number bit varies drastically sequence sequence depending image complexity problem becomes severe especially low bit rate therefore mechanism allocate data bit iframe according complexity indispensable order constant coding quality present mechanism establish iframes generic relationship quantization value data bit image complexity experimental result show generic relationship provides fairly accurate estimation quantization value iframe given data bit image complexity useful controlling data bit generated iframe ,2
BD_792,increasing capability mobile handset advancing multimedia processing improving codec technology eg mp jpeg mpeg sp bigger communication pipe potential providing increasing volume multimedia data mobile user problem intelligently managing multimedia content becoming increasingly prevalent space example application archive retrieve personal content well search stream commercial content wired wireless channel need provide compelling experience transparently efficiently handling vast amount underlying data provides userintuitive standardsbased approach managing multimedia content mobile handset ,2
BD_793,short term load forecasting recurrent topic operative planning activity company dedicated distribution trade energy around world due competitive electricity market advantage previous knowledge demand could mean difference obtaining big benefit incur economic loss novel method short term load forecasting proposed based similar day approach soft computing technique approach founded search similar day history forecasted day based explanatory meteorological variable forecast load day similar day found load forecast day adjustment load growth lamdafuzzyclustering technique regression tree cart classification fuzzy inference peak power daily energy load curve forecast used validation proposed method made meteorological load data colombian city ,2
BD_794,transfer broadcast packet safely node computer network important issue however big challenge transfer broadcast packet wireless network reliably due unsettled wireless link lack acknowledgment ack scheme therefore propose reliable broadcast scheme named broadcast engagement ack mechanism beam completely compatible ieee protocol beam data link layer rather network layer overhead raising reliability broadcast transmission network layer significantly reduced data link layer simulation result show beam reach approximately % reliability even heavy traffic load besides proposed mechanism ieee protocol provide reliability unicast transmission well broadcast transmission avoid redundant control overhead ,2
BD_795,one many challenge associated sensor network transmit data power sensor sensing multiple parameter environment requires miniaturized sensor node relatively powerful programming platform interface process data reliable longterm power solution battery provide obvious power source long module reasonably big square centimeter easily accessible number battery easily replaced recharged vision ubiquitous computing module embedded everyday object computer hardware invisible replacing battery isnt compatible vision several solution power problem exist reducing power consumption point battery last module lifetime another solution energy scavenging extracting energy ambient source vibration hear light water approach provides power source fast communication miniaturized module sensor node mhz carrier although powering range limited method well suited application communication must fast sensor module hard access ,2
BD_796,discus gerd binning nobel laureate physic star ibm corp metamorphosing research apparatus tom rust selftaught engineer founded nanochip inc competing develop nanotechnology first truly big commercial breakthrough called probe storage probe storage memory system could keep data storage par pitiless pace advance consumer computing electronics prime candidate combine low cost high capacity random access feature ordinary magnetic hard disk drive low power draw high data rate small size nonvolatility solidstate flash memory ,2
BD_797,comparison traditional singlegene method reverse transcriptasepolymerase chain reaction rtpcr microarray technology produce highthroughout gene expression data simultaneously advancement technology also present big challenge cancer research issue identify signature gene biomarkers associated particular cancer perform precise objective systematic cancer diagnosis treatment specifically goal accurately analyze interpret resulting large amount gene expression data relatively small patient sample size developing novel multischeme system derive optimal decision based best utilization gene expression data feature clinical biological knowledge reporting result first phase development novel system unsupervised clustering method discover gene relationship knowledgebased supervised classification get highly accurate prediction cancer diagnosis prognosis set foundation next step drug target ,2
BD_798,since nakhodka oil spill incident several equipment system oil recovery researched developed japan oil skimming vessel launched expected well hard judge effectively equipment product performs site coast without experience canada u test equipment large tank ohmsett towing bridge norway big circulating tank sea improve outcome many data experiment real situation however test tank japan could opportunity test real situation government appropriated fund constructing tank pari research development oil spill response supplementary budget tank specification planned test equipment oil recovery test site coast collect requirement tank satisfy theme tank objective tank advance research development recovery emulsified heavy oil cause hard damage marine environment simulate wave velocity vessel current water temperature viscosity oil wind site coast test several skimmer oil boom oil recovery system order judge performance behavior influenced several factor therefore tank dimension width length water depth salty water filled controlled temperature chiller heater leftover oil cleaned oil filter generate wave max current max m physic chemistry analyzing room cylindrical tank depth placed supplementary facility plant appreciated synthetic ,2
BD_799,electronic device convey information displaying liquid crystal display lcd visually impaired people benefit electronic device lcd technology adapted product exist market product established relatively small number imported therefore useful product available affordable cost design construction talking call line identification tcli unit integrated sound output used telkom line unit incorporates audio visual inputoutput onboard function visually impaired user navigate unit setting assisted prerecorded voice prompt big input button graphical lcd unit completes unit used nonimpaired reproduction human voice accomplished prerecording solidstate information storage device isd capable recording eight minute voice data enables unit announce incoming caller number associated recording caller name come great benefit visually impaired seeing user telephone well ,2
BD_800,digital watermarking refers process embedding digital code image video printed document audio medium code interfere normal medium recovered later growing interest haptic interaction training museum display matter time haptic digital medium become available internet example one soon able feel shape michaelangelo david japan big buddha downloading file played forcefeedback device haptic file may contain surface texture data addition topography david feel like marble big buddha wood meanwhile need haptic digital watermarking arise protecting haptic medium content introduces first time idea haptic watermarking show one way embed watermark host surface texture signal also demonstrate imperceptibility texture watermark psychophysical experiment ,2
